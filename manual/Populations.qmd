---
title: "Populations"
execute:
  echo: true
jupyter: python3
---

Once the `Neuron` objects have been defined, the populations can be created. Let's suppose we have defined the following rate-coded neuron:

```{python}
import numpy as np
import ANNarchy as ann

LeakyIntegratorNeuron = ann.Neuron(
    parameters = dict(
        tau = 10.0,
        baseline = -0.2
    ),
    equations = [
        'tau * dv/dt  + v = baseline + sum(exc)',
        'r = pos(v)',
    ]
)
```

## Creating populations

Populations of neurons are contained in an instance of the `Population` class, which can be created by calling the `create()` method of a network:

```{python}
net = ann.Network()

pop1 = net.create(geometry=100, neuron=LeakyIntegratorNeuron)
pop2 = net.create(geometry=(8, 8), neuron=LeakyIntegratorNeuron, name="pop2")
```

The rate-coded or spiking nature of the `Neuron` instance is irrelevant when creating the `Population` object. `Population` objects can also be created directly by providing the id of the network object, but it is not recommended.

`Network.create()` takes different arguments:

* `geometry` defines the number of neurons in the population, as well as its spatial structure (1D/2D/3D or more). For example, a two-dimensional population with 15\*10 neurons takes the argument `(15, 10)`, while a one-dimensional array of 100 neurons would take `(100,)` or simply `100`.
* `neuron` indicates the neuron type to use for this population (which must have been defined before). It requires a `Neuron` class or instance.
* `name` is an unique string for each population in the network. If `name` is omitted, an internal name such as `pop0` will be given (the number is incremented every time a new population is defined). Although this argument is optional, it is recommended to give an understandable name to each population: if you somehow "lose" the reference to the `Population` object in some portion of your code, you can always retrieve it using the `net.get_population(name)` method.

After creation, each population has several attributes defined (corresponding to the parameters and variables of the `Neuron` type) and is assigned a fixed size (`pop.size` corresponding to the total number of neurons, here 100 for `pop1` and 64 for `pop2`) and geometry (`pop1.geometry`, here `(100, )` and `(8, 8)`).

## Geometry and ranks

Each neuron in the population has a set of **coordinates** (expressed relative to `pop1.geometry`) and a **rank** (from 0 to `pop1.size -1`). The reason is that spatial coordinates are useful for visualization, or when defining a distance-dependent connection pattern, but that ANNarchy internally uses flat arrays for performance reasons.

The coordinates use the matrix notation for multi-dimensional arrays, which is also used by Numpy (for a 2D matrix, the first index represents the row, the second the column). You can therefore use safely the `reshape()` methods of Numpy to switch between coordinates-based and rank-based representations of an array.

To convert the rank of a neuron to its coordinates (and vice-versa), you
can use the [ravel_multi_index](http://docs.scipy.org/doc/numpy/reference/generated/numpy.ravel_multi_index.html) and [unravel_index](http://docs.scipy.org/doc/numpy/reference/generated/numpy.unravel_index.html#numpy.unravel_index) methods of Numpy, but they can be quite slow. The `Population` class provides two more efficient methods to do this conversion:

* `coordinates_from_rank` returns a tuple representing the coordinates of neuron based on its rank (between 0 and `size -1`, otherwise an error is thrown).
* `rank_from_coordinates` returns the rank corresponding to the coordinates.

For example, with `pop2` having a geometry `(8, 8)`:

```{python}
pop2.coordinates_from_rank(15)
```

```{python}
pop2.rank_from_coordinates((4, 6))
```

## Population attributes

The value of the parameters and variables of all neurons in a population can be accessed and modified through population attributes.

With the previously defined populations, you can list all their parameters and variables with:

```{python}
pop2.attributes
```
```{python}
pop2.parameters
```
```{python}
pop2.variables
```

Reading their value is straightforward:

```{python}
pop2.tau
```
```{python}
pop2.r
```

Population-wise parameters/variables have a single value for the
population, while neuron-specific ones return a NumPy array with the
same geometry has the population.

Setting their value is also simple:

```{python}
pop2.tau = 20.0
print(pop2.tau)
```

```{python}
pop2.r = 1.0
print(pop2.r) 
```

```{python}
pop2.v = 0.5 * np.ones(pop2.geometry)
print(pop2.v)
```
```{python}
pop2.r = ann.Uniform(0.0, 1.0)
print(pop2.r)
```

For population-wide attributes, you can only specify a single value (float, int or bool depending on the type of the parameter/variable). For neuron-specific attributes, you can provide either:

* a single value which will be applied to all neurons of the population.
* a list or a one-dimensional Numpy array of the same length as the number of neurons in the population. This information is provided by `pop1.size`.
* a Numpy array of the same shape as the geometry of the population. This information is provided by `pop1.geometry`.
* a random number generator object (Uniform, Normal\...).

:::callout-note

If you do not want to use the attributes of Python (for example when doing a loop over unknown attributes), you can also use the `get(name)` and `set(values)` methods of **Population**:

```{python}
pop1.set({'v': 1.0, 'r': ann.Uniform(0.0, 1.0)})
print(pop1.get('v'))
print(pop1.get('r'))
```
:::


## Accessing individual neurons

There exists a purely semantic access to individual neurons of a population. The `IndividualNeuron` class wraps population data for a specific neuron. It can be accessed through the `Population.neuron()` method using either the rank of the neuron (from 0 to `pop1.size - 1`) or its coordinates in the population's geometry:

```{python}
print(pop2.neuron(2, 2))
```

The individual neurons can be manipulated individually:

```{python}
my_neuron = pop2.neuron(2, 2)
my_neuron.r = 1.0
print(my_neuron)
```

:::callout-warning

`IndividualNeuron` is only a wrapper for ease of use, the real data is stored in arrays for the whole population, so accessing individual neurons is much slower and should be reserved to specific cases (i.e. only from time to time and for a limited set of neurons).
:::

## Accessing groups of neurons - PopulationView

Individual neurons can be grouped into `PopulationView` objects, which hold references to different neurons of the same population. One can create population views by "adding" several neurons together:

```{python}
popview = pop2.neuron(2, 2) + pop2.neuron(3, 3) + pop2.neuron(4, 4)
```
```{python}
popview.r = 1.0
print(pop2.r)
```

One can also use the slice operators to create PopulationViews:

```{python}
popview = pop2[3, :]
popview.r = 1.0
print(pop2.r)
```

or:

```{python}
popview = pop2[2:5, 4] 
popview.r = 1.0
print(pop1.r)
```

`PopulationView` objects can be used to create projections.

:::callout-warning
Contrary to the equivalent in PyNN, PopulationViews in ANNarchy can only group neurons from the same population.
:::

## Functions

If you have defined a function inside a `Neuron` definition:

```python
LeakyIntegratorNeuron = ann.Neuron(
    parameters = dict(   
        tau = 10.0,
        slope = 1.0,
        baseline = -0.2,
    ),
    equations = [
        'tau * dv/dt + v = baseline + sum(exc)'
        'r = sigmoid(v, slope)'
    ],
    functions = """
        sigmoid(x, k) = 1.0 / (1.0 + exp(-x*k))
    """
)
```

you can use this function in Python as if it were a method of the
corresponding object:

```python
pop = net.create(1000, LeakyIntegratorNeuron)

x = np.linspace(-1., 1., 100)
k = np.ones(100)
r = pop.sigmoid(x, k)
```

You can pass either a list or a 1D Numpy array to each argument (**not a single value, nor a multidimensional array!**).

The size of the arrays passed for each argument is arbitrary (it must not match the population's size) but you have to make sure that they all have the same size. Errors are not catched, so be careful.
