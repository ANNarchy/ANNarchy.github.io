
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      <link rel="icon" href="../_static/logo.svg">
      <meta name="generator" content="mkdocs-1.4.2, mkdocs-material-8.5.10">
    
    
      
        <title>Convolution and Pooling - ANNarchy 4.7.2</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.975780f9.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.2505c338.min.css">
        
          
          
          <meta name="theme-color" content="#000000">
        
      
      

    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="../css/ansi-colours.css">
    
      <link rel="stylesheet" href="../css/jupyter-cells.css">
    
      <link rel="stylesheet" href="../css/pandas-dataframe.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="black" data-md-color-accent="indigo">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#convolution-and-pooling" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../index.html" title="ANNarchy 4.7.2" class="md-header__button md-logo" aria-label="ANNarchy 4.7.2" data-md-component="logo">
      
  <img src="../_static/logowhite.svg" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            ANNarchy 4.7.2
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Convolution and Pooling
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/ANNarchy/ANNarchy" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.2.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../index.html" title="ANNarchy 4.7.2" class="md-nav__button md-logo" aria-label="ANNarchy 4.7.2" data-md-component="logo">
      
  <img src="../_static/logowhite.svg" alt="logo">

    </a>
    ANNarchy 4.7.2
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/ANNarchy/ANNarchy" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.2.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../index.html" class="md-nav__link">
        Home
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../Installation.html" class="md-nav__link">
        Installation
      </a>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3" type="checkbox" id="__nav_3" >
      
      
      
      
        <label class="md-nav__link" for="__nav_3">
          Manual
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Manual" data-md-level="1">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          Manual
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../manual/Structure.html" class="md-nav__link">
        General structure
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../manual/Parser.html" class="md-nav__link">
        Parser
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../manual/RateNeuron.html" class="md-nav__link">
        Rate-coded neurons
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../manual/SpikeNeuron.html" class="md-nav__link">
        Spiking neurons
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../manual/RateSynapse.html" class="md-nav__link">
        Rate-coded synapses
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../manual/SpikeSynapse.html" class="md-nav__link">
        Spiking synapses
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../manual/Populations.html" class="md-nav__link">
        Populations
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../manual/Projections.html" class="md-nav__link">
        Projections
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../manual/Connector.html" class="md-nav__link">
        Connectivity
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../manual/Inputs.html" class="md-nav__link">
        Setting inputs
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../manual/Simulation.html" class="md-nav__link">
        Simulation
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../manual/Configuration.html" class="md-nav__link">
        Configuration
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../manual/NumericalMethods.html" class="md-nav__link">
        Equations and numerical methods
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../manual/Recording.html" class="md-nav__link">
        Recording with Monitors
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../manual/Saving.html" class="md-nav__link">
        Saving and loading a network
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../manual/Network.html" class="md-nav__link">
        Parallel simulations and networks
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../manual/Hybrid.html" class="md-nav__link">
        Hybrid networks
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../manual/StructuralPlasticity.html" class="md-nav__link">
        Structural plasticity
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../manual/ConvolutionalNetworks.html" class="md-nav__link">
        Convolution and pooling
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../manual/Notebooks.html" class="md-nav__link">
        Notebooks
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../manual/Reporting.html" class="md-nav__link">
        Reporting
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../manual/Logging.html" class="md-nav__link">
        Logging with tensorboard
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4" type="checkbox" id="__nav_4" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_4">
          API
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="API" data-md-level="1">
        <label class="md-nav__title" for="__nav_4">
          <span class="md-nav__icon md-icon"></span>
          API
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_1" type="checkbox" id="__nav_4_1" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_1">
          core
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="core" data-md-level="2">
        <label class="md-nav__title" for="__nav_4_1">
          <span class="md-nav__icon md-icon"></span>
          core
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="ANNarchy.html" class="md-nav__link">
        Top-level methods
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Neuron.html" class="md-nav__link">
        Neuron class
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="SpecificNeuron.html" class="md-nav__link">
        Built-in neuron types
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Synapse.html" class="md-nav__link">
        Synapse class
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="SpecificSynapse.html" class="md-nav__link">
        Built-in synapse types
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Population.html" class="md-nav__link">
        Population class
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="SpecificPopulation.html" class="md-nav__link">
        Specific Populations
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Projection.html" class="md-nav__link">
        Projection class
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="SpecificProjection.html" class="md-nav__link">
        Specific Projections
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Dendrite.html" class="md-nav__link">
        Dendrite class
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Monitor.html" class="md-nav__link">
        Monitoring
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="RandomDistribution.html" class="md-nav__link">
        Random Distributions
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Network.html" class="md-nav__link">
        Network class
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="IO.html" class="md-nav__link">
        Saving / Loading
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Utilities.html" class="md-nav__link">
        Reporting
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Hybrid.html" class="md-nav__link">
        Hybrid networks
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_2" type="checkbox" id="__nav_4_2" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_4_2">
          extensions
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="extensions" data-md-level="2">
        <label class="md-nav__title" for="__nav_4_2">
          <span class="md-nav__icon md-icon"></span>
          extensions
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          Convolution and Pooling
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="Convolution.html" class="md-nav__link md-nav__link--active">
        Convolution and Pooling
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#ANNarchy.extensions.convolution.Convolution" class="md-nav__link">
    Convolution
  </a>
  
    <nav class="md-nav" aria-label="Convolution">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ANNarchy.extensions.convolution.Convolve.Convolution.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ANNarchy.extensions.convolution.Convolve.Convolution.connect_filter" class="md-nav__link">
    connect_filter()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ANNarchy.extensions.convolution.Convolve.Convolution.connect_filters" class="md-nav__link">
    connect_filters()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ANNarchy.extensions.convolution.Convolve.Convolution.connectivity_matrix" class="md-nav__link">
    connectivity_matrix()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ANNarchy.extensions.convolution.Convolve.Convolution.load" class="md-nav__link">
    load()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ANNarchy.extensions.convolution.Convolve.Convolution.receptive_fields" class="md-nav__link">
    receptive_fields()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ANNarchy.extensions.convolution.Convolve.Convolution.save" class="md-nav__link">
    save()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ANNarchy.extensions.convolution.Convolve.Convolution.save_connectivity" class="md-nav__link">
    save_connectivity()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#ANNarchy.extensions.convolution.Pooling" class="md-nav__link">
    Pooling
  </a>
  
    <nav class="md-nav" aria-label="Pooling">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ANNarchy.extensions.convolution.Pooling.Pooling" class="md-nav__link">
    Pooling
  </a>
  
    <nav class="md-nav" aria-label="Pooling">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ANNarchy.extensions.convolution.Pooling.Pooling.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ANNarchy.extensions.convolution.Pooling.Pooling.connect_pooling" class="md-nav__link">
    connect_pooling()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ANNarchy.extensions.convolution.Pooling.Pooling.connectivity_matrix" class="md-nav__link">
    connectivity_matrix()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ANNarchy.extensions.convolution.Pooling.Pooling.load" class="md-nav__link">
    load()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ANNarchy.extensions.convolution.Pooling.Pooling.receptive_fields" class="md-nav__link">
    receptive_fields()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ANNarchy.extensions.convolution.Pooling.Pooling.save" class="md-nav__link">
    save()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ANNarchy.extensions.convolution.Pooling.Pooling.save_connectivity" class="md-nav__link">
    save_connectivity()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#ANNarchy.extensions.convolution.Copy" class="md-nav__link">
    Copy
  </a>
  
    <nav class="md-nav" aria-label="Copy">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ANNarchy.extensions.convolution.Copy.Copy" class="md-nav__link">
    Copy
  </a>
  
    <nav class="md-nav" aria-label="Copy">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ANNarchy.extensions.convolution.Copy.Copy.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ANNarchy.extensions.convolution.Copy.Copy.connect_copy" class="md-nav__link">
    connect_copy()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ANNarchy.extensions.convolution.Copy.Copy.connectivity_matrix" class="md-nav__link">
    connectivity_matrix()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ANNarchy.extensions.convolution.Copy.Copy.generate_omp" class="md-nav__link">
    generate_omp()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ANNarchy.extensions.convolution.Copy.Copy.load" class="md-nav__link">
    load()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ANNarchy.extensions.convolution.Copy.Copy.receptive_fields" class="md-nav__link">
    receptive_fields()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ANNarchy.extensions.convolution.Copy.Copy.save" class="md-nav__link">
    save()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ANNarchy.extensions.convolution.Copy.Copy.save_connectivity" class="md-nav__link">
    save_connectivity()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Logging.html" class="md-nav__link">
        Logging with tensorboard
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="BOLD.html" class="md-nav__link">
        BOLD monitoring
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5" type="checkbox" id="__nav_5" >
      
      
      
      
        <label class="md-nav__link" for="__nav_5">
          Examples
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Examples" data-md-level="1">
        <label class="md-nav__title" for="__nav_5">
          <span class="md-nav__icon md-icon"></span>
          Examples
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../example/List.html" class="md-nav__link">
        List of notebooks
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../example/NeuralField.html" class="md-nav__link">
        Neural Field
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../example/BarLearning.html" class="md-nav__link">
        Bar Learning
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../example/StructuralPlasticity.html" class="md-nav__link">
        Structural plasticity
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../example/Izhikevich.html" class="md-nav__link">
        Izhikevich
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../example/GapJunctions.html" class="md-nav__link">
        Gap junctions
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../example/HodgkinHuxley.html" class="md-nav__link">
        Hodgkin-Huxley
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../example/COBA.html" class="md-nav__link">
        COBA
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../example/STP.html" class="md-nav__link">
        STP
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../example/SimpleSTDP.html" class="md-nav__link">
        STDP
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../example/Ramp.html" class="md-nav__link">
        Ramp
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../example/Hybrid.html" class="md-nav__link">
        Hybrid
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../example/Image.html" class="md-nav__link">
        Image
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../example/Webcam.html" class="md-nav__link">
        Webcam
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../example/MultipleNetworks.html" class="md-nav__link">
        Parallel simulations
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../example/BayesianOptimization.html" class="md-nav__link">
        Bayesian optimization
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../example/BasalGanglia.html" class="md-nav__link">
        Logging with tensorboard
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../example/BoldMonitoring.html" class="md-nav__link">
        BOLD monitoring
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../License.html" class="md-nav__link">
        License
      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#ANNarchy.extensions.convolution.Convolution" class="md-nav__link">
    Convolution
  </a>
  
    <nav class="md-nav" aria-label="Convolution">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ANNarchy.extensions.convolution.Convolve.Convolution.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ANNarchy.extensions.convolution.Convolve.Convolution.connect_filter" class="md-nav__link">
    connect_filter()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ANNarchy.extensions.convolution.Convolve.Convolution.connect_filters" class="md-nav__link">
    connect_filters()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ANNarchy.extensions.convolution.Convolve.Convolution.connectivity_matrix" class="md-nav__link">
    connectivity_matrix()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ANNarchy.extensions.convolution.Convolve.Convolution.load" class="md-nav__link">
    load()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ANNarchy.extensions.convolution.Convolve.Convolution.receptive_fields" class="md-nav__link">
    receptive_fields()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ANNarchy.extensions.convolution.Convolve.Convolution.save" class="md-nav__link">
    save()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ANNarchy.extensions.convolution.Convolve.Convolution.save_connectivity" class="md-nav__link">
    save_connectivity()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#ANNarchy.extensions.convolution.Pooling" class="md-nav__link">
    Pooling
  </a>
  
    <nav class="md-nav" aria-label="Pooling">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ANNarchy.extensions.convolution.Pooling.Pooling" class="md-nav__link">
    Pooling
  </a>
  
    <nav class="md-nav" aria-label="Pooling">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ANNarchy.extensions.convolution.Pooling.Pooling.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ANNarchy.extensions.convolution.Pooling.Pooling.connect_pooling" class="md-nav__link">
    connect_pooling()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ANNarchy.extensions.convolution.Pooling.Pooling.connectivity_matrix" class="md-nav__link">
    connectivity_matrix()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ANNarchy.extensions.convolution.Pooling.Pooling.load" class="md-nav__link">
    load()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ANNarchy.extensions.convolution.Pooling.Pooling.receptive_fields" class="md-nav__link">
    receptive_fields()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ANNarchy.extensions.convolution.Pooling.Pooling.save" class="md-nav__link">
    save()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ANNarchy.extensions.convolution.Pooling.Pooling.save_connectivity" class="md-nav__link">
    save_connectivity()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#ANNarchy.extensions.convolution.Copy" class="md-nav__link">
    Copy
  </a>
  
    <nav class="md-nav" aria-label="Copy">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ANNarchy.extensions.convolution.Copy.Copy" class="md-nav__link">
    Copy
  </a>
  
    <nav class="md-nav" aria-label="Copy">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ANNarchy.extensions.convolution.Copy.Copy.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ANNarchy.extensions.convolution.Copy.Copy.connect_copy" class="md-nav__link">
    connect_copy()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ANNarchy.extensions.convolution.Copy.Copy.connectivity_matrix" class="md-nav__link">
    connectivity_matrix()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ANNarchy.extensions.convolution.Copy.Copy.generate_omp" class="md-nav__link">
    generate_omp()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ANNarchy.extensions.convolution.Copy.Copy.load" class="md-nav__link">
    load()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ANNarchy.extensions.convolution.Copy.Copy.receptive_fields" class="md-nav__link">
    receptive_fields()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ANNarchy.extensions.convolution.Copy.Copy.save" class="md-nav__link">
    save()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ANNarchy.extensions.convolution.Copy.Copy.save_connectivity" class="md-nav__link">
    save_connectivity()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  <a href="https://github.com/ANNarchy/ANNarchy/edit/master/docs/API/Convolution.md" title="Edit this page" class="md-content__button md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25Z"/></svg>
  </a>


<h1 id="convolution-and-pooling">Convolution and Pooling<a class="headerlink" href="#convolution-and-pooling" title="Permanent link">#</a></h1>
<p>Convolution and pooling operations are provided in the module
<code>ANNarchy.extensions.convolution</code>. They must be explicitely imported:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">ANNarchy</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">ANNarchy.extensions.convolution</span> <span class="kn">import</span> <span class="o">*</span>
</code></pre></div>


<div class="doc doc-object doc-class">



<h2 id="ANNarchy.extensions.convolution.Convolution" class="doc doc-heading">
        <code>ANNarchy.extensions.convolution.Convolution</code>


<a href="#ANNarchy.extensions.convolution.Convolution" class="headerlink" title="Permanent link">#</a></h2>


  <div class="doc doc-contents first">
      <p class="doc doc-class-bases">
        Bases: <code><a title="ANNarchy.core.Projection.Projection" href="Projection.html#ANNarchy.Projection">Projection</a></code></p>

  
      <p>Performs a convolution of a weight kernel on the pre-synaptic population.</p>
<p>Despite its name, the operation performed is actually a cross-correlation, as is usual in computer vision and convolutional neural networks:</p>
<div class="arithmatex">\[g(x) = \sum_{k=-n}^n h(k) \, f(x + k)\]</div>
<p>The convolution operation benefits from giving a multi-dimensional geometry to the populations and filters, for example in 2D:</p>
<div class="highlight"><pre><span></span><code><span class="n">inp</span> <span class="o">=</span> <span class="n">Population</span><span class="p">(</span><span class="n">geometry</span><span class="o">=</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">),</span> <span class="n">neuron</span><span class="o">=</span><span class="n">Neuron</span><span class="p">(</span><span class="n">parameters</span><span class="o">=</span><span class="s2">&quot;r = 0.0&quot;</span><span class="p">))</span>
<span class="n">pop</span> <span class="o">=</span> <span class="n">Population</span><span class="p">(</span><span class="n">geometry</span><span class="o">=</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">),</span> <span class="n">neuron</span><span class="o">=</span><span class="n">Neuron</span><span class="p">(</span><span class="n">equations</span><span class="o">=</span><span class="s2">&quot;r = sum(exc)&quot;</span><span class="p">))</span>
<span class="n">proj</span> <span class="o">=</span> <span class="n">Convolution</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">pop</span><span class="p">,</span> <span class="s1">&#39;exc&#39;</span><span class="p">)</span>
<span class="n">proj</span><span class="o">.</span><span class="n">connect_filter</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]</span>
    <span class="p">])</span>
</code></pre></div>
<p>The maximum number of dimensions for populations and filters is 4, an error is thrown otherwise.</p>
<p>Depending on the number of dimensions of the pre- and post-synaptic populations, as well as of the kernel, the convolution is implemented differentely.</p>
<p><strong>Method connect_filter()</strong></p>
<ul>
<li>
<p>If the pre- and post-populations have the same dimension as the kernel, the convolution is regular. Example:</p>
<p>(100, 100) * (3, 3) -&gt; (100, 100)</p>
</li>
<li>
<p>If the post-population has one dimension less than the pre-synaptic one, the last dimension of the kernel must match the last one of the pre-synaptic population. Example:</p>
<p>(100, 100, 3) * (3, 3, 3) -&gt; (100, 100)</p>
</li>
<li>
<p>If the kernel has less dimensions than the two populations, the number of neurons in the last dimension of the populations must be the same. The convolution will be calculated for each feature map in the last dimension. In this case, you must set <code>keep_last_dimension</code> to <code>True</code>. Example:</p>
<p>(100, 100, 16) * (3, 3) -&gt; (100, 100, 16)</p>
</li>
</ul>
<p><strong>Method connect_filters()</strong></p>
<ul>
<li>
<p>If the kernel has more dimensions than the pre-synaptic population, this means a bank of different filters will be applied on the pre-synaptic population (like a convolutional layer in a CNN). Attention: the first index of <code>weights</code> corresponds to the different filters, while the result will be accessible in the last dimension of the post-synaptic population. You must set the <code>multiple</code> argument to True. Example:</p>
<p>(100, 100) * (16, 3, 3) -&gt; (100, 100, 16)</p>
</li>
</ul>
<p>The convolution <strong>always</strong> uses padding for elements that would be outside the array (no equivalent of <code>valid</code> in tensorflow). It is 0.0 by default, but can be changed using the <code>padding</code> argument. Setting <code>padding</code> to the string <code>border</code> will repeat the value of the border elements.</p>
<p>Sub-sampling will be automatically performed according to the populations' geometry. If these geometries do not match, an error will be thrown. Example:</p>
<div class="highlight"><pre><span></span><code>(100, 100) * (3, 3) -&gt; (50, 50)
</code></pre></div>
<p>You can redefine the sub-sampling by providing a list <code>subsampling</code> as argument, defining for each post-synaptic neuron the coordinates of the pre-synaptic neuron which will be the center of the filter/kernel.</p>


        <details class="quote">
          <summary>Source code in <code>ANNarchy/extensions/convolution/Convolve.py</code></summary>
          <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span>
<span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span>
<span class="normal">583</span>
<span class="normal">584</span>
<span class="normal">585</span>
<span class="normal">586</span>
<span class="normal">587</span>
<span class="normal">588</span>
<span class="normal">589</span>
<span class="normal">590</span>
<span class="normal">591</span>
<span class="normal">592</span>
<span class="normal">593</span>
<span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span>
<span class="normal">597</span>
<span class="normal">598</span>
<span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span>
<span class="normal">602</span>
<span class="normal">603</span>
<span class="normal">604</span>
<span class="normal">605</span>
<span class="normal">606</span>
<span class="normal">607</span>
<span class="normal">608</span>
<span class="normal">609</span>
<span class="normal">610</span>
<span class="normal">611</span>
<span class="normal">612</span>
<span class="normal">613</span>
<span class="normal">614</span>
<span class="normal">615</span>
<span class="normal">616</span>
<span class="normal">617</span>
<span class="normal">618</span>
<span class="normal">619</span>
<span class="normal">620</span>
<span class="normal">621</span>
<span class="normal">622</span>
<span class="normal">623</span>
<span class="normal">624</span>
<span class="normal">625</span>
<span class="normal">626</span>
<span class="normal">627</span>
<span class="normal">628</span>
<span class="normal">629</span>
<span class="normal">630</span>
<span class="normal">631</span>
<span class="normal">632</span>
<span class="normal">633</span>
<span class="normal">634</span>
<span class="normal">635</span>
<span class="normal">636</span>
<span class="normal">637</span>
<span class="normal">638</span>
<span class="normal">639</span>
<span class="normal">640</span>
<span class="normal">641</span>
<span class="normal">642</span>
<span class="normal">643</span>
<span class="normal">644</span>
<span class="normal">645</span>
<span class="normal">646</span>
<span class="normal">647</span>
<span class="normal">648</span>
<span class="normal">649</span>
<span class="normal">650</span>
<span class="normal">651</span>
<span class="normal">652</span>
<span class="normal">653</span>
<span class="normal">654</span>
<span class="normal">655</span>
<span class="normal">656</span>
<span class="normal">657</span>
<span class="normal">658</span>
<span class="normal">659</span>
<span class="normal">660</span>
<span class="normal">661</span>
<span class="normal">662</span>
<span class="normal">663</span>
<span class="normal">664</span>
<span class="normal">665</span>
<span class="normal">666</span>
<span class="normal">667</span>
<span class="normal">668</span>
<span class="normal">669</span>
<span class="normal">670</span>
<span class="normal">671</span>
<span class="normal">672</span>
<span class="normal">673</span>
<span class="normal">674</span>
<span class="normal">675</span>
<span class="normal">676</span>
<span class="normal">677</span>
<span class="normal">678</span>
<span class="normal">679</span>
<span class="normal">680</span>
<span class="normal">681</span>
<span class="normal">682</span>
<span class="normal">683</span>
<span class="normal">684</span>
<span class="normal">685</span>
<span class="normal">686</span>
<span class="normal">687</span>
<span class="normal">688</span>
<span class="normal">689</span>
<span class="normal">690</span>
<span class="normal">691</span>
<span class="normal">692</span>
<span class="normal">693</span>
<span class="normal">694</span>
<span class="normal">695</span>
<span class="normal">696</span>
<span class="normal">697</span>
<span class="normal">698</span>
<span class="normal">699</span>
<span class="normal">700</span>
<span class="normal">701</span>
<span class="normal">702</span>
<span class="normal">703</span>
<span class="normal">704</span>
<span class="normal">705</span>
<span class="normal">706</span>
<span class="normal">707</span>
<span class="normal">708</span>
<span class="normal">709</span>
<span class="normal">710</span>
<span class="normal">711</span>
<span class="normal">712</span>
<span class="normal">713</span>
<span class="normal">714</span>
<span class="normal">715</span>
<span class="normal">716</span>
<span class="normal">717</span>
<span class="normal">718</span>
<span class="normal">719</span>
<span class="normal">720</span>
<span class="normal">721</span>
<span class="normal">722</span>
<span class="normal">723</span>
<span class="normal">724</span>
<span class="normal">725</span>
<span class="normal">726</span>
<span class="normal">727</span>
<span class="normal">728</span>
<span class="normal">729</span>
<span class="normal">730</span>
<span class="normal">731</span>
<span class="normal">732</span>
<span class="normal">733</span>
<span class="normal">734</span>
<span class="normal">735</span>
<span class="normal">736</span>
<span class="normal">737</span>
<span class="normal">738</span>
<span class="normal">739</span>
<span class="normal">740</span>
<span class="normal">741</span>
<span class="normal">742</span>
<span class="normal">743</span>
<span class="normal">744</span>
<span class="normal">745</span>
<span class="normal">746</span>
<span class="normal">747</span>
<span class="normal">748</span>
<span class="normal">749</span>
<span class="normal">750</span>
<span class="normal">751</span>
<span class="normal">752</span>
<span class="normal">753</span>
<span class="normal">754</span>
<span class="normal">755</span>
<span class="normal">756</span>
<span class="normal">757</span>
<span class="normal">758</span>
<span class="normal">759</span>
<span class="normal">760</span>
<span class="normal">761</span>
<span class="normal">762</span>
<span class="normal">763</span>
<span class="normal">764</span>
<span class="normal">765</span>
<span class="normal">766</span>
<span class="normal">767</span>
<span class="normal">768</span>
<span class="normal">769</span>
<span class="normal">770</span>
<span class="normal">771</span>
<span class="normal">772</span>
<span class="normal">773</span>
<span class="normal">774</span>
<span class="normal">775</span>
<span class="normal">776</span>
<span class="normal">777</span>
<span class="normal">778</span>
<span class="normal">779</span>
<span class="normal">780</span>
<span class="normal">781</span>
<span class="normal">782</span>
<span class="normal">783</span>
<span class="normal">784</span>
<span class="normal">785</span>
<span class="normal">786</span>
<span class="normal">787</span>
<span class="normal">788</span>
<span class="normal">789</span>
<span class="normal">790</span>
<span class="normal">791</span>
<span class="normal">792</span>
<span class="normal">793</span>
<span class="normal">794</span>
<span class="normal">795</span>
<span class="normal">796</span>
<span class="normal">797</span>
<span class="normal">798</span>
<span class="normal">799</span>
<span class="normal">800</span>
<span class="normal">801</span>
<span class="normal">802</span>
<span class="normal">803</span>
<span class="normal">804</span>
<span class="normal">805</span>
<span class="normal">806</span>
<span class="normal">807</span>
<span class="normal">808</span>
<span class="normal">809</span>
<span class="normal">810</span>
<span class="normal">811</span>
<span class="normal">812</span>
<span class="normal">813</span>
<span class="normal">814</span>
<span class="normal">815</span>
<span class="normal">816</span>
<span class="normal">817</span>
<span class="normal">818</span>
<span class="normal">819</span>
<span class="normal">820</span>
<span class="normal">821</span>
<span class="normal">822</span>
<span class="normal">823</span>
<span class="normal">824</span>
<span class="normal">825</span>
<span class="normal">826</span>
<span class="normal">827</span>
<span class="normal">828</span>
<span class="normal">829</span>
<span class="normal">830</span>
<span class="normal">831</span>
<span class="normal">832</span>
<span class="normal">833</span>
<span class="normal">834</span>
<span class="normal">835</span>
<span class="normal">836</span>
<span class="normal">837</span>
<span class="normal">838</span>
<span class="normal">839</span>
<span class="normal">840</span>
<span class="normal">841</span>
<span class="normal">842</span>
<span class="normal">843</span>
<span class="normal">844</span>
<span class="normal">845</span>
<span class="normal">846</span>
<span class="normal">847</span>
<span class="normal">848</span>
<span class="normal">849</span>
<span class="normal">850</span>
<span class="normal">851</span>
<span class="normal">852</span>
<span class="normal">853</span>
<span class="normal">854</span>
<span class="normal">855</span>
<span class="normal">856</span>
<span class="normal">857</span>
<span class="normal">858</span>
<span class="normal">859</span>
<span class="normal">860</span>
<span class="normal">861</span>
<span class="normal">862</span>
<span class="normal">863</span>
<span class="normal">864</span>
<span class="normal">865</span>
<span class="normal">866</span>
<span class="normal">867</span>
<span class="normal">868</span>
<span class="normal">869</span>
<span class="normal">870</span>
<span class="normal">871</span>
<span class="normal">872</span>
<span class="normal">873</span>
<span class="normal">874</span>
<span class="normal">875</span>
<span class="normal">876</span>
<span class="normal">877</span>
<span class="normal">878</span>
<span class="normal">879</span>
<span class="normal">880</span>
<span class="normal">881</span>
<span class="normal">882</span>
<span class="normal">883</span>
<span class="normal">884</span>
<span class="normal">885</span>
<span class="normal">886</span>
<span class="normal">887</span>
<span class="normal">888</span>
<span class="normal">889</span>
<span class="normal">890</span>
<span class="normal">891</span>
<span class="normal">892</span>
<span class="normal">893</span>
<span class="normal">894</span>
<span class="normal">895</span>
<span class="normal">896</span>
<span class="normal">897</span>
<span class="normal">898</span>
<span class="normal">899</span>
<span class="normal">900</span>
<span class="normal">901</span>
<span class="normal">902</span>
<span class="normal">903</span>
<span class="normal">904</span>
<span class="normal">905</span>
<span class="normal">906</span>
<span class="normal">907</span>
<span class="normal">908</span>
<span class="normal">909</span>
<span class="normal">910</span>
<span class="normal">911</span>
<span class="normal">912</span>
<span class="normal">913</span>
<span class="normal">914</span>
<span class="normal">915</span>
<span class="normal">916</span>
<span class="normal">917</span>
<span class="normal">918</span>
<span class="normal">919</span>
<span class="normal">920</span>
<span class="normal">921</span>
<span class="normal">922</span>
<span class="normal">923</span>
<span class="normal">924</span>
<span class="normal">925</span>
<span class="normal">926</span>
<span class="normal">927</span>
<span class="normal">928</span>
<span class="normal">929</span>
<span class="normal">930</span>
<span class="normal">931</span>
<span class="normal">932</span>
<span class="normal">933</span>
<span class="normal">934</span>
<span class="normal">935</span>
<span class="normal">936</span>
<span class="normal">937</span>
<span class="normal">938</span>
<span class="normal">939</span>
<span class="normal">940</span>
<span class="normal">941</span>
<span class="normal">942</span>
<span class="normal">943</span>
<span class="normal">944</span>
<span class="normal">945</span>
<span class="normal">946</span>
<span class="normal">947</span>
<span class="normal">948</span>
<span class="normal">949</span>
<span class="normal">950</span>
<span class="normal">951</span>
<span class="normal">952</span>
<span class="normal">953</span>
<span class="normal">954</span>
<span class="normal">955</span>
<span class="normal">956</span>
<span class="normal">957</span>
<span class="normal">958</span>
<span class="normal">959</span>
<span class="normal">960</span>
<span class="normal">961</span>
<span class="normal">962</span>
<span class="normal">963</span>
<span class="normal">964</span>
<span class="normal">965</span>
<span class="normal">966</span>
<span class="normal">967</span>
<span class="normal">968</span>
<span class="normal">969</span>
<span class="normal">970</span>
<span class="normal">971</span>
<span class="normal">972</span>
<span class="normal">973</span>
<span class="normal">974</span>
<span class="normal">975</span>
<span class="normal">976</span>
<span class="normal">977</span>
<span class="normal">978</span>
<span class="normal">979</span>
<span class="normal">980</span>
<span class="normal">981</span>
<span class="normal">982</span>
<span class="normal">983</span>
<span class="normal">984</span>
<span class="normal">985</span>
<span class="normal">986</span>
<span class="normal">987</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">Convolution</span><span class="p">(</span><span class="n">Projection</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Performs a convolution of a weight kernel on the pre-synaptic population.</span>

<span class="sd">    Despite its name, the operation performed is actually a cross-correlation, as is usual in computer vision and convolutional neural networks:</span>

<span class="sd">    $$g(x) = \sum_{k=-n}^n h(k) \, f(x + k)$$</span>

<span class="sd">    The convolution operation benefits from giving a multi-dimensional geometry to the populations and filters, for example in 2D:</span>

<span class="sd">    ```python</span>
<span class="sd">    inp = Population(geometry=(100, 100), neuron=Neuron(parameters=&quot;r = 0.0&quot;))</span>
<span class="sd">    pop = Population(geometry=(100, 100), neuron=Neuron(equations=&quot;r = sum(exc)&quot;))</span>
<span class="sd">    proj = Convolution(inp, pop, &#39;exc&#39;)</span>
<span class="sd">    proj.connect_filter(</span>
<span class="sd">        [</span>
<span class="sd">            [-1., 0., 1.],</span>
<span class="sd">            [-1., 0., 1.],</span>
<span class="sd">            [-1., 0., 1.]</span>
<span class="sd">        ])</span>
<span class="sd">    ```</span>

<span class="sd">    The maximum number of dimensions for populations and filters is 4, an error is thrown otherwise.</span>

<span class="sd">    Depending on the number of dimensions of the pre- and post-synaptic populations, as well as of the kernel, the convolution is implemented differentely.</span>

<span class="sd">    **Method connect_filter()**</span>

<span class="sd">    * If the pre- and post-populations have the same dimension as the kernel, the convolution is regular. Example:</span>

<span class="sd">        (100, 100) * (3, 3) -&gt; (100, 100)</span>

<span class="sd">    * If the post-population has one dimension less than the pre-synaptic one, the last dimension of the kernel must match the last one of the pre-synaptic population. Example:</span>

<span class="sd">        (100, 100, 3) * (3, 3, 3) -&gt; (100, 100)</span>

<span class="sd">    * If the kernel has less dimensions than the two populations, the number of neurons in the last dimension of the populations must be the same. The convolution will be calculated for each feature map in the last dimension. In this case, you must set ``keep_last_dimension`` to ``True``. Example:</span>

<span class="sd">        (100, 100, 16) * (3, 3) -&gt; (100, 100, 16)</span>

<span class="sd">    **Method connect_filters()**</span>

<span class="sd">    * If the kernel has more dimensions than the pre-synaptic population, this means a bank of different filters will be applied on the pre-synaptic population (like a convolutional layer in a CNN). Attention: the first index of ``weights`` corresponds to the different filters, while the result will be accessible in the last dimension of the post-synaptic population. You must set the ``multiple`` argument to True. Example:</span>

<span class="sd">        (100, 100) * (16, 3, 3) -&gt; (100, 100, 16)</span>

<span class="sd">    The convolution **always** uses padding for elements that would be outside the array (no equivalent of ``valid`` in tensorflow). It is 0.0 by default, but can be changed using the ``padding`` argument. Setting ``padding`` to the string ``border`` will repeat the value of the border elements.</span>

<span class="sd">    Sub-sampling will be automatically performed according to the populations&#39; geometry. If these geometries do not match, an error will be thrown. Example:</span>

<span class="sd">        (100, 100) * (3, 3) -&gt; (50, 50)</span>

<span class="sd">    You can redefine the sub-sampling by providing a list ``subsampling`` as argument, defining for each post-synaptic neuron the coordinates of the pre-synaptic neuron which will be the center of the filter/kernel.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pre</span><span class="p">,</span> <span class="n">post</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">psp</span><span class="o">=</span><span class="s2">&quot;pre.r * w&quot;</span><span class="p">,</span> <span class="n">operation</span><span class="o">=</span><span class="s2">&quot;sum&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">copied</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :param pre: pre-synaptic population (either its name or a ``Population`` object).</span>
<span class="sd">        :param post: post-synaptic population (either its name or a ``Population`` object).</span>
<span class="sd">        :param target: type of the connection</span>
<span class="sd">        :param psp: continuous influence of a single synapse on the post-synaptic neuron (default for rate-coded: ``w*pre.r``).</span>
<span class="sd">        :param operation: operation (sum, max, min, mean) performed by the kernel (default: sum).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Sanity check</span>
        <span class="c1">#if not pre.neuron_type.type == &#39;rate&#39;:</span>
        <span class="c1">#    Global._error(&#39;Convolution: only implemented for rate-coded populations.&#39;)</span>

        <span class="c1"># Create the description, but it will not be used for generation</span>
        <span class="n">Projection</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="n">pre</span><span class="p">,</span>
            <span class="n">post</span><span class="p">,</span>
            <span class="n">target</span><span class="p">,</span>
            <span class="n">synapse</span><span class="o">=</span><span class="n">SharedSynapse</span><span class="p">(</span><span class="n">psp</span><span class="o">=</span><span class="n">psp</span><span class="p">,</span> <span class="n">operation</span><span class="o">=</span><span class="n">operation</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;Convolution operation&quot;</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Convoluted kernel over the pre-synaptic population.&quot;</span><span class="p">),</span>
            <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
            <span class="n">copied</span><span class="o">=</span><span class="n">copied</span>
        <span class="p">)</span>

        <span class="c1"># Disable saving</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_saveable</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="c1"># For copy</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_used_single_filter</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_used_bank_of_filters</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">operation</span> <span class="o">=</span> <span class="n">operation</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">weights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">initialized</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">init</span><span class="p">[</span><span class="s2">&quot;weights&quot;</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">cyInstance</span><span class="o">.</span><span class="n">get_w</span><span class="p">()</span>

    <span class="nd">@weights</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">initialized</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">init</span><span class="p">[</span><span class="s2">&quot;weights&quot;</span><span class="p">]</span><span class="o">=</span><span class="n">value</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_kernel</span> <span class="o">!=</span> <span class="n">value</span><span class="o">.</span><span class="n">ndim</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span><span class="s2">&quot;Mismatch between filter dimensions&quot;</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">cyInstance</span><span class="o">.</span><span class="n">set_w</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">connect_filter</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">delays</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">keep_last_dimension</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">subsampling</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Applies a single filter on the pre-synaptic population.</span>

<span class="sd">        :param weights: numpy array or list of lists representing the matrix of weights for the filter.</span>
<span class="sd">        :param delays: delay in synaptic transmission (default: dt). Can only be the same value for all neurons.</span>
<span class="sd">        :param keep_last_dimension: defines if the last dimension of the pre- and post-synaptic will be convolved in parallel. The weights matrix must have one dimension less than the pre-synaptic population, and the number of neurons in the last dimension of the pre- and post-synaptic populations must match. Default: False.</span>
<span class="sd">        :param padding: value to be used for the rates outside the pre-synaptic population. If it is a floating value, the pre-synaptic population is virtually extended with this value above its boundaries. If it is equal to &#39;border&#39;, the values on the boundaries are repeated. Default: 0.0.</span>
<span class="sd">        :param subsampling: list for each post-synaptic neuron of coordinates in the pre-synaptic population defining the center of the kernel/filter. Default: None.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Process the weights</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>

        <span class="c1"># Process the delays</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">delays</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">delays</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">delays</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">)):</span>
            <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s1">&#39;Convolutions can only have constant delays.&#39;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">subsampling</span> <span class="o">=</span> <span class="n">subsampling</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">keep_last_dimension</span> <span class="o">=</span> <span class="n">keep_last_dimension</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">padding</span> <span class="o">=</span> <span class="n">padding</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">multiple</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="c1"># Check dimensions of populations and weight matrix</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dim_kernel</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="o">.</span><span class="n">ndim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dim_pre</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">dimension</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dim_post</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">dimension</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_post</span> <span class="o">&gt;</span> <span class="mi">4</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Convolution:&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_pre</span><span class="p">,</span> <span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_kernel</span><span class="p">,</span> <span class="s1">&#39;-&gt;&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_post</span><span class="p">)</span>
            <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s1">&#39;Convolution: Too many dimensions for the post-synaptic population (maximum 4).&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_pre</span> <span class="o">&gt;</span> <span class="mi">4</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Convolution:&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_pre</span><span class="p">,</span> <span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_kernel</span><span class="p">,</span> <span class="s1">&#39;-&gt;&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_post</span><span class="p">)</span>
            <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s1">&#39;Convolution: Too many dimensions for the pre-synaptic population (maximum 4).&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_kernel</span> <span class="o">&gt;</span> <span class="mi">5</span>  <span class="ow">or</span> <span class="p">(</span><span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">multiple</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_kernel</span> <span class="o">&gt;</span> <span class="mi">4</span><span class="p">):</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Convolution:&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_pre</span><span class="p">,</span> <span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_kernel</span><span class="p">,</span> <span class="s1">&#39;-&gt;&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_post</span><span class="p">)</span>
            <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s1">&#39;Convolution: Too many dimensions for the kernel (maximum 4).&#39;</span><span class="p">)</span>

        <span class="c1"># Check if the last axes match for parallel convolution (e.g. 3-2-3)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_kernel</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_pre</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">keep_last_dimension</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Convolution:&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_pre</span><span class="p">,</span> <span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_kernel</span><span class="p">,</span> <span class="s1">&#39;-&gt;&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_post</span><span class="p">)</span>
                <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s1">&#39;Convolution: If the kernel has less dimensions than the pre-synaptic population, you need to set the flag keep_last_dimension to True.&#39;</span><span class="p">)</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">geometry</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">geometry</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Convolution:&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_pre</span><span class="p">,</span> <span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_kernel</span><span class="p">,</span> <span class="s1">&#39;-&gt;&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_post</span><span class="p">)</span>
                <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s1">&#39;Convolution: If the kernel has fewer dimensions than the two populations (keep_last_dimension=True), these must have the same number of neurons in the last dimension.&#39;</span><span class="p">)</span>

        <span class="c1"># If the last dim of the kernel matches the last dim of the pre-pop, the last pop can have one dimension less.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_post</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_pre</span><span class="p">:</span> <span class="c1"># OK, but check the last dimension of the kernel has the same size as the post-population</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">geometry</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Convolution:&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_pre</span><span class="p">,</span> <span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_kernel</span><span class="p">,</span> <span class="s1">&#39;-&gt;&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_post</span><span class="p">)</span>
                <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s1">&#39;Convolution: If the post-synaptic population has less dimensions than the pre-synaptic one, the last dimension of the filter must be equal to the last of the pre-synaptic population.&#39;</span><span class="p">)</span>

        <span class="c1"># Check if it is a bank of filters</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_kernel</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_pre</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Convolution:&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_pre</span><span class="p">,</span> <span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_kernel</span><span class="p">,</span> <span class="s1">&#39;-&gt;&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_post</span><span class="p">)</span>
            <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s1">&#39;Convolution: If the kernel has more dimensions than the pre-synaptic population, you need to use the connect_filters() method.&#39;</span><span class="p">)</span>


        <span class="c1"># Generate the pre-synaptic coordinates</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_generate_pre_coordinates</span><span class="p">()</span>

        <span class="c1"># Finish building the synapses</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_create</span><span class="p">()</span>

        <span class="c1"># For copy</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_used_single_filter</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="k">return</span> <span class="bp">self</span>


    <span class="k">def</span> <span class="nf">connect_filters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">delays</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">keep_last_dimension</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">subsampling</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Applies a set of different filters on the pre-synaptic population.</span>

<span class="sd">        The weights matrix must have one dimension more than the pre-synaptic populations, and the number of neurons in the last dimension of the post-synaptic population must be equal to the number of filters.</span>


<span class="sd">        :param weights: numpy array or list of lists representing the matrix of weights for the filter.</span>
<span class="sd">        :param delays: delay in synaptic transmission (default: dt). Can only be the same value for all neurons.</span>
<span class="sd">        :param keep_last_dimension: defines if the last dimension of the pre- and post-synaptic will be convolved in parallel. The weights matrix must have one dimension less than the pre-synaptic population, and the number of neurons in the last dimension of the pre- and post-synaptic populations must match. Default: False.</span>
<span class="sd">        :param padding: value to be used for the rates outside the pre-synaptic population. If it is a floating value, the pre-synaptic population is virtually extended with this value above its boundaries. If it is equal to &#39;border&#39;, the values on the boundaries are repeated. Default: 0.0.</span>
<span class="sd">        :param subsampling: list for each post-synaptic neuron of coordinates in the pre-synaptic population defining the center of the kernel/filter. Default: None.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Process the weights</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>

        <span class="c1"># Process the delays</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">delays</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">delays</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">delays</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">)):</span>
            <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s1">&#39;Convolutions can only have constant delays.&#39;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">subsampling</span> <span class="o">=</span> <span class="n">subsampling</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">keep_last_dimension</span> <span class="o">=</span> <span class="n">keep_last_dimension</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">padding</span> <span class="o">=</span> <span class="n">padding</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">multiple</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="c1"># Check dimensions of populations and weight matrix</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dim_kernel</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="o">.</span><span class="n">ndim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dim_pre</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">dimension</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dim_post</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">dimension</span>


        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_post</span> <span class="o">&gt;</span> <span class="mi">4</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Convolution:&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_pre</span><span class="p">,</span> <span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_kernel</span><span class="p">,</span> <span class="s1">&#39;-&gt;&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_post</span><span class="p">)</span>
            <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s1">&#39;Convolution: Too many dimensions for the post-synaptic population (maximum 4).&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_pre</span> <span class="o">&gt;</span> <span class="mi">4</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Convolution:&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_pre</span><span class="p">,</span> <span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_kernel</span><span class="p">,</span> <span class="s1">&#39;-&gt;&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_post</span><span class="p">)</span>
            <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s1">&#39;Convolution: Too many dimensions for the pre-synaptic population (maximum 4).&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_kernel</span> <span class="o">&gt;</span> <span class="mi">5</span>  <span class="ow">or</span> <span class="p">(</span><span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">multiple</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_kernel</span> <span class="o">&gt;</span> <span class="mi">4</span><span class="p">):</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Convolution:&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_pre</span><span class="p">,</span> <span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_kernel</span><span class="p">,</span> <span class="s1">&#39;-&gt;&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_post</span><span class="p">)</span>
            <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s1">&#39;Convolution: Too many dimensions for the kernel (maximum 4).&#39;</span><span class="p">)</span>

        <span class="c1"># Check if the last axes match for parallel convolution (e.g. 3-2-3)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_kernel</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_pre</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">keep_last_dimension</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Convolution:&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_pre</span><span class="p">,</span> <span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_kernel</span><span class="p">,</span> <span class="s1">&#39;-&gt;&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_post</span><span class="p">)</span>
                <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s1">&#39;Convolution: If the kernel has less dimensions than the pre-synaptic population, you need to set the flag keep_last_dimension to True.&#39;</span><span class="p">)</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">geometry</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">geometry</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Convolution:&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_pre</span><span class="p">,</span> <span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_kernel</span><span class="p">,</span> <span class="s1">&#39;-&gt;&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_post</span><span class="p">)</span>
                <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s1">&#39;Convolution: If the kernel has fewer dimensions than the two populations (keep_last_dimension=True), these must have the same number of neurons in the last dimension.&#39;</span><span class="p">)</span>

        <span class="c1"># If the last dim of the kernel matches the last dim of the pre-pop, the last pop can have one dimension less.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_post</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_pre</span><span class="p">:</span> <span class="c1"># OK, but check the last dimension of the kernel has the same size as the post-population</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">geometry</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Convolution:&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_pre</span><span class="p">,</span> <span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_kernel</span><span class="p">,</span> <span class="s1">&#39;-&gt;&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_post</span><span class="p">)</span>
                <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s1">&#39;Convolution: If the post-synaptic population has less dimensions than the pre-synaptic one, the last dimension of the filter must be equal to the last of the pre-synaptic population.&#39;</span><span class="p">)</span>

        <span class="c1"># The last dimension of the post population must correspond to the number of filters</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">geometry</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Convolution:&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_pre</span><span class="p">,</span> <span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_kernel</span><span class="p">,</span> <span class="s1">&#39;-&gt;&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_post</span><span class="p">)</span>
            <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s1">&#39;Convolution: For multiple filters, the last dimension of the post-synaptic population must have as many neurons as there are filters.&#39;</span><span class="p">)</span>

        <span class="c1"># Generate the pre-synaptic coordinates</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_generate_pre_coordinates_bank</span><span class="p">()</span>

        <span class="c1"># Finish building the synapses</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_create</span><span class="p">()</span>

        <span class="c1"># For copy</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_used_bank_of_filters</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">_copy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pre</span><span class="p">,</span> <span class="n">post</span><span class="p">):</span>
        <span class="s2">&quot;Returns a copy of the projection when creating networks.  Internal use only.&quot;</span>
        <span class="n">copied_proj</span> <span class="o">=</span> <span class="n">Convolution</span><span class="p">(</span><span class="n">pre</span><span class="o">=</span><span class="n">pre</span><span class="p">,</span> <span class="n">post</span><span class="o">=</span><span class="n">post</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="p">,</span>
                                  <span class="n">psp</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">synapse_type</span><span class="o">.</span><span class="n">psp</span><span class="p">,</span> <span class="n">operation</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">operation</span><span class="p">,</span>
                                  <span class="n">name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">copied</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="n">copied_proj</span><span class="o">.</span><span class="n">delays</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">delays</span>
        <span class="n">copied_proj</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span>

        <span class="n">copied_proj</span><span class="o">.</span><span class="n">subsampling</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">subsampling</span>
        <span class="n">copied_proj</span><span class="o">.</span><span class="n">keep_last_dimension</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">keep_last_dimension</span>
        <span class="n">copied_proj</span><span class="o">.</span><span class="n">padding</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding</span>
        <span class="n">copied_proj</span><span class="o">.</span><span class="n">multiple</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">multiple</span>
        <span class="n">copied_proj</span><span class="o">.</span><span class="n">dim_kernel</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="o">.</span><span class="n">ndim</span>
        <span class="n">copied_proj</span><span class="o">.</span><span class="n">dim_pre</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">dimension</span>
        <span class="n">copied_proj</span><span class="o">.</span><span class="n">dim_post</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">dimension</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_used_single_filter</span><span class="p">:</span>
            <span class="n">copied_proj</span><span class="o">.</span><span class="n">_generate_pre_coordinates</span><span class="p">()</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_used_bank_of_filters</span><span class="p">:</span>
            <span class="n">copied_proj</span><span class="o">.</span><span class="n">_generate_pre_coordinates_bank</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Either use single filter or bank of filter must be True! (Missing connect?)&quot;</span><span class="p">)</span>

        <span class="n">copied_proj</span><span class="o">.</span><span class="n">_create</span><span class="p">()</span>
        <span class="n">copied_proj</span><span class="o">.</span><span class="n">_connection_method</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_connection_method</span>
        <span class="n">copied_proj</span><span class="o">.</span><span class="n">_connection_args</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_connection_args</span>
        <span class="n">copied_proj</span><span class="o">.</span><span class="n">_connection_delay</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_connection_delay</span>
        <span class="n">copied_proj</span><span class="o">.</span><span class="n">_storage_format</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_storage_format</span>
        <span class="k">return</span> <span class="n">copied_proj</span>

    <span class="k">def</span> <span class="nf">_create</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># create fake LIL object, just for compilation.</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="kn">from</span> <span class="nn">ANNarchy.core.cython_ext.Connector</span> <span class="kn">import</span> <span class="n">LILConnectivity</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">Global</span><span class="o">.</span><span class="n">_print</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
            <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s1">&#39;ANNarchy was not successfully installed.&#39;</span><span class="p">)</span>

        <span class="n">lil</span> <span class="o">=</span> <span class="n">LILConnectivity</span><span class="p">()</span>
        <span class="n">lil</span><span class="o">.</span><span class="n">max_delay</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">delays</span>
        <span class="n">lil</span><span class="o">.</span><span class="n">uniform_delay</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">delays</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">connector_name</span> <span class="o">=</span> <span class="s2">&quot;Convolution&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">connector_description</span> <span class="o">=</span> <span class="s2">&quot;Convolution&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_store_connectivity</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_load_from_lil</span><span class="p">,</span> <span class="p">(</span><span class="n">lil</span><span class="p">,</span> <span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">delays</span><span class="p">,</span> <span class="n">storage_format</span><span class="o">=</span><span class="s2">&quot;lil&quot;</span><span class="p">,</span> <span class="n">storage_order</span><span class="o">=</span><span class="s2">&quot;post_to_pre&quot;</span><span class="p">)</span>

    <span class="c1">################################</span>
    <span class="c1">### Create connection pattern</span>
    <span class="c1">################################</span>
    <span class="k">def</span> <span class="nf">_connect</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">module</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Builds up dendrites either from list or dictionary. Called by instantiate().</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_connection_method</span><span class="p">:</span>
            <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s1">&#39;Convolution: The projection between &#39;</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39; and &#39;</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39; is declared but not connected.&#39;</span><span class="p">)</span>

        <span class="c1"># Create the Cython instance</span>
        <span class="n">proj</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="s1">&#39;proj&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">id</span><span class="p">)</span><span class="o">+</span><span class="s1">&#39;_wrapper&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cyInstance</span> <span class="o">=</span> <span class="n">proj</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre_coordinates</span><span class="p">)</span>

        <span class="c1"># Set delays after instantiation</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">delays</span> <span class="o">&gt;</span> <span class="mf">0.0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">cyInstance</span><span class="o">.</span><span class="n">set_delay</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">delays</span><span class="o">/</span><span class="n">Global</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;dt&#39;</span><span class="p">])</span>

        <span class="k">return</span> <span class="kc">True</span>

    <span class="k">def</span> <span class="nf">_generate_pre_coordinates</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="s2">&quot; Returns a list for each post neuron of the corresponding center coordinates.&quot;</span>

        <span class="c1"># Check if the list is already defined:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">subsampling</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">shape</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">subsampling</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
            <span class="k">except</span><span class="p">:</span>
                <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s1">&#39;Convolution: The sub-sampling list must have&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="s1">&#39;elements of size&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">dimension</span><span class="p">)</span>
                <span class="k">return</span>
            <span class="k">if</span> <span class="n">shape</span> <span class="o">!=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">dimension</span><span class="p">):</span>
                <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s1">&#39;Convolution: The sub-sampling list must have&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="s1">&#39;elements of size&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">dimension</span><span class="p">)</span>
                <span class="k">return</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pre_coordinates</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">subsampling</span>
            <span class="k">return</span>

        <span class="c1"># Otherwise create it, possibly with sub-sampling</span>
        <span class="n">coords</span> <span class="o">=</span> <span class="p">[[]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">size</span><span class="p">)]</span>

        <span class="c1"># Compute pre-indices</span>
        <span class="n">idx_range</span><span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">dim</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dim_pre</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">dim</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_post</span><span class="p">:</span>
                <span class="n">pre_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">geometry</span><span class="p">[</span><span class="n">dim</span><span class="p">])</span>
                <span class="n">post_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">geometry</span><span class="p">[</span><span class="n">dim</span><span class="p">])</span>
                <span class="n">sample</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">pre_size</span><span class="o">/</span><span class="n">post_size</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">post_size</span> <span class="o">*</span> <span class="n">sample</span> <span class="o">!=</span> <span class="n">pre_size</span><span class="p">:</span>
                    <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s1">&#39;Convolution: The pre-synaptic dimensions must be a multiple of the post-synaptic ones for down-sampling to work.&#39;</span><span class="p">)</span>

                <span class="n">idx_range</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="nb">int</span><span class="p">((</span><span class="n">sample</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="n">sample</span> <span class="o">*</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">post_size</span><span class="p">)])</span>
            <span class="k">else</span><span class="p">:</span> <span class="c1"># extra dimension</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">keep_last_dimension</span><span class="p">:</span>
                    <span class="n">idx_range</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">geometry</span><span class="p">[</span><span class="n">dim</span><span class="p">]))</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">idx_range</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">_center_filter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">dim</span><span class="p">])])</span>

        <span class="c1"># Generates coordinates TODO: Find a more robust way!</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_pre</span> <span class="o">==</span> <span class="mi">1</span> <span class="p">:</span>
            <span class="n">rk</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">idx_range</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
                <span class="n">coords</span><span class="p">[</span><span class="n">rk</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="n">rk</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_pre</span> <span class="o">==</span> <span class="mi">2</span> <span class="p">:</span>
            <span class="n">rk</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">idx_range</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
                <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">idx_range</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
                    <span class="n">coords</span><span class="p">[</span><span class="n">rk</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span>
                    <span class="n">rk</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_pre</span> <span class="o">==</span> <span class="mi">3</span> <span class="p">:</span>
            <span class="n">rk</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">idx_range</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
                <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">idx_range</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
                    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">idx_range</span><span class="p">[</span><span class="mi">2</span><span class="p">]:</span>
                        <span class="n">coords</span><span class="p">[</span><span class="n">rk</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span>
                        <span class="n">rk</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_pre</span> <span class="o">==</span> <span class="mi">4</span> <span class="p">:</span>
            <span class="n">rk</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">idx_range</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
                <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">idx_range</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
                    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">idx_range</span><span class="p">[</span><span class="mi">2</span><span class="p">]:</span>
                        <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">idx_range</span><span class="p">[</span><span class="mi">3</span><span class="p">]:</span>
                            <span class="n">coords</span><span class="p">[</span><span class="n">rk</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">l</span><span class="p">]</span>
                            <span class="n">rk</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="c1"># Save the result</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pre_coordinates</span> <span class="o">=</span> <span class="n">coords</span>

    <span class="k">def</span> <span class="nf">_generate_pre_coordinates_bank</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="s2">&quot; Returns a list for each post neuron of the corresponding center coordinates, when the filter is a bank.&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">nb_filters</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dim_single_filter</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>

        <span class="c1"># Check if the list is already defined:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">subsampling</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">shape</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">subsampling</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
            <span class="k">except</span><span class="p">:</span>
                <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s1">&#39;Convolution: The sub-sampling list must have&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">size</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">geometry</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;elements of size&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">dimension</span><span class="p">)</span>
                <span class="k">return</span>
            <span class="k">if</span> <span class="n">shape</span> <span class="o">!=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">size</span><span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">geometry</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">dimension</span><span class="p">):</span>
                <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s1">&#39;Convolution: The sub-sampling list must have&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">size</span><span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">geometry</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;elements of size&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">dimension</span><span class="p">)</span>
                <span class="k">return</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pre_coordinates</span> <span class="o">=</span> <span class="p">[</span><span class="n">c</span> <span class="o">+</span> <span class="p">[</span><span class="n">d</span><span class="p">]</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">subsampling</span>  <span class="k">for</span> <span class="n">d</span>  <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nb_filters</span><span class="p">)]</span>
            <span class="k">return</span>

        <span class="c1"># Otherwise create it, possibly with sub-sampling</span>
        <span class="n">coords</span> <span class="o">=</span> <span class="p">[[]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">size</span><span class="p">)]</span>

        <span class="c1"># Compute pre-indices</span>
        <span class="n">idx_range</span><span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">dim</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dim_pre</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">dim</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_post</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
                <span class="n">pre_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">geometry</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span>
                <span class="n">post_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">geometry</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span>
                <span class="n">sample</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">pre_size</span><span class="o">/</span><span class="n">post_size</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">post_size</span> <span class="o">*</span> <span class="n">sample</span> <span class="o">!=</span> <span class="n">pre_size</span><span class="p">:</span>
                    <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s1">&#39;Convolution: The pre-synaptic dimensions must be a multiple of the post-synaptic ones for down-sampling to work.&#39;</span><span class="p">)</span>

                <span class="n">idx_range</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="nb">int</span><span class="p">((</span><span class="n">sample</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="n">sample</span> <span class="o">*</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">post_size</span><span class="p">)])</span>
            <span class="k">else</span><span class="p">:</span> <span class="c1"># extra dimension</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">keep_last_dimension</span><span class="p">:</span>
                    <span class="n">idx_range</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">geometry</span><span class="p">[</span><span class="n">dim</span><span class="p">]))</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">idx_range</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">_center_filter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">dim</span><span class="o">+</span><span class="mi">1</span><span class="p">])])</span>


        <span class="c1"># Generates coordinates TODO: Find a more robust way!</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_pre</span> <span class="o">==</span> <span class="mi">1</span> <span class="p">:</span>
            <span class="n">rk</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">idx_range</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
                <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nb_filters</span><span class="p">):</span>
                    <span class="n">coords</span><span class="p">[</span><span class="n">rk</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">d</span><span class="p">]</span>
                    <span class="n">rk</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_pre</span> <span class="o">==</span> <span class="mi">2</span> <span class="p">:</span>
            <span class="n">rk</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">idx_range</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
                <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">idx_range</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
                    <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nb_filters</span><span class="p">):</span>
                        <span class="n">coords</span><span class="p">[</span><span class="n">rk</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">d</span> <span class="p">]</span>
                        <span class="n">rk</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_pre</span> <span class="o">==</span> <span class="mi">3</span> <span class="p">:</span>
            <span class="n">rk</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">idx_range</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
                <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">idx_range</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
                    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">idx_range</span><span class="p">[</span><span class="mi">2</span><span class="p">]:</span>
                        <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nb_filters</span><span class="p">):</span>
                            <span class="n">coords</span><span class="p">[</span><span class="n">rk</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">d</span><span class="p">]</span>
                            <span class="n">rk</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_pre</span> <span class="o">==</span> <span class="mi">4</span> <span class="p">:</span>
            <span class="n">rk</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">idx_range</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
                <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">idx_range</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
                    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">idx_range</span><span class="p">[</span><span class="mi">2</span><span class="p">]:</span>
                        <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">idx_range</span><span class="p">[</span><span class="mi">3</span><span class="p">]:</span>
                            <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nb_filters</span><span class="p">):</span>
                                <span class="n">coords</span><span class="p">[</span><span class="n">rk</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">l</span><span class="p">,</span> <span class="n">d</span><span class="p">]</span>
                                <span class="n">rk</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="c1"># Save the result</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pre_coordinates</span> <span class="o">=</span> <span class="n">coords</span>

    <span class="c1">################################</span>
    <span class="c1"># Code generation</span>
    <span class="c1">################################</span>
    <span class="k">def</span> <span class="nf">_generate</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overrides default code generation. This function is called during the code generation procedure.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Filter definition</span>
        <span class="n">filter_definition</span><span class="p">,</span> <span class="n">filter_pyx_definition</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_filter_definition</span><span class="p">()</span>

        <span class="c1"># Convolve_code</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">multiple</span><span class="p">:</span>
            <span class="n">convolve_code</span><span class="p">,</span> <span class="n">sum_code</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generate_convolve_code</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">convolve_code</span><span class="p">,</span> <span class="n">sum_code</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generate_bank_code</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">Global</span><span class="o">.</span><span class="n">_check_paradigm</span><span class="p">(</span><span class="s2">&quot;openmp&quot;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_generate_omp</span><span class="p">(</span><span class="n">filter_definition</span><span class="p">,</span> <span class="n">filter_pyx_definition</span><span class="p">,</span> <span class="n">convolve_code</span><span class="p">,</span> <span class="n">sum_code</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">Global</span><span class="o">.</span><span class="n">_check_paradigm</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">):</span>
            <span class="k">raise</span> <span class="n">Global</span><span class="o">.</span><span class="n">ANNarchyException</span><span class="p">(</span><span class="s2">&quot;Convolution is not available on CUDA devices yet.&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="k">def</span> <span class="nf">_generate_omp</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filter_definition</span><span class="p">,</span> <span class="n">filter_pyx_definition</span><span class="p">,</span> <span class="n">convolve_code</span><span class="p">,</span> <span class="n">sum_code</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        OpenMP code generation.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Basic ids</span>
        <span class="n">base_ids</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;id_proj&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">id</span><span class="p">,</span>
            <span class="s1">&#39;size_post&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">size</span><span class="p">,</span>
            <span class="s1">&#39;float_prec&#39;</span><span class="p">:</span> <span class="n">Global</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;precision&#39;</span><span class="p">]</span>
        <span class="p">}</span>

        <span class="c1"># Fill the basic definitions</span>
        <span class="n">conv_dict</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">convole_template_omp</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">conv_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">value</span> <span class="o">=</span> <span class="n">value</span> <span class="o">%</span> <span class="n">base_ids</span>
            <span class="n">conv_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_specific_template</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">conv_dict</span><span class="p">)</span>

        <span class="c1"># Kernel-based method: specify w with the correct dimension</span>
        <span class="k">if</span> <span class="n">kernel</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_specific_template</span><span class="p">[</span><span class="s1">&#39;declare_parameters_variables&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tabify</span><span class="p">(</span><span class="n">filter_definition</span><span class="o">.</span><span class="n">strip</span><span class="p">(),</span> <span class="mi">1</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_specific_template</span><span class="p">[</span><span class="s1">&#39;export_parameters_variables&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_specific_template</span><span class="p">[</span><span class="s1">&#39;access_parameters_variables&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">    // Local parameter w</span>
<span class="s2">    </span><span class="si">%(type_w)s</span><span class="s2"> get_w() { return w; }</span>
<span class="s2">    void set_w(</span><span class="si">%(type_w)s</span><span class="s2"> value) { w = value; }</span>
<span class="s2">&quot;&quot;&quot;</span> <span class="o">%</span> <span class="p">{</span><span class="s1">&#39;type_w&#39;</span><span class="p">:</span> <span class="n">filter_definition</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39; w;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)}</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_specific_template</span><span class="p">[</span><span class="s1">&#39;export_connectivity&#39;</span><span class="p">]</span> <span class="o">+=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">        # Local variable w</span>
<span class="s2">        </span><span class="si">%(type_w)s</span><span class="s2"> get_w()</span>
<span class="s2">        void set_w(</span><span class="si">%(type_w)s</span><span class="s2">)</span>
<span class="s2">&quot;&quot;&quot;</span> <span class="o">%</span> <span class="p">{</span><span class="s1">&#39;type_w&#39;</span><span class="p">:</span> <span class="n">filter_pyx_definition</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39; w&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)}</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_specific_template</span><span class="p">[</span><span class="s1">&#39;wrapper_init_connectivity&#39;</span><span class="p">]</span> <span class="o">+=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">        proj</span><span class="si">%(id_proj)s</span><span class="s2">.set_w(weights)</span>
<span class="s2">&quot;&quot;&quot;</span> <span class="o">%</span> <span class="p">{</span><span class="s1">&#39;id_proj&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">id</span><span class="p">}</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_specific_template</span><span class="p">[</span><span class="s1">&#39;wrapper_access_connectivity&#39;</span><span class="p">]</span> <span class="o">+=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">    # Local variable w</span>
<span class="s2">    def get_w(self):</span>
<span class="s2">        return proj</span><span class="si">%(id_proj)s</span><span class="s2">.get_w()</span>
<span class="s2">    def set_w(self, value):</span>
<span class="s2">        proj</span><span class="si">%(id_proj)s</span><span class="s2">.set_w( value )</span>
<span class="s2">    def get_dendrite_w(self, int rank):</span>
<span class="s2">        return proj</span><span class="si">%(id_proj)s</span><span class="s2">.get_w()</span>
<span class="s2">    def set_dendrite_w(self, int rank, value):</span>
<span class="s2">        proj</span><span class="si">%(id_proj)s</span><span class="s2">.set_w(value)</span>
<span class="s2">    def get_synapse_w(self, int rank_post, int rank_pre):</span>
<span class="s2">        return 0.0</span>
<span class="s2">    def set_synapse_w(self, int rank_post, int rank_pre, </span><span class="si">%(float_prec)s</span><span class="s2"> value):</span>
<span class="s2">        pass</span>
<span class="s2">&quot;&quot;&quot;</span> <span class="o">%</span> <span class="p">{</span><span class="s1">&#39;id_proj&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">id</span><span class="p">,</span> <span class="s1">&#39;float_prec&#39;</span><span class="p">:</span> <span class="n">Global</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;precision&#39;</span><span class="p">]}</span>

        <span class="c1"># Override the monitor to avoid recording the weights</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_specific_template</span><span class="p">[</span><span class="s1">&#39;monitor_class&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_specific_template</span><span class="p">[</span><span class="s1">&#39;monitor_export&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_specific_template</span><span class="p">[</span><span class="s1">&#39;monitor_wrapper&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>

        <span class="c1"># OMP code</span>
        <span class="n">omp_code</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
        <span class="k">if</span> <span class="n">Global</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;num_threads&#39;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">omp_code</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">        #pragma omp for private(sum, rk_pre, coord) </span><span class="si">%(psp_schedule)s</span><span class="s2">&quot;&quot;&quot;</span> <span class="o">%</span> <span class="p">{</span><span class="s1">&#39;psp_schedule&#39;</span><span class="p">:</span> <span class="s2">&quot;&quot;</span> <span class="k">if</span> <span class="ow">not</span> <span class="s1">&#39;psp_schedule&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_omp_config</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">_omp_config</span><span class="p">[</span><span class="s1">&#39;psp_schedule&#39;</span><span class="p">]}</span>

        <span class="c1"># HD ( 16.10.2015 ):</span>
        <span class="c1"># pre-load delayed firing rate in a local array, so we</span>
        <span class="c1"># prevent multiple accesses to pop%(id_pre)s._delayed_r[delay-1]</span>
        <span class="c1"># wheareas delay is set available as variable</span>
        <span class="c1"># TODO HD: wouldn&#39;t it be much better to reduce delay globaly, instead of the substraction here???</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">delays</span> <span class="o">&gt;</span> <span class="n">Global</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;dt&#39;</span><span class="p">]:</span>
            <span class="n">pre_load_r</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">        // pre-load delayed firing rate</span>
<span class="s2">        auto delayed_r = pop</span><span class="si">%(id_pre)s</span><span class="s2">._delayed_r[delay-1];</span>
<span class="s2">        &quot;&quot;&quot;</span><span class="o">%</span> <span class="p">{</span><span class="s1">&#39;id_pre&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">id</span><span class="p">}</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">pre_load_r</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>

        <span class="c1"># Target variable depends on neuron type</span>
        <span class="n">target_code</span> <span class="o">=</span> <span class="s2">&quot;_sum_</span><span class="si">%(target)s</span><span class="s2">&quot;</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">neuron_type</span><span class="o">.</span><span class="n">type</span><span class="o">==</span><span class="s2">&quot;rate&quot;</span> <span class="k">else</span> <span class="s2">&quot;g_</span><span class="si">%(target)s</span><span class="s2">&quot;</span>
        <span class="n">target_code</span> <span class="o">%=</span> <span class="p">{</span><span class="s1">&#39;target&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="p">}</span>

        <span class="c1"># Compute sum</span>
        <span class="n">wsum</span> <span class="o">=</span>  <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">        if ( _transmission &amp;&amp; pop</span><span class="si">%(id_pre)s</span><span class="s2">._active ) {</span>
<span class="s2">            int* coord;</span>
<span class="s2">&quot;&quot;&quot;</span> <span class="o">+</span> <span class="n">pre_load_r</span> <span class="o">+</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">            </span><span class="si">%(omp_code)s</span><span class="s2"></span>
<span class="s2">            for(int i = 0; i &lt; </span><span class="si">%(size_post)s</span><span class="s2">; i++){</span>
<span class="s2">                coord = pre_coords[i].data();</span>

<span class="s2">                // perform the convolution</span>
<span class="s2">&quot;&quot;&quot;</span> <span class="o">+</span> <span class="n">tabify</span><span class="p">(</span><span class="n">convolve_code</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;&quot;&quot;</span>

<span class="s2">                // store result</span>
<span class="s2">                pop</span><span class="si">%(id_post)s</span><span class="s2">.</span><span class="si">%(target)s</span><span class="s2">[i] += &quot;&quot;&quot;</span> <span class="o">+</span> <span class="n">sum_code</span> <span class="o">+</span> <span class="s2">&quot;&quot;&quot;;</span>
<span class="s2">            } // for</span>
<span class="s2">        } // if</span>
<span class="s2">&quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_specific_template</span><span class="p">[</span><span class="s1">&#39;psp_code&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">wsum</span> <span class="o">%</span> \
        <span class="p">{</span>   <span class="s1">&#39;id_proj&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">id</span><span class="p">,</span>
            <span class="s1">&#39;target&#39;</span><span class="p">:</span> <span class="n">target_code</span><span class="p">,</span>
            <span class="s1">&#39;id_pre&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">id</span><span class="p">,</span> <span class="s1">&#39;name_pre&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="s1">&#39;size_pre&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">size</span><span class="p">,</span>
            <span class="s1">&#39;id_post&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">id</span><span class="p">,</span> <span class="s1">&#39;name_post&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="s1">&#39;size_post&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">size</span><span class="p">,</span>
            <span class="s1">&#39;omp_code&#39;</span><span class="p">:</span> <span class="n">omp_code</span><span class="p">,</span>
            <span class="s1">&#39;convolve_code&#39;</span><span class="p">:</span> <span class="n">convolve_code</span>
        <span class="p">}</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_specific_template</span><span class="p">[</span><span class="s1">&#39;size_in_bytes&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">        // post-ranks</span>
<span class="s2">        size_in_bytes += sizeof(std::vector&lt;int&gt;);</span>
<span class="s2">        size_in_bytes += post_rank.capacity() * sizeof(int);</span>

<span class="s2">        // pre-coords</span>
<span class="s2">        size_in_bytes += sizeof(std::vector&lt;std::vector&lt;int&gt;&gt;);</span>
<span class="s2">        size_in_bytes += pre_coords.capacity() * sizeof(std::vector&lt;int&gt;);</span>
<span class="s2">        for (auto it = pre_coords.begin(); it != pre_coords.end(); it++) {</span>
<span class="s2">            size_in_bytes += it-&gt;capacity() * sizeof(int);</span>
<span class="s2">        }</span>

<span class="s2">        // filter</span>
<span class="s2">        // TODO:</span>
<span class="s2">&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_specific_template</span><span class="p">[</span><span class="s1">&#39;clear&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">        // post-ranks</span>
<span class="s2">        post_rank.clear();</span>
<span class="s2">        post_rank.shrink_to_fit();</span>

<span class="s2">        // pre-coords</span>
<span class="s2">        for (auto it = pre_coords.begin(); it != pre_coords.end(); it++) {</span>
<span class="s2">            it-&gt;clear();</span>
<span class="s2">            it-&gt;shrink_to_fit();</span>
<span class="s2">        }</span>
<span class="s2">        pre_coords.clear();</span>
<span class="s2">        pre_coords.shrink_to_fit();</span>

<span class="s2">        // filter</span>
<span class="s2">        // TODO:</span>
<span class="s2">&quot;&quot;&quot;</span>

    <span class="c1">################################</span>
    <span class="c1">### Utilities</span>
    <span class="c1">################################</span>
    <span class="k">def</span> <span class="nf">_center_filter</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">int</span><span class="p">(</span><span class="n">i</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span> <span class="k">if</span> <span class="n">i</span><span class="o">%</span><span class="mi">2</span><span class="o">==</span><span class="mi">1</span> <span class="k">else</span> <span class="nb">int</span><span class="p">(</span><span class="n">i</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span>

    <span class="k">def</span> <span class="nf">_filter_definition</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_kernel</span>
        <span class="n">cpp</span> <span class="o">=</span> <span class="n">Global</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;precision&#39;</span><span class="p">]</span>
        <span class="n">pyx</span> <span class="o">=</span> <span class="n">Global</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;precision&#39;</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">dim</span><span class="p">):</span>
            <span class="n">cpp</span> <span class="o">=</span> <span class="s1">&#39;std::vector&lt; &#39;</span> <span class="o">+</span> <span class="n">cpp</span> <span class="o">+</span> <span class="s1">&#39; &gt;&#39;</span>
            <span class="n">pyx</span> <span class="o">=</span> <span class="s1">&#39;vector[&#39;</span> <span class="o">+</span> <span class="n">pyx</span> <span class="o">+</span> <span class="s1">&#39;]&#39;</span>
        <span class="n">cpp</span> <span class="o">+=</span> <span class="s1">&#39; w;&#39;</span>
        <span class="n">pyx</span> <span class="o">+=</span> <span class="s1">&#39; w&#39;</span>
        <span class="k">return</span> <span class="n">cpp</span><span class="p">,</span> <span class="n">pyx</span>

    <span class="k">def</span> <span class="nf">_coordinates_to_rank</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">geometry</span><span class="p">):</span>

        <span class="n">dim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">geometry</span><span class="p">)</span>

        <span class="n">txt</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>

        <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">dim</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">txt</span> <span class="o">==</span> <span class="s2">&quot;&quot;</span> <span class="p">:</span> <span class="c1"># first coordinate is special</span>
                <span class="n">txt</span> <span class="o">=</span> <span class="n">indices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot;_&quot;</span> <span class="o">+</span> <span class="n">name</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">txt</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">geometry</span><span class="p">[</span><span class="n">d</span><span class="p">])</span> <span class="o">+</span> <span class="s1">&#39;*(&#39;</span> <span class="o">+</span> <span class="n">txt</span> <span class="o">+</span> <span class="s1">&#39;) + &#39;</span> <span class="o">+</span> <span class="n">indices</span><span class="p">[</span><span class="n">d</span><span class="p">]</span>  <span class="o">+</span> <span class="s1">&#39;_&#39;</span> <span class="o">+</span> <span class="n">name</span>

        <span class="k">return</span> <span class="n">txt</span>

    <span class="k">def</span> <span class="nf">_generate_convolve_code</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

        <span class="c1"># Operation to be performed: sum, max, min, mean</span>
        <span class="n">operation</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">synapse_type</span><span class="o">.</span><span class="n">operation</span>

        <span class="c1"># Main code</span>
        <span class="n">code</span> <span class="o">=</span> <span class="n">tabify</span><span class="p">(</span><span class="s2">&quot;sum = 0.0;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

        <span class="c1"># Generate for loops</span>
        <span class="k">for</span> <span class="n">dim</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dim_kernel</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">dim</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_kernel</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span>
                <span class="n">inner_idx</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dim_kernel</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
                    <span class="n">inner_idx</span> <span class="o">+=</span> <span class="s2">&quot;[&quot;</span><span class="o">+</span><span class="n">indices</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">+</span><span class="s2">&quot;_w]&quot;</span>
                <span class="n">code</span> <span class="o">+=</span> <span class="s2">&quot;auto inner_line = w&quot;</span><span class="o">+</span><span class="n">inner_idx</span><span class="o">+</span><span class="s2">&quot;.data();</span><span class="se">\n</span><span class="s2">&quot;</span>

            <span class="n">code</span> <span class="o">+=</span> <span class="n">tabify</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">            for(int </span><span class="si">%(index)s</span><span class="s2">_w = 0; </span><span class="si">%(index)s</span><span class="s2">_w &lt; </span><span class="si">%(size)s</span><span class="s2">;</span><span class="si">%(index)s</span><span class="s2">_w++) {</span>
<span class="s2">            &quot;&quot;&quot;</span> <span class="o">%</span> <span class="p">{</span> <span class="s1">&#39;index&#39;</span><span class="p">:</span> <span class="n">indices</span><span class="p">[</span><span class="n">dim</span><span class="p">],</span> <span class="s1">&#39;size&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">dim</span><span class="p">]},</span> <span class="n">dim</span><span class="p">)</span>

            <span class="c1"># Compute indices</span>
            <span class="k">if</span> <span class="n">dim</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_kernel</span><span class="p">:</span>
                <span class="n">code</span> <span class="o">+=</span> <span class="n">tabify</span><span class="p">(</span>
                    <span class="sd">&quot;&quot;&quot;int %(index)s_pre = coord[%(dim)s] %(operator)s (%(index)s_w - %(center)s);&quot;&quot;&quot;</span> <span class="o">%</span>
                        <span class="p">{</span>
                            <span class="s1">&#39;id_proj&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">id</span><span class="p">,</span>
                            <span class="s1">&#39;index&#39;</span><span class="p">:</span> <span class="n">indices</span><span class="p">[</span><span class="n">dim</span><span class="p">],</span>
                            <span class="s1">&#39;dim&#39;</span><span class="p">:</span> <span class="n">dim</span><span class="p">,</span>
                            <span class="s1">&#39;operator&#39;</span><span class="p">:</span> <span class="s1">&#39;+&#39;</span> <span class="p">,</span>
                            <span class="s1">&#39;center&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_center_filter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">dim</span><span class="p">])</span>
                        <span class="p">},</span> <span class="mi">1</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">code</span> <span class="o">+=</span> <span class="n">tabify</span><span class="p">(</span>
                    <span class="sd">&quot;&quot;&quot;int %(index)s_pre = coord[%(dim)s];&quot;&quot;&quot;</span> <span class="o">%</span>
                        <span class="p">{</span>
                            <span class="s1">&#39;id_proj&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">id</span><span class="p">,</span>
                            <span class="s1">&#39;index&#39;</span><span class="p">:</span> <span class="n">indices</span><span class="p">[</span><span class="n">dim</span><span class="p">],</span>
                            <span class="s1">&#39;dim&#39;</span><span class="p">:</span> <span class="n">dim</span>
                        <span class="p">},</span> <span class="mi">1</span><span class="p">)</span>

            <span class="c1"># Check indices</span>
            <span class="k">if</span> <span class="n">operation</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;sum&#39;</span><span class="p">,</span> <span class="s1">&#39;mean&#39;</span><span class="p">]:</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">padding</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span> <span class="c1"># &#39;border&#39;</span>
                        <span class="n">code</span> <span class="o">+=</span> <span class="n">tabify</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">                if (</span><span class="si">%(index)s</span><span class="s2">_pre &lt; 0) </span><span class="si">%(index)s</span><span class="s2">_pre = 0 ;</span>
<span class="s2">                if (</span><span class="si">%(index)s</span><span class="s2">_pre &gt; </span><span class="si">%(max_size)s</span><span class="s2">) </span><span class="si">%(index)s</span><span class="s2">_pre = </span><span class="si">%(max_size)s</span><span class="s2"> ;</span>
<span class="s2">                &quot;&quot;&quot;</span> <span class="o">%</span> <span class="p">{</span> <span class="s1">&#39;index&#39;</span><span class="p">:</span> <span class="n">indices</span><span class="p">[</span><span class="n">dim</span><span class="p">],</span> <span class="s1">&#39;dim&#39;</span><span class="p">:</span> <span class="n">dim</span><span class="p">,</span> <span class="s1">&#39;max_size&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">geometry</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="o">-</span><span class="mi">1</span><span class="p">},</span> <span class="n">dim</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">code</span> <span class="o">+=</span> <span class="n">tabify</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">                if ((</span><span class="si">%(index)s</span><span class="s2">_pre &lt; 0) || (</span><span class="si">%(index)s</span><span class="s2">_pre &gt; </span><span class="si">%(max_size)s</span><span class="s2">)){</span>
<span class="s2">                    sum += </span><span class="si">%(padding)s</span><span class="s2">;</span>
<span class="s2">                    continue;</span>
<span class="s2">                }</span>
<span class="s2">                &quot;&quot;&quot;</span> <span class="o">%</span> <span class="p">{</span> <span class="s1">&#39;index&#39;</span><span class="p">:</span> <span class="n">indices</span><span class="p">[</span><span class="n">dim</span><span class="p">],</span> <span class="s1">&#39;padding&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding</span><span class="p">,</span> <span class="s1">&#39;max_size&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">geometry</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="o">-</span><span class="mi">1</span><span class="p">},</span> <span class="n">dim</span><span class="p">)</span>

            <span class="k">else</span><span class="p">:</span> <span class="c1"># min, max</span>
                <span class="n">code</span> <span class="o">+=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">                if ((</span><span class="si">%(index)s</span><span class="s2">_pre &lt; 0) || (</span><span class="si">%(index)s</span><span class="s2">_pre &gt; </span><span class="si">%(max_size)s</span><span class="s2">)) {</span>
<span class="s2">                    continue;</span>
<span class="s2">                }</span>
<span class="s2">                &quot;&quot;&quot;</span> <span class="o">%</span> <span class="p">{</span> <span class="s1">&#39;index&#39;</span><span class="p">:</span> <span class="n">indices</span><span class="p">[</span><span class="n">dim</span><span class="p">],</span> <span class="s1">&#39;max_size&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">geometry</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="o">-</span><span class="mi">1</span><span class="p">}</span>

        <span class="c1"># if True, we need to take the last dimension from coords</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">keep_last_dimension</span><span class="p">:</span>
            <span class="n">id_dict</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s1">&#39;index&#39;</span><span class="p">:</span> <span class="n">indices</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">dim_kernel</span><span class="p">],</span>
                <span class="s1">&#39;dim&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_kernel</span>
            <span class="p">}</span>
            <span class="n">code</span> <span class="o">+=</span> <span class="s2">&quot;int </span><span class="si">%(index)s</span><span class="s2">_pre = coord[</span><span class="si">%(dim)s</span><span class="s2">];&quot;</span> <span class="o">%</span> <span class="n">id_dict</span>

        <span class="c1"># Compute pre-synaptic rank</span>
        <span class="n">code</span> <span class="o">+=</span> <span class="n">tabify</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">                rk_pre = </span><span class="si">%(value)s</span><span class="s2">;&quot;&quot;&quot;</span> <span class="o">%</span> <span class="p">{</span><span class="s1">&#39;value&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_coordinates_to_rank</span><span class="p">(</span><span class="s1">&#39;pre&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">geometry</span><span class="p">)},</span> <span class="n">dim</span><span class="p">)</span>

        <span class="c1"># Compute the increment</span>
        <span class="n">index</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
        <span class="k">for</span> <span class="n">dim</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dim_kernel</span><span class="p">):</span>
            <span class="n">index</span> <span class="o">+=</span> <span class="s1">&#39;[&#39;</span> <span class="o">+</span> <span class="n">indices</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="o">+</span> <span class="s1">&#39;_w]&#39;</span>

        <span class="n">increment</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">synapse_type</span><span class="o">.</span><span class="n">description</span><span class="p">[</span><span class="s1">&#39;psp&#39;</span><span class="p">][</span><span class="s1">&#39;cpp&#39;</span><span class="p">]</span> <span class="o">%</span> <span class="p">{</span>
            <span class="s1">&#39;id_pre&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">id</span><span class="p">,</span>
            <span class="s1">&#39;id_post&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">id</span><span class="p">,</span>
            <span class="s1">&#39;local_index&#39;</span><span class="p">:</span> <span class="n">index</span><span class="p">,</span>
            <span class="s1">&#39;global_index&#39;</span><span class="p">:</span> <span class="s1">&#39;[i]&#39;</span><span class="p">,</span>
            <span class="s1">&#39;pre_index&#39;</span><span class="p">:</span> <span class="s1">&#39;[rk_pre]&#39;</span><span class="p">,</span>
            <span class="s1">&#39;post_index&#39;</span><span class="p">:</span> <span class="s1">&#39;[rk_post]&#39;</span><span class="p">,</span>
            <span class="s1">&#39;pre_prefix&#39;</span><span class="p">:</span> <span class="s1">&#39;pop&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">id</span><span class="p">)</span><span class="o">+</span><span class="s1">&#39;.&#39;</span><span class="p">,</span>
            <span class="s1">&#39;post_prefix&#39;</span><span class="p">:</span> <span class="s1">&#39;pop&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">id</span><span class="p">)</span><span class="o">+</span><span class="s1">&#39;.&#39;</span>
        <span class="p">}</span>

        <span class="c1"># Delays</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">delays</span> <span class="o">&gt;</span> <span class="n">Global</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;dt&#39;</span><span class="p">]:</span>
            <span class="n">increment</span> <span class="o">=</span> <span class="n">increment</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span>
                <span class="s1">&#39;pop</span><span class="si">%(id_pre)s</span><span class="s1">.r[rk_pre]&#39;</span> <span class="o">%</span> <span class="p">{</span><span class="s1">&#39;id_pre&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">id</span><span class="p">},</span>
                <span class="s1">&#39;delayed_r[rk_pre]&#39;</span>
            <span class="p">)</span>

        <span class="c1"># Apply the operation</span>
        <span class="k">if</span> <span class="n">operation</span> <span class="o">==</span> <span class="s2">&quot;sum&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_kernel</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">code</span> <span class="o">+=</span> <span class="n">tabify</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">                sum += </span><span class="si">%(increment)s</span><span class="s2">&quot;&quot;&quot;</span> <span class="o">%</span> <span class="p">{</span><span class="s1">&#39;increment&#39;</span><span class="p">:</span> <span class="n">increment</span><span class="p">},</span> <span class="n">dim</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">code</span> <span class="o">+=</span> <span class="n">tabify</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">                sum += </span><span class="si">%(increment)s</span><span class="s2">&quot;&quot;&quot;</span> <span class="o">%</span> <span class="p">{</span><span class="s1">&#39;increment&#39;</span><span class="p">:</span> <span class="n">increment</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;w&#39;</span><span class="o">+</span><span class="n">inner_idx</span><span class="p">,</span> <span class="s1">&#39;inner_line&#39;</span><span class="p">)},</span> <span class="n">dim</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">operation</span> <span class="o">==</span> <span class="s2">&quot;max&quot;</span><span class="p">:</span>
            <span class="n">code</span> <span class="o">+=</span> <span class="n">tabify</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">                </span><span class="si">%(float_prec)s</span><span class="s2"> _psp = </span><span class="si">%(increment)s</span><span class="s2"></span>
<span class="s2">                if(_psp &gt; sum) sum = _psp;&quot;&quot;&quot;</span> <span class="o">%</span> <span class="p">{</span><span class="s1">&#39;increment&#39;</span><span class="p">:</span> <span class="n">increment</span><span class="p">,</span> <span class="s1">&#39;float_prec&#39;</span><span class="p">:</span> <span class="n">Global</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;precision&#39;</span><span class="p">]},</span> <span class="n">dim</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">operation</span> <span class="o">==</span> <span class="s2">&quot;min&quot;</span><span class="p">:</span>
            <span class="n">code</span> <span class="o">+=</span> <span class="n">tabify</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">                </span><span class="si">%(float_prec)s</span><span class="s2"> _psp = </span><span class="si">%(increment)s</span><span class="s2"></span>
<span class="s2">                if(_psp &lt; sum) sum = _psp;&quot;&quot;&quot;</span> <span class="o">%</span> <span class="p">{</span><span class="s1">&#39;increment&#39;</span><span class="p">:</span> <span class="n">increment</span><span class="p">,</span> <span class="s1">&#39;float_prec&#39;</span><span class="p">:</span> <span class="n">Global</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;precision&#39;</span><span class="p">]},</span> <span class="n">dim</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">operation</span> <span class="o">==</span> <span class="s2">&quot;mean&quot;</span><span class="p">:</span>
            <span class="n">code</span> <span class="o">+=</span> <span class="n">tabify</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">                sum += </span><span class="si">%(increment)s</span><span class="s2">&quot;&quot;&quot;</span> <span class="o">%</span> <span class="p">{</span><span class="s1">&#39;increment&#39;</span><span class="p">:</span> <span class="n">increment</span><span class="p">},</span> <span class="n">dim</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s1">&#39;Convolution: Operation&#39;</span><span class="p">,</span> <span class="n">operation</span><span class="p">,</span> <span class="s1">&#39;is not implemented yet for shared projections.&#39;</span><span class="p">)</span>

        <span class="c1"># Close for loops</span>
        <span class="k">for</span> <span class="n">dim</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dim_kernel</span><span class="p">):</span>
            <span class="n">code</span> <span class="o">+=</span> <span class="n">tabify</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">            }&quot;&quot;&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_kernel</span><span class="o">-</span><span class="mi">1</span><span class="o">-</span><span class="n">dim</span><span class="p">)</span>

        <span class="n">impl_code</span> <span class="o">=</span> <span class="n">code</span> <span class="o">%</span> <span class="p">{</span><span class="s1">&#39;id_proj&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">id</span><span class="p">,</span>
            <span class="s1">&#39;target&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="p">,</span>
            <span class="s1">&#39;id_pre&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">id</span><span class="p">,</span>
            <span class="s1">&#39;name_pre&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
            <span class="s1">&#39;size_pre&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">size</span><span class="p">,</span>
            <span class="s1">&#39;id_post&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">id</span><span class="p">,</span>
            <span class="s1">&#39;name_post&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
            <span class="s1">&#39;size_post&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">size</span>
          <span class="p">}</span>

        <span class="c1"># sum code</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="o">.</span><span class="n">size</span>
        <span class="k">if</span> <span class="n">operation</span> <span class="o">==</span> <span class="s2">&quot;mean&quot;</span><span class="p">:</span>
            <span class="n">sum_code</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;sum/</span><span class="si">%(filter_size)s</span><span class="s2">&quot;&quot;&quot;</span> <span class="o">%</span> <span class="p">{</span><span class="s1">&#39;filter_size&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="o">.</span><span class="n">size</span><span class="p">}</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">sum_code</span> <span class="o">=</span> <span class="s2">&quot;sum&quot;</span>

        <span class="k">return</span> <span class="n">impl_code</span><span class="p">,</span> <span class="n">sum_code</span>

    <span class="k">def</span> <span class="nf">_generate_bank_code</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

        <span class="c1"># Operation to be performed: sum, max, min, mean</span>
        <span class="n">operation</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">synapse_type</span><span class="o">.</span><span class="n">operation</span>

        <span class="c1"># Main code</span>
        <span class="n">code</span> <span class="o">=</span> <span class="n">tabify</span><span class="p">(</span><span class="s2">&quot;sum = 0.0;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

        <span class="c1"># Generate for loops</span>
        <span class="k">for</span> <span class="n">dim</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dim_kernel</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">code</span> <span class="o">+=</span> <span class="n">tabify</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">            for(int </span><span class="si">%(index)s</span><span class="s2">_w = 0; </span><span class="si">%(index)s</span><span class="s2">_w &lt; </span><span class="si">%(size)s</span><span class="s2">;</span><span class="si">%(index)s</span><span class="s2">_w++) {</span>
<span class="s2">            &quot;&quot;&quot;</span> <span class="o">%</span> <span class="p">{</span> <span class="s1">&#39;index&#39;</span><span class="p">:</span> <span class="n">indices</span><span class="p">[</span><span class="n">dim</span><span class="p">],</span> <span class="s1">&#39;size&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">dim</span><span class="o">+</span><span class="mi">1</span><span class="p">]},</span> <span class="n">dim</span><span class="p">)</span>

            <span class="c1"># Compute indices</span>
            <span class="k">if</span> <span class="n">dim</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_kernel</span><span class="p">:</span>
                <span class="n">code</span> <span class="o">+=</span> <span class="n">tabify</span><span class="p">(</span>
                    <span class="sd">&quot;&quot;&quot;int %(index)s_pre = coord[%(dim)s] %(operator)s (%(index)s_w - %(center)s);&quot;&quot;&quot;</span> <span class="o">%</span>
                    <span class="p">{</span>
                        <span class="s1">&#39;id_proj&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">id</span><span class="p">,</span>
                        <span class="s1">&#39;index&#39;</span><span class="p">:</span> <span class="n">indices</span><span class="p">[</span><span class="n">dim</span><span class="p">],</span>
                        <span class="s1">&#39;dim&#39;</span><span class="p">:</span> <span class="n">dim</span><span class="p">,</span>
                        <span class="s1">&#39;operator&#39;</span><span class="p">:</span> <span class="s1">&#39;+&#39;</span><span class="p">,</span>
                        <span class="s1">&#39;center&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_center_filter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">dim</span><span class="o">+</span><span class="mi">1</span><span class="p">])</span>
                    <span class="p">},</span> <span class="mi">1</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">code</span> <span class="o">+=</span> <span class="n">tabify</span><span class="p">(</span>
                    <span class="sd">&quot;&quot;&quot;int %(index)s_pre = coord[%(dim)s];&quot;&quot;&quot;</span> <span class="o">%</span>
                    <span class="p">{</span>
                        <span class="s1">&#39;id_proj&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">id</span><span class="p">,</span>
                        <span class="s1">&#39;index&#39;</span><span class="p">:</span> <span class="n">indices</span><span class="p">[</span><span class="n">dim</span><span class="p">],</span>
                        <span class="s1">&#39;dim&#39;</span><span class="p">:</span> <span class="n">dim</span>
                    <span class="p">},</span> <span class="mi">1</span><span class="p">)</span>

            <span class="c1"># Check indices</span>
            <span class="k">if</span> <span class="n">operation</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;sum&#39;</span><span class="p">,</span> <span class="s1">&#39;mean&#39;</span><span class="p">]:</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">padding</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span> <span class="c1"># &#39;border&#39;</span>
                    <span class="n">code</span> <span class="o">+=</span> <span class="n">tabify</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">            if (</span><span class="si">%(index)s</span><span class="s2">_pre &lt; 0) </span><span class="si">%(index)s</span><span class="s2">_pre = 0 ;</span>
<span class="s2">            if (</span><span class="si">%(index)s</span><span class="s2">_pre &gt; </span><span class="si">%(max_size)s</span><span class="s2">) </span><span class="si">%(index)s</span><span class="s2">_pre = </span><span class="si">%(max_size)s</span><span class="s2"> ;</span>
<span class="s2">            &quot;&quot;&quot;</span> <span class="o">%</span> <span class="p">{</span> <span class="s1">&#39;index&#39;</span><span class="p">:</span> <span class="n">indices</span><span class="p">[</span><span class="n">dim</span><span class="p">],</span> <span class="s1">&#39;dim&#39;</span><span class="p">:</span> <span class="n">dim</span><span class="p">,</span> <span class="s1">&#39;max_size&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">geometry</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="o">-</span><span class="mi">1</span><span class="p">},</span> <span class="mi">1</span><span class="o">+</span><span class="n">dim</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">code</span> <span class="o">+=</span> <span class="n">tabify</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">            if ((</span><span class="si">%(index)s</span><span class="s2">_pre &lt; 0) || (</span><span class="si">%(index)s</span><span class="s2">_pre &gt; </span><span class="si">%(max_size)s</span><span class="s2">)) {</span>
<span class="s2">                sum += </span><span class="si">%(padding)s</span><span class="s2">;</span>
<span class="s2">                continue;</span>
<span class="s2">            }</span>
<span class="s2">            &quot;&quot;&quot;</span> <span class="o">%</span> <span class="p">{</span> <span class="s1">&#39;index&#39;</span><span class="p">:</span> <span class="n">indices</span><span class="p">[</span><span class="n">dim</span><span class="p">],</span> <span class="s1">&#39;padding&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding</span><span class="p">,</span> <span class="s1">&#39;max_size&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">geometry</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="o">-</span><span class="mi">1</span><span class="p">},</span> <span class="mi">1</span><span class="o">+</span><span class="n">dim</span><span class="p">)</span>

            <span class="k">else</span><span class="p">:</span> <span class="c1"># min, max</span>
                <span class="n">code</span> <span class="o">+=</span> <span class="n">tabify</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">            if ((</span><span class="si">%(index)s</span><span class="s2">_pre &lt; 0) || (</span><span class="si">%(index)s</span><span class="s2">_pre &gt; </span><span class="si">%(max_size)s</span><span class="s2">)){</span>
<span class="s2">                continue;</span>
<span class="s2">            }</span>
<span class="s2">            &quot;&quot;&quot;</span> <span class="o">%</span> <span class="p">{</span> <span class="s1">&#39;index&#39;</span><span class="p">:</span> <span class="n">indices</span><span class="p">[</span><span class="n">dim</span><span class="p">],</span> <span class="s1">&#39;max_size&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">geometry</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="o">-</span><span class="mi">1</span><span class="p">},</span> <span class="mi">1</span><span class="o">+</span><span class="n">dim</span><span class="p">)</span>

        <span class="c1"># Compute pre-synaptic rank</span>
        <span class="n">code</span> <span class="o">+=</span><span class="n">tabify</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">            rk_pre = </span><span class="si">%(value)s</span><span class="s2">;&quot;&quot;&quot;</span> <span class="o">%</span> <span class="p">{</span><span class="s1">&#39;value&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_coordinates_to_rank</span><span class="p">(</span><span class="s1">&#39;pre&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">geometry</span><span class="p">)},</span> <span class="mi">1</span><span class="o">+</span><span class="n">dim</span><span class="p">)</span>

        <span class="c1"># Compute the increment</span>
        <span class="n">index</span> <span class="o">=</span> <span class="s2">&quot;[coord[&quot;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dim_pre</span><span class="p">)</span><span class="o">+</span><span class="s2">&quot;]]&quot;</span>
        <span class="k">for</span> <span class="n">dim</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dim_kernel</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">index</span> <span class="o">+=</span> <span class="s1">&#39;[&#39;</span> <span class="o">+</span> <span class="n">indices</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="o">+</span> <span class="s1">&#39;_w]&#39;</span>

        <span class="n">increment</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">synapse_type</span><span class="o">.</span><span class="n">description</span><span class="p">[</span><span class="s1">&#39;psp&#39;</span><span class="p">][</span><span class="s1">&#39;cpp&#39;</span><span class="p">]</span> <span class="o">%</span> <span class="p">{</span>
            <span class="s1">&#39;id_pre&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">id</span><span class="p">,</span>
            <span class="s1">&#39;id_post&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">id</span><span class="p">,</span>
            <span class="s1">&#39;local_index&#39;</span><span class="p">:</span> <span class="n">index</span><span class="p">,</span>
            <span class="s1">&#39;global_index&#39;</span><span class="p">:</span> <span class="s1">&#39;[i]&#39;</span><span class="p">,</span>
            <span class="s1">&#39;pre_index&#39;</span><span class="p">:</span> <span class="s1">&#39;[rk_pre]&#39;</span><span class="p">,</span>
            <span class="s1">&#39;post_index&#39;</span><span class="p">:</span> <span class="s1">&#39;[rk_post]&#39;</span><span class="p">,</span>
            <span class="s1">&#39;pre_prefix&#39;</span><span class="p">:</span> <span class="s1">&#39;pop&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">id</span><span class="p">)</span><span class="o">+</span><span class="s1">&#39;.&#39;</span><span class="p">,</span>
            <span class="s1">&#39;post_prefix&#39;</span><span class="p">:</span> <span class="s1">&#39;pop&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">id</span><span class="p">)</span><span class="o">+</span><span class="s1">&#39;.&#39;</span><span class="p">}</span>

        <span class="c1"># Delays</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">delays</span> <span class="o">&gt;</span> <span class="n">Global</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;dt&#39;</span><span class="p">]:</span>
            <span class="n">increment</span> <span class="o">=</span> <span class="n">increment</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span>
                <span class="s1">&#39;pop</span><span class="si">%(id_pre)s</span><span class="s1">.r[rk_pre]&#39;</span> <span class="o">%</span> <span class="p">{</span><span class="s1">&#39;id_pre&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">id</span><span class="p">},</span>
                <span class="s1">&#39;delayed_r[rk_pre]&#39;</span>
            <span class="p">)</span>

        <span class="c1"># Apply the operation</span>
        <span class="k">if</span> <span class="n">operation</span> <span class="o">==</span> <span class="s2">&quot;sum&quot;</span><span class="p">:</span>
            <span class="n">code</span> <span class="o">+=</span> <span class="n">tabify</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">            sum += </span><span class="si">%(increment)s</span><span class="s2">&quot;&quot;&quot;</span> <span class="o">%</span> <span class="p">{</span><span class="s1">&#39;increment&#39;</span><span class="p">:</span> <span class="n">increment</span><span class="p">},</span> <span class="mi">1</span><span class="o">+</span><span class="n">dim</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">operation</span> <span class="o">==</span> <span class="s2">&quot;max&quot;</span><span class="p">:</span>
            <span class="n">code</span> <span class="o">+=</span> <span class="n">tabify</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">            </span><span class="si">%(float_prec)s</span><span class="s2"> _psp = </span><span class="si">%(increment)s</span><span class="s2"></span>
<span class="s2">            if(_psp &gt; sum) sum = _psp;&quot;&quot;&quot;</span> <span class="o">%</span> <span class="p">{</span><span class="s1">&#39;increment&#39;</span><span class="p">:</span> <span class="n">increment</span><span class="p">,</span> <span class="s1">&#39;float_prec&#39;</span><span class="p">:</span> <span class="n">Global</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;precision&#39;</span><span class="p">]},</span> <span class="mi">1</span><span class="o">+</span><span class="n">dim</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">operation</span> <span class="o">==</span> <span class="s2">&quot;min&quot;</span><span class="p">:</span>
            <span class="n">code</span> <span class="o">+=</span> <span class="n">tabify</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">            </span><span class="si">%(float_prec)s</span><span class="s2"> _psp = </span><span class="si">%(increment)s</span><span class="s2"></span>
<span class="s2">            if(_psp &lt; sum) sum = _psp;&quot;&quot;&quot;</span> <span class="o">%</span> <span class="p">{</span><span class="s1">&#39;increment&#39;</span><span class="p">:</span> <span class="n">increment</span><span class="p">,</span> <span class="s1">&#39;float_prec&#39;</span><span class="p">:</span> <span class="n">Global</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;precision&#39;</span><span class="p">]},</span> <span class="mi">1</span><span class="o">+</span><span class="n">dim</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">operation</span> <span class="o">==</span> <span class="s2">&quot;mean&quot;</span><span class="p">:</span>
            <span class="n">code</span> <span class="o">+=</span> <span class="n">tabify</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">            sum += </span><span class="si">%(increment)s</span><span class="s2">&quot;&quot;&quot;</span> <span class="o">%</span> <span class="p">{</span><span class="s1">&#39;increment&#39;</span><span class="p">:</span> <span class="n">increment</span><span class="p">},</span> <span class="mi">1</span><span class="o">+</span><span class="n">dim</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s1">&#39;SharedProjection: Operation&#39;</span><span class="p">,</span> <span class="n">operation</span><span class="p">,</span> <span class="s1">&#39;is not implemented yet for shared projections.&#39;</span><span class="p">)</span>

        <span class="c1"># Close for loops</span>
        <span class="k">for</span> <span class="n">dim</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dim_kernel</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">code</span> <span class="o">+=</span> <span class="n">tabify</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">        }&quot;&quot;&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_kernel</span><span class="o">-</span><span class="mi">1</span><span class="o">-</span><span class="n">dim</span><span class="p">)</span>

        <span class="n">impl_code</span> <span class="o">=</span> <span class="n">code</span> <span class="o">%</span> <span class="p">{</span><span class="s1">&#39;id_proj&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">id</span><span class="p">,</span>
            <span class="s1">&#39;target&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="p">,</span>
            <span class="s1">&#39;id_pre&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">id</span><span class="p">,</span> <span class="s1">&#39;name_pre&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="s1">&#39;size_pre&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">size</span><span class="p">,</span>
            <span class="s1">&#39;id_post&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">id</span><span class="p">,</span> <span class="s1">&#39;name_post&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="s1">&#39;size_post&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">size</span>
        <span class="p">}</span>

        <span class="c1"># sum code</span>
        <span class="k">if</span> <span class="n">operation</span> <span class="o">==</span> <span class="s2">&quot;mean&quot;</span><span class="p">:</span>
            <span class="n">sum_code</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;sum/</span><span class="si">%(filter_size)s</span><span class="s2">&quot;&quot;&quot;</span> <span class="o">%</span> <span class="p">{</span><span class="s1">&#39;filter_size&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="o">.</span><span class="n">size</span><span class="p">}</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">sum_code</span> <span class="o">=</span> <span class="s2">&quot;sum&quot;</span>

        <span class="k">return</span> <span class="n">impl_code</span><span class="p">,</span> <span class="n">sum_code</span>

    <span class="c1">##############################</span>
    <span class="c1">## Override useless methods</span>
    <span class="c1">##############################</span>
    <span class="k">def</span> <span class="nf">_data</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="s2">&quot;Disable saving.&quot;</span>
        <span class="n">desc</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">desc</span><span class="p">[</span><span class="s1">&#39;post_ranks&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">post_ranks</span>
        <span class="n">desc</span><span class="p">[</span><span class="s1">&#39;attributes&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attributes</span>
        <span class="n">desc</span><span class="p">[</span><span class="s1">&#39;parameters&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span>
        <span class="n">desc</span><span class="p">[</span><span class="s1">&#39;variables&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">variables</span>

        <span class="n">desc</span><span class="p">[</span><span class="s1">&#39;dendrites&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">desc</span><span class="p">[</span><span class="s1">&#39;number_of_synapses&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">return</span> <span class="n">desc</span>

    <span class="k">def</span> <span class="nf">save_connectivity</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filename</span><span class="p">):</span>
        <span class="s2">&quot;Not available.&quot;</span>
        <span class="n">Global</span><span class="o">.</span><span class="n">_warning</span><span class="p">(</span><span class="s1">&#39;Convolutional projections can not be saved.&#39;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filename</span><span class="p">):</span>
        <span class="s2">&quot;Not available.&quot;</span>
        <span class="n">Global</span><span class="o">.</span><span class="n">_warning</span><span class="p">(</span><span class="s1">&#39;Convolutional projections can not be saved.&#39;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filename</span><span class="p">):</span>
        <span class="s2">&quot;Not available.&quot;</span>
        <span class="n">Global</span><span class="o">.</span><span class="n">_warning</span><span class="p">(</span><span class="s1">&#39;Convolutional projections can not be loaded.&#39;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">receptive_fields</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">variable</span> <span class="o">=</span> <span class="s1">&#39;w&#39;</span><span class="p">,</span> <span class="n">in_post_geometry</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
        <span class="s2">&quot;Not available.&quot;</span>
        <span class="n">Global</span><span class="o">.</span><span class="n">_warning</span><span class="p">(</span><span class="s1">&#39;Convolutional projections can not display receptive fields.&#39;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">connectivity_matrix</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="mf">0.0</span><span class="p">):</span>
        <span class="s2">&quot;Not available.&quot;</span>
        <span class="n">Global</span><span class="o">.</span><span class="n">_warning</span><span class="p">(</span><span class="s1">&#39;Convolutional projections can not display connectivity matrices.&#39;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
        </details>

  

  <div class="doc doc-children">









<div class="doc doc-object doc-function">



<h3 id="ANNarchy.extensions.convolution.Convolve.Convolution.__init__" class="doc doc-heading">
<code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">pre</span><span class="p">,</span> <span class="n">post</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">psp</span><span class="o">=</span><span class="s1">&#39;pre.r * w&#39;</span><span class="p">,</span> <span class="n">operation</span><span class="o">=</span><span class="s1">&#39;sum&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">copied</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

<a href="#ANNarchy.extensions.convolution.Convolve.Convolution.__init__" class="headerlink" title="Permanent link">#</a></h3>


  <div class="doc doc-contents ">
  
      

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>pre</code></td>
          <td>
          </td>
          <td><p>pre-synaptic population (either its name or a <code>Population</code> object).</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>post</code></td>
          <td>
          </td>
          <td><p>post-synaptic population (either its name or a <code>Population</code> object).</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>target</code></td>
          <td>
          </td>
          <td><p>type of the connection</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>psp</code></td>
          <td>
          </td>
          <td><p>continuous influence of a single synapse on the post-synaptic neuron (default for rate-coded: <code>w*pre.r</code>).</p></td>
          <td>
                <code>&#39;pre.r * w&#39;</code>
          </td>
        </tr>
        <tr>
          <td><code>operation</code></td>
          <td>
          </td>
          <td><p>operation (sum, max, min, mean) performed by the kernel (default: sum).</p></td>
          <td>
                <code>&#39;sum&#39;</code>
          </td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>ANNarchy/extensions/convolution/Convolve.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pre</span><span class="p">,</span> <span class="n">post</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">psp</span><span class="o">=</span><span class="s2">&quot;pre.r * w&quot;</span><span class="p">,</span> <span class="n">operation</span><span class="o">=</span><span class="s2">&quot;sum&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">copied</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    :param pre: pre-synaptic population (either its name or a ``Population`` object).</span>
<span class="sd">    :param post: post-synaptic population (either its name or a ``Population`` object).</span>
<span class="sd">    :param target: type of the connection</span>
<span class="sd">    :param psp: continuous influence of a single synapse on the post-synaptic neuron (default for rate-coded: ``w*pre.r``).</span>
<span class="sd">    :param operation: operation (sum, max, min, mean) performed by the kernel (default: sum).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Sanity check</span>
    <span class="c1">#if not pre.neuron_type.type == &#39;rate&#39;:</span>
    <span class="c1">#    Global._error(&#39;Convolution: only implemented for rate-coded populations.&#39;)</span>

    <span class="c1"># Create the description, but it will not be used for generation</span>
    <span class="n">Projection</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">pre</span><span class="p">,</span>
        <span class="n">post</span><span class="p">,</span>
        <span class="n">target</span><span class="p">,</span>
        <span class="n">synapse</span><span class="o">=</span><span class="n">SharedSynapse</span><span class="p">(</span><span class="n">psp</span><span class="o">=</span><span class="n">psp</span><span class="p">,</span> <span class="n">operation</span><span class="o">=</span><span class="n">operation</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;Convolution operation&quot;</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Convoluted kernel over the pre-synaptic population.&quot;</span><span class="p">),</span>
        <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
        <span class="n">copied</span><span class="o">=</span><span class="n">copied</span>
    <span class="p">)</span>

    <span class="c1"># Disable saving</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_saveable</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="c1"># For copy</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_used_single_filter</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_used_bank_of_filters</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">operation</span> <span class="o">=</span> <span class="n">operation</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h3 id="ANNarchy.extensions.convolution.Convolve.Convolution.connect_filter" class="doc doc-heading">
<code class="highlight language-python"><span class="n">connect_filter</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">delays</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">keep_last_dimension</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">subsampling</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#ANNarchy.extensions.convolution.Convolve.Convolution.connect_filter" class="headerlink" title="Permanent link">#</a></h3>


  <div class="doc doc-contents ">
  
      <p>Applies a single filter on the pre-synaptic population.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>weights</code></td>
          <td>
          </td>
          <td><p>numpy array or list of lists representing the matrix of weights for the filter.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>delays</code></td>
          <td>
          </td>
          <td><p>delay in synaptic transmission (default: dt). Can only be the same value for all neurons.</p></td>
          <td>
                <code>0.0</code>
          </td>
        </tr>
        <tr>
          <td><code>keep_last_dimension</code></td>
          <td>
          </td>
          <td><p>defines if the last dimension of the pre- and post-synaptic will be convolved in parallel. The weights matrix must have one dimension less than the pre-synaptic population, and the number of neurons in the last dimension of the pre- and post-synaptic populations must match. Default: False.</p></td>
          <td>
                <code>False</code>
          </td>
        </tr>
        <tr>
          <td><code>padding</code></td>
          <td>
          </td>
          <td><p>value to be used for the rates outside the pre-synaptic population. If it is a floating value, the pre-synaptic population is virtually extended with this value above its boundaries. If it is equal to 'border', the values on the boundaries are repeated. Default: 0.0.</p></td>
          <td>
                <code>0.0</code>
          </td>
        </tr>
        <tr>
          <td><code>subsampling</code></td>
          <td>
          </td>
          <td><p>list for each post-synaptic neuron of coordinates in the pre-synaptic population defining the center of the kernel/filter. Default: None.</p></td>
          <td>
                <code>None</code>
          </td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>ANNarchy/extensions/convolution/Convolve.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">connect_filter</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">delays</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">keep_last_dimension</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">subsampling</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies a single filter on the pre-synaptic population.</span>

<span class="sd">    :param weights: numpy array or list of lists representing the matrix of weights for the filter.</span>
<span class="sd">    :param delays: delay in synaptic transmission (default: dt). Can only be the same value for all neurons.</span>
<span class="sd">    :param keep_last_dimension: defines if the last dimension of the pre- and post-synaptic will be convolved in parallel. The weights matrix must have one dimension less than the pre-synaptic population, and the number of neurons in the last dimension of the pre- and post-synaptic populations must match. Default: False.</span>
<span class="sd">    :param padding: value to be used for the rates outside the pre-synaptic population. If it is a floating value, the pre-synaptic population is virtually extended with this value above its boundaries. If it is equal to &#39;border&#39;, the values on the boundaries are repeated. Default: 0.0.</span>
<span class="sd">    :param subsampling: list for each post-synaptic neuron of coordinates in the pre-synaptic population defining the center of the kernel/filter. Default: None.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># Process the weights</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>

    <span class="c1"># Process the delays</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">delays</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">delays</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">delays</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">)):</span>
        <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s1">&#39;Convolutions can only have constant delays.&#39;</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">subsampling</span> <span class="o">=</span> <span class="n">subsampling</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">keep_last_dimension</span> <span class="o">=</span> <span class="n">keep_last_dimension</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">padding</span> <span class="o">=</span> <span class="n">padding</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">multiple</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="c1"># Check dimensions of populations and weight matrix</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dim_kernel</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="o">.</span><span class="n">ndim</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dim_pre</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">dimension</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dim_post</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">dimension</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_post</span> <span class="o">&gt;</span> <span class="mi">4</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Convolution:&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_pre</span><span class="p">,</span> <span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_kernel</span><span class="p">,</span> <span class="s1">&#39;-&gt;&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_post</span><span class="p">)</span>
        <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s1">&#39;Convolution: Too many dimensions for the post-synaptic population (maximum 4).&#39;</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_pre</span> <span class="o">&gt;</span> <span class="mi">4</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Convolution:&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_pre</span><span class="p">,</span> <span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_kernel</span><span class="p">,</span> <span class="s1">&#39;-&gt;&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_post</span><span class="p">)</span>
        <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s1">&#39;Convolution: Too many dimensions for the pre-synaptic population (maximum 4).&#39;</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_kernel</span> <span class="o">&gt;</span> <span class="mi">5</span>  <span class="ow">or</span> <span class="p">(</span><span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">multiple</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_kernel</span> <span class="o">&gt;</span> <span class="mi">4</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Convolution:&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_pre</span><span class="p">,</span> <span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_kernel</span><span class="p">,</span> <span class="s1">&#39;-&gt;&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_post</span><span class="p">)</span>
        <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s1">&#39;Convolution: Too many dimensions for the kernel (maximum 4).&#39;</span><span class="p">)</span>

    <span class="c1"># Check if the last axes match for parallel convolution (e.g. 3-2-3)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_kernel</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_pre</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">keep_last_dimension</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Convolution:&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_pre</span><span class="p">,</span> <span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_kernel</span><span class="p">,</span> <span class="s1">&#39;-&gt;&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_post</span><span class="p">)</span>
            <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s1">&#39;Convolution: If the kernel has less dimensions than the pre-synaptic population, you need to set the flag keep_last_dimension to True.&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">geometry</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">geometry</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Convolution:&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_pre</span><span class="p">,</span> <span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_kernel</span><span class="p">,</span> <span class="s1">&#39;-&gt;&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_post</span><span class="p">)</span>
            <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s1">&#39;Convolution: If the kernel has fewer dimensions than the two populations (keep_last_dimension=True), these must have the same number of neurons in the last dimension.&#39;</span><span class="p">)</span>

    <span class="c1"># If the last dim of the kernel matches the last dim of the pre-pop, the last pop can have one dimension less.</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_post</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_pre</span><span class="p">:</span> <span class="c1"># OK, but check the last dimension of the kernel has the same size as the post-population</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">geometry</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Convolution:&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_pre</span><span class="p">,</span> <span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_kernel</span><span class="p">,</span> <span class="s1">&#39;-&gt;&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_post</span><span class="p">)</span>
            <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s1">&#39;Convolution: If the post-synaptic population has less dimensions than the pre-synaptic one, the last dimension of the filter must be equal to the last of the pre-synaptic population.&#39;</span><span class="p">)</span>

    <span class="c1"># Check if it is a bank of filters</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_kernel</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_pre</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Convolution:&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_pre</span><span class="p">,</span> <span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_kernel</span><span class="p">,</span> <span class="s1">&#39;-&gt;&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_post</span><span class="p">)</span>
        <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s1">&#39;Convolution: If the kernel has more dimensions than the pre-synaptic population, you need to use the connect_filters() method.&#39;</span><span class="p">)</span>


    <span class="c1"># Generate the pre-synaptic coordinates</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_generate_pre_coordinates</span><span class="p">()</span>

    <span class="c1"># Finish building the synapses</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_create</span><span class="p">()</span>

    <span class="c1"># For copy</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_used_single_filter</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">return</span> <span class="bp">self</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h3 id="ANNarchy.extensions.convolution.Convolve.Convolution.connect_filters" class="doc doc-heading">
<code class="highlight language-python"><span class="n">connect_filters</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">delays</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">keep_last_dimension</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">subsampling</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#ANNarchy.extensions.convolution.Convolve.Convolution.connect_filters" class="headerlink" title="Permanent link">#</a></h3>


  <div class="doc doc-contents ">
  
      <p>Applies a set of different filters on the pre-synaptic population.</p>
<p>The weights matrix must have one dimension more than the pre-synaptic populations, and the number of neurons in the last dimension of the post-synaptic population must be equal to the number of filters.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>weights</code></td>
          <td>
          </td>
          <td><p>numpy array or list of lists representing the matrix of weights for the filter.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>delays</code></td>
          <td>
          </td>
          <td><p>delay in synaptic transmission (default: dt). Can only be the same value for all neurons.</p></td>
          <td>
                <code>0.0</code>
          </td>
        </tr>
        <tr>
          <td><code>keep_last_dimension</code></td>
          <td>
          </td>
          <td><p>defines if the last dimension of the pre- and post-synaptic will be convolved in parallel. The weights matrix must have one dimension less than the pre-synaptic population, and the number of neurons in the last dimension of the pre- and post-synaptic populations must match. Default: False.</p></td>
          <td>
                <code>False</code>
          </td>
        </tr>
        <tr>
          <td><code>padding</code></td>
          <td>
          </td>
          <td><p>value to be used for the rates outside the pre-synaptic population. If it is a floating value, the pre-synaptic population is virtually extended with this value above its boundaries. If it is equal to 'border', the values on the boundaries are repeated. Default: 0.0.</p></td>
          <td>
                <code>0.0</code>
          </td>
        </tr>
        <tr>
          <td><code>subsampling</code></td>
          <td>
          </td>
          <td><p>list for each post-synaptic neuron of coordinates in the pre-synaptic population defining the center of the kernel/filter. Default: None.</p></td>
          <td>
                <code>None</code>
          </td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>ANNarchy/extensions/convolution/Convolve.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">connect_filters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">delays</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">keep_last_dimension</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">subsampling</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies a set of different filters on the pre-synaptic population.</span>

<span class="sd">    The weights matrix must have one dimension more than the pre-synaptic populations, and the number of neurons in the last dimension of the post-synaptic population must be equal to the number of filters.</span>


<span class="sd">    :param weights: numpy array or list of lists representing the matrix of weights for the filter.</span>
<span class="sd">    :param delays: delay in synaptic transmission (default: dt). Can only be the same value for all neurons.</span>
<span class="sd">    :param keep_last_dimension: defines if the last dimension of the pre- and post-synaptic will be convolved in parallel. The weights matrix must have one dimension less than the pre-synaptic population, and the number of neurons in the last dimension of the pre- and post-synaptic populations must match. Default: False.</span>
<span class="sd">    :param padding: value to be used for the rates outside the pre-synaptic population. If it is a floating value, the pre-synaptic population is virtually extended with this value above its boundaries. If it is equal to &#39;border&#39;, the values on the boundaries are repeated. Default: 0.0.</span>
<span class="sd">    :param subsampling: list for each post-synaptic neuron of coordinates in the pre-synaptic population defining the center of the kernel/filter. Default: None.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># Process the weights</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>

    <span class="c1"># Process the delays</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">delays</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">delays</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">delays</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">)):</span>
        <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s1">&#39;Convolutions can only have constant delays.&#39;</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">subsampling</span> <span class="o">=</span> <span class="n">subsampling</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">keep_last_dimension</span> <span class="o">=</span> <span class="n">keep_last_dimension</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">padding</span> <span class="o">=</span> <span class="n">padding</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">multiple</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="c1"># Check dimensions of populations and weight matrix</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dim_kernel</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="o">.</span><span class="n">ndim</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dim_pre</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">dimension</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dim_post</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">dimension</span>


    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_post</span> <span class="o">&gt;</span> <span class="mi">4</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Convolution:&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_pre</span><span class="p">,</span> <span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_kernel</span><span class="p">,</span> <span class="s1">&#39;-&gt;&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_post</span><span class="p">)</span>
        <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s1">&#39;Convolution: Too many dimensions for the post-synaptic population (maximum 4).&#39;</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_pre</span> <span class="o">&gt;</span> <span class="mi">4</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Convolution:&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_pre</span><span class="p">,</span> <span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_kernel</span><span class="p">,</span> <span class="s1">&#39;-&gt;&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_post</span><span class="p">)</span>
        <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s1">&#39;Convolution: Too many dimensions for the pre-synaptic population (maximum 4).&#39;</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_kernel</span> <span class="o">&gt;</span> <span class="mi">5</span>  <span class="ow">or</span> <span class="p">(</span><span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">multiple</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_kernel</span> <span class="o">&gt;</span> <span class="mi">4</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Convolution:&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_pre</span><span class="p">,</span> <span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_kernel</span><span class="p">,</span> <span class="s1">&#39;-&gt;&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_post</span><span class="p">)</span>
        <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s1">&#39;Convolution: Too many dimensions for the kernel (maximum 4).&#39;</span><span class="p">)</span>

    <span class="c1"># Check if the last axes match for parallel convolution (e.g. 3-2-3)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_kernel</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_pre</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">keep_last_dimension</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Convolution:&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_pre</span><span class="p">,</span> <span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_kernel</span><span class="p">,</span> <span class="s1">&#39;-&gt;&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_post</span><span class="p">)</span>
            <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s1">&#39;Convolution: If the kernel has less dimensions than the pre-synaptic population, you need to set the flag keep_last_dimension to True.&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">geometry</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">geometry</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Convolution:&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_pre</span><span class="p">,</span> <span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_kernel</span><span class="p">,</span> <span class="s1">&#39;-&gt;&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_post</span><span class="p">)</span>
            <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s1">&#39;Convolution: If the kernel has fewer dimensions than the two populations (keep_last_dimension=True), these must have the same number of neurons in the last dimension.&#39;</span><span class="p">)</span>

    <span class="c1"># If the last dim of the kernel matches the last dim of the pre-pop, the last pop can have one dimension less.</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_post</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_pre</span><span class="p">:</span> <span class="c1"># OK, but check the last dimension of the kernel has the same size as the post-population</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">geometry</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Convolution:&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_pre</span><span class="p">,</span> <span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_kernel</span><span class="p">,</span> <span class="s1">&#39;-&gt;&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_post</span><span class="p">)</span>
            <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s1">&#39;Convolution: If the post-synaptic population has less dimensions than the pre-synaptic one, the last dimension of the filter must be equal to the last of the pre-synaptic population.&#39;</span><span class="p">)</span>

    <span class="c1"># The last dimension of the post population must correspond to the number of filters</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">geometry</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Convolution:&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_pre</span><span class="p">,</span> <span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_kernel</span><span class="p">,</span> <span class="s1">&#39;-&gt;&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_post</span><span class="p">)</span>
        <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s1">&#39;Convolution: For multiple filters, the last dimension of the post-synaptic population must have as many neurons as there are filters.&#39;</span><span class="p">)</span>

    <span class="c1"># Generate the pre-synaptic coordinates</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_generate_pre_coordinates_bank</span><span class="p">()</span>

    <span class="c1"># Finish building the synapses</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_create</span><span class="p">()</span>

    <span class="c1"># For copy</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_used_bank_of_filters</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">return</span> <span class="bp">self</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h3 id="ANNarchy.extensions.convolution.Convolve.Convolution.connectivity_matrix" class="doc doc-heading">
<code class="highlight language-python"><span class="n">connectivity_matrix</span><span class="p">(</span><span class="n">fill</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span></code>

<a href="#ANNarchy.extensions.convolution.Convolve.Convolution.connectivity_matrix" class="headerlink" title="Permanent link">#</a></h3>


  <div class="doc doc-contents ">
  
      <p>Not available.</p>

      <details class="quote">
        <summary>Source code in <code>ANNarchy/extensions/convolution/Convolve.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">985</span>
<span class="normal">986</span>
<span class="normal">987</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">connectivity_matrix</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="mf">0.0</span><span class="p">):</span>
    <span class="s2">&quot;Not available.&quot;</span>
    <span class="n">Global</span><span class="o">.</span><span class="n">_warning</span><span class="p">(</span><span class="s1">&#39;Convolutional projections can not display connectivity matrices.&#39;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h3 id="ANNarchy.extensions.convolution.Convolve.Convolution.load" class="doc doc-heading">
<code class="highlight language-python"><span class="n">load</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span></code>

<a href="#ANNarchy.extensions.convolution.Convolve.Convolution.load" class="headerlink" title="Permanent link">#</a></h3>


  <div class="doc doc-contents ">
  
      <p>Not available.</p>

      <details class="quote">
        <summary>Source code in <code>ANNarchy/extensions/convolution/Convolve.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">979</span>
<span class="normal">980</span>
<span class="normal">981</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filename</span><span class="p">):</span>
    <span class="s2">&quot;Not available.&quot;</span>
    <span class="n">Global</span><span class="o">.</span><span class="n">_warning</span><span class="p">(</span><span class="s1">&#39;Convolutional projections can not be loaded.&#39;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h3 id="ANNarchy.extensions.convolution.Convolve.Convolution.receptive_fields" class="doc doc-heading">
<code class="highlight language-python"><span class="n">receptive_fields</span><span class="p">(</span><span class="n">variable</span><span class="o">=</span><span class="s1">&#39;w&#39;</span><span class="p">,</span> <span class="n">in_post_geometry</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></code>

<a href="#ANNarchy.extensions.convolution.Convolve.Convolution.receptive_fields" class="headerlink" title="Permanent link">#</a></h3>


  <div class="doc doc-contents ">
  
      <p>Not available.</p>

      <details class="quote">
        <summary>Source code in <code>ANNarchy/extensions/convolution/Convolve.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">982</span>
<span class="normal">983</span>
<span class="normal">984</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">receptive_fields</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">variable</span> <span class="o">=</span> <span class="s1">&#39;w&#39;</span><span class="p">,</span> <span class="n">in_post_geometry</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
    <span class="s2">&quot;Not available.&quot;</span>
    <span class="n">Global</span><span class="o">.</span><span class="n">_warning</span><span class="p">(</span><span class="s1">&#39;Convolutional projections can not display receptive fields.&#39;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h3 id="ANNarchy.extensions.convolution.Convolve.Convolution.save" class="doc doc-heading">
<code class="highlight language-python"><span class="n">save</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span></code>

<a href="#ANNarchy.extensions.convolution.Convolve.Convolution.save" class="headerlink" title="Permanent link">#</a></h3>


  <div class="doc doc-contents ">
  
      <p>Not available.</p>

      <details class="quote">
        <summary>Source code in <code>ANNarchy/extensions/convolution/Convolve.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">976</span>
<span class="normal">977</span>
<span class="normal">978</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filename</span><span class="p">):</span>
    <span class="s2">&quot;Not available.&quot;</span>
    <span class="n">Global</span><span class="o">.</span><span class="n">_warning</span><span class="p">(</span><span class="s1">&#39;Convolutional projections can not be saved.&#39;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h3 id="ANNarchy.extensions.convolution.Convolve.Convolution.save_connectivity" class="doc doc-heading">
<code class="highlight language-python"><span class="n">save_connectivity</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span></code>

<a href="#ANNarchy.extensions.convolution.Convolve.Convolution.save_connectivity" class="headerlink" title="Permanent link">#</a></h3>


  <div class="doc doc-contents ">
  
      <p>Not available.</p>

      <details class="quote">
        <summary>Source code in <code>ANNarchy/extensions/convolution/Convolve.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">973</span>
<span class="normal">974</span>
<span class="normal">975</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">save_connectivity</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filename</span><span class="p">):</span>
    <span class="s2">&quot;Not available.&quot;</span>
    <span class="n">Global</span><span class="o">.</span><span class="n">_warning</span><span class="p">(</span><span class="s1">&#39;Convolutional projections can not be saved.&#39;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>



  </div>

  </div>

</div>

<div class="doc doc-object doc-module">



<h2 id="ANNarchy.extensions.convolution.Pooling" class="doc doc-heading">
          <code>ANNarchy.extensions.convolution.Pooling</code>


<a href="#ANNarchy.extensions.convolution.Pooling" class="headerlink" title="Permanent link">#</a></h2>

  <div class="doc doc-contents first">

  

  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h3 id="ANNarchy.extensions.convolution.Pooling.Pooling" class="doc doc-heading">
        <code>Pooling</code>


<a href="#ANNarchy.extensions.convolution.Pooling.Pooling" class="headerlink" title="Permanent link">#</a></h3>


  <div class="doc doc-contents ">
      <p class="doc doc-class-bases">
        Bases: <code><a title="ANNarchy.core.Projection.Projection" href="../Projection.html#ANNarchy.Projection">Projection</a></code></p>

  
      <p>Performs a pooling operation (e.g. max.pooling) on the pre-synaptic population.</p>
<p>Each post-synaptic neuron covers a specific region (<code>extent</code>) of the pre-synaptic
population, over which the result of the operation on firing rates will be
assigned to sum(target).</p>
<p>The extent is automatically computed using the geometry of the populations, but can be specified in the `connect_pooling()`` methods.</p>
<p>Example:</p>
<div class="highlight"><pre><span></span><code><span class="n">inp</span> <span class="o">=</span> <span class="n">Population</span><span class="p">(</span><span class="n">geometry</span><span class="o">=</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">),</span> <span class="n">neuron</span><span class="o">=</span><span class="n">Neuron</span><span class="p">(</span><span class="n">parameters</span><span class="o">=</span><span class="s2">&quot;r = 0.0&quot;</span><span class="p">))</span>
<span class="n">pop</span> <span class="o">=</span> <span class="n">Population</span><span class="p">(</span><span class="n">geometry</span><span class="o">=</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="mi">50</span><span class="p">),</span> <span class="n">neuron</span><span class="o">=</span><span class="n">Neuron</span><span class="p">(</span><span class="n">equations</span><span class="o">=</span><span class="s2">&quot;r = sum(exc)&quot;</span><span class="p">))</span>
<span class="n">proj</span> <span class="o">=</span> <span class="n">Pooling</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">pop</span><span class="p">,</span> <span class="s1">&#39;exc&#39;</span><span class="p">,</span> <span class="n">operation</span><span class="o">=</span><span class="s1">&#39;max&#39;</span><span class="p">)</span> <span class="c1"># max-pooling</span>
<span class="n">proj</span><span class="o">.</span><span class="n">connect_pooling</span><span class="p">()</span> <span class="c1"># extent=(2, 2) is implicit</span>
</code></pre></div>


        <details class="quote">
          <summary>Source code in <code>ANNarchy/extensions/convolution/Pooling.py</code></summary>
          <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span>
<span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span>
<span class="normal">583</span>
<span class="normal">584</span>
<span class="normal">585</span>
<span class="normal">586</span>
<span class="normal">587</span>
<span class="normal">588</span>
<span class="normal">589</span>
<span class="normal">590</span>
<span class="normal">591</span>
<span class="normal">592</span>
<span class="normal">593</span>
<span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span>
<span class="normal">597</span>
<span class="normal">598</span>
<span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span>
<span class="normal">602</span>
<span class="normal">603</span>
<span class="normal">604</span>
<span class="normal">605</span>
<span class="normal">606</span>
<span class="normal">607</span>
<span class="normal">608</span>
<span class="normal">609</span>
<span class="normal">610</span>
<span class="normal">611</span>
<span class="normal">612</span>
<span class="normal">613</span>
<span class="normal">614</span>
<span class="normal">615</span>
<span class="normal">616</span>
<span class="normal">617</span>
<span class="normal">618</span>
<span class="normal">619</span>
<span class="normal">620</span>
<span class="normal">621</span>
<span class="normal">622</span>
<span class="normal">623</span>
<span class="normal">624</span>
<span class="normal">625</span>
<span class="normal">626</span>
<span class="normal">627</span>
<span class="normal">628</span>
<span class="normal">629</span>
<span class="normal">630</span>
<span class="normal">631</span>
<span class="normal">632</span>
<span class="normal">633</span>
<span class="normal">634</span>
<span class="normal">635</span>
<span class="normal">636</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">Pooling</span><span class="p">(</span><span class="n">Projection</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Performs a pooling operation (e.g. max.pooling) on the pre-synaptic population.</span>

<span class="sd">    Each post-synaptic neuron covers a specific region (``extent``) of the pre-synaptic</span>
<span class="sd">    population, over which the result of the operation on firing rates will be</span>
<span class="sd">    assigned to sum(target).</span>

<span class="sd">    The extent is automatically computed using the geometry of the populations, but can be specified in the `connect_pooling()`` methods.</span>

<span class="sd">    Example:</span>

<span class="sd">    ```python</span>
<span class="sd">    inp = Population(geometry=(100, 100), neuron=Neuron(parameters=&quot;r = 0.0&quot;))</span>
<span class="sd">    pop = Population(geometry=(50, 50), neuron=Neuron(equations=&quot;r = sum(exc)&quot;))</span>
<span class="sd">    proj = Pooling(inp, pop, &#39;exc&#39;, operation=&#39;max&#39;) # max-pooling</span>
<span class="sd">    proj.connect_pooling() # extent=(2, 2) is implicit</span>
<span class="sd">    ```</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pre</span><span class="p">,</span> <span class="n">post</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">psp</span><span class="o">=</span><span class="s2">&quot;pre.r&quot;</span><span class="p">,</span> <span class="n">operation</span><span class="o">=</span><span class="s2">&quot;max&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">copied</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :param pre: pre-synaptic population (either its name or a ``Population`` object).</span>
<span class="sd">        :param post: post-synaptic population (either its name or a ``Population`` object).</span>
<span class="sd">        :param target: type of the connection</span>
<span class="sd">        :param operation: pooling function to be applied (&quot;max&quot;, &quot;min&quot;, &quot;mean&quot;)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Sanity check</span>
        <span class="c1">#if not pre.neuron_type.type == &#39;rate&#39;:</span>
        <span class="c1">#    Global._error(&#39;Pooling: only implemented for rate-coded populations.&#39;)</span>

        <span class="c1"># Sanity check</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">operation</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;max&quot;</span><span class="p">,</span> <span class="s2">&quot;mean&quot;</span><span class="p">,</span> <span class="s2">&quot;min&quot;</span><span class="p">]:</span>
            <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s2">&quot;Pooling: the operation must be either &#39;max&#39;, &#39;mean&#39; or &#39;min&#39;.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">operation</span> <span class="o">=</span> <span class="n">operation</span>

        <span class="c1"># Store for _copy</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">psp</span> <span class="o">=</span> <span class="n">psp</span>

        <span class="n">Projection</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="n">pre</span><span class="p">,</span>
            <span class="n">post</span><span class="p">,</span>
            <span class="n">target</span><span class="p">,</span>
            <span class="n">synapse</span><span class="o">=</span><span class="n">SharedSynapse</span><span class="p">(</span><span class="n">psp</span><span class="o">=</span><span class="n">psp</span><span class="p">,</span> <span class="n">operation</span><span class="o">=</span><span class="n">operation</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;Pooling operation&quot;</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="n">operation</span><span class="o">+</span><span class="s2">&quot;-pooling operation over the pre-synaptic population.&quot;</span><span class="p">),</span>
            <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
            <span class="n">copied</span><span class="o">=</span><span class="n">copied</span>
        <span class="p">)</span>

        <span class="c1"># check dimensions of populations, should not exceed 4</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dim_pre</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">dimension</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dim_post</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">dimension</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_post</span> <span class="o">&gt;</span> <span class="mi">4</span><span class="p">:</span>
            <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s1">&#39;Pooling: Too many dimensions for the post-synaptic population (maximum 4).&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_pre</span> <span class="o">&gt;</span> <span class="mi">4</span><span class="p">:</span>
            <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s1">&#39;Pooling: Too many dimensions for the pre-synaptic population (maximum 4).&#39;</span><span class="p">)</span>

        <span class="c1"># Disable saving</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_saveable</span> <span class="o">=</span> <span class="kc">False</span>



    <span class="k">def</span> <span class="nf">connect_pooling</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">extent</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">delays</span><span class="o">=</span><span class="mf">0.0</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :param extent: extent of the pooling area expressed in the geometry of the pre-synaptic population (e.g ``(2, 2)``). In each dimension, the product of this extent with the number of neurons in the post-synaptic population must be equal to the number of pre-synaptic neurons. Default: None.</span>
<span class="sd">        :param delays: synaptic delay in ms</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># process extent</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">extent_init</span> <span class="o">=</span> <span class="n">extent</span>
        <span class="k">if</span> <span class="n">extent</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>  <span class="c1"># compute the extent automatically</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">dimension</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">dimension</span><span class="p">:</span>
                <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span>
                    <span class="s1">&#39;Pooling: If you do not provide the extent parameter, the two populations must have the same number of dimensions.&#39;</span><span class="p">)</span>

            <span class="n">extent</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">geometry</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">dim</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">dimension</span><span class="p">):</span>
                <span class="n">extent</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="o">/=</span> <span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">geometry</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">geometry</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="o">!=</span> <span class="n">extent</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">geometry</span><span class="p">[</span><span class="n">dim</span><span class="p">]:</span>
                    <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span>
                        <span class="s1">&#39;Pooling: Unable to compute the extent of the pooling area: the number of neurons do not match.&#39;</span><span class="p">)</span>

        <span class="k">elif</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">extent</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
            <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s1">&#39;Pooling: You must provide a tuple for the extent of the pooling operation.&#39;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">extent</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">extent</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">extent</span><span class="p">)</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">dimension</span><span class="p">:</span>
            <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s1">&#39;Pooling: You must provide a tuple for the extent of the pooling operation.&#39;</span><span class="p">)</span>

        <span class="c1"># process delays</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">delays</span> <span class="o">=</span> <span class="n">delays</span>

        <span class="c1"># Generate the pre-synaptic coordinates</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_generate_extent_coordinates</span><span class="p">()</span>

        <span class="c1"># create fake LIL</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_create</span><span class="p">()</span>

        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">_copy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pre</span><span class="p">,</span> <span class="n">post</span><span class="p">):</span>
        <span class="s2">&quot;Returns a copy of the projection when creating networks.  Internal use only.&quot;</span>
        <span class="n">copied_proj</span> <span class="o">=</span> <span class="n">Pooling</span><span class="p">(</span><span class="n">pre</span><span class="o">=</span><span class="n">pre</span><span class="p">,</span> <span class="n">post</span><span class="o">=</span><span class="n">post</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">psp</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">psp</span><span class="p">,</span>
                              <span class="n">operation</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">operation</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">copied</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="n">copied_proj</span><span class="o">.</span><span class="n">extent</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">extent</span>
        <span class="n">copied_proj</span><span class="o">.</span><span class="n">delays</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">delays</span>

        <span class="n">copied_proj</span><span class="o">.</span><span class="n">_generate_extent_coordinates</span><span class="p">()</span>
        <span class="n">copied_proj</span><span class="o">.</span><span class="n">_create</span><span class="p">()</span>

        <span class="n">copied_proj</span><span class="o">.</span><span class="n">_connection_method</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_connection_method</span>
        <span class="n">copied_proj</span><span class="o">.</span><span class="n">_connection_args</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_connection_args</span>
        <span class="n">copied_proj</span><span class="o">.</span><span class="n">_connection_delay</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_connection_delay</span>
        <span class="n">copied_proj</span><span class="o">.</span><span class="n">_storage_format</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_storage_format</span>
        <span class="k">return</span> <span class="n">copied_proj</span>

    <span class="k">def</span> <span class="nf">_create</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        create fake LIL object, just for compilation process</span>

<span class="sd">        :return: no return value</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="kn">from</span> <span class="nn">ANNarchy.core.cython_ext.Connector</span> <span class="kn">import</span> <span class="n">LILConnectivity</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">Global</span><span class="o">.</span><span class="n">_print</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
            <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s1">&#39;ANNarchy was not successfully installed.&#39;</span><span class="p">)</span>

        <span class="n">lil</span> <span class="o">=</span> <span class="n">LILConnectivity</span><span class="p">()</span>
        <span class="n">lil</span><span class="o">.</span><span class="n">max_delay</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">delays</span>
        <span class="n">lil</span><span class="o">.</span><span class="n">uniform_delay</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">delays</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">connector_name</span> <span class="o">=</span> <span class="s2">&quot;Pooling&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">connector_description</span> <span class="o">=</span> <span class="s2">&quot;Pooling&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_store_connectivity</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_load_from_lil</span><span class="p">,</span> <span class="p">(</span><span class="n">lil</span><span class="p">,</span> <span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">delays</span><span class="p">,</span> <span class="n">storage_format</span><span class="o">=</span><span class="s2">&quot;lil&quot;</span><span class="p">,</span> <span class="n">storage_order</span><span class="o">=</span><span class="s2">&quot;post_to_pre&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_connect</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">module</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Builds up dendrites either from list or dictionary. Called by instantiate().</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_connection_method</span><span class="p">:</span>
            <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span>
                <span class="s1">&#39;Pooling: The projection between &#39;</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39; and &#39;</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39; is declared but not connected.&#39;</span><span class="p">)</span>

        <span class="c1"># Create the Cython instance</span>
        <span class="n">proj</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="s1">&#39;proj&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">id</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;_wrapper&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cyInstance</span> <span class="o">=</span> <span class="n">proj</span><span class="p">([],</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre_coordinates</span><span class="p">)</span>

        <span class="k">return</span> <span class="kc">True</span>

    <span class="k">def</span> <span class="nf">_generate_extent_coordinates</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generates for each post-neuron the position of the top-left corner, where the pooling should be applied.</span>

<span class="sd">        :return:  a list for each post neuron of the corresponding top-left coordinates</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Generates coordinates TODO: Find a more robust way!</span>
        <span class="n">coords</span> <span class="o">=</span> <span class="p">[[]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">size</span><span class="p">)]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_pre</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">rk</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">geometry</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
                <span class="n">coords</span><span class="p">[</span><span class="n">rk</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">extent</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
                <span class="n">rk</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_pre</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">rk</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">geometry</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_post</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">geometry</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
                        <span class="n">coords</span><span class="p">[</span><span class="n">rk</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">extent</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">j</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">extent</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>
                        <span class="n">rk</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="k">else</span><span class="p">:</span> <span class="c1"># over the whole second axis</span>
                    <span class="n">coords</span><span class="p">[</span><span class="n">rk</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">extent</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">0</span><span class="p">]</span>
                    <span class="n">rk</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_pre</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
            <span class="n">rk</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">geometry</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
                <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">geometry</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_post</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
                        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">geometry</span><span class="p">[</span><span class="mi">2</span><span class="p">]):</span>
                            <span class="n">coords</span><span class="p">[</span><span class="n">rk</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">extent</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">j</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">extent</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">k</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">extent</span><span class="p">[</span><span class="mi">2</span><span class="p">]]</span>
                            <span class="n">rk</span> <span class="o">+=</span> <span class="mi">1</span>
                    <span class="k">else</span><span class="p">:</span> <span class="c1"># over the whole third axis</span>
                        <span class="n">coords</span><span class="p">[</span><span class="n">rk</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">extent</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">j</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">extent</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">0</span><span class="p">]</span>
                        <span class="n">rk</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_pre</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span> <span class="c1"># TODO: post has less than 4 dimensions</span>
            <span class="n">rk</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">geometry</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
                <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">geometry</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
                    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">geometry</span><span class="p">[</span><span class="mi">2</span><span class="p">]):</span>
                        <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">geometry</span><span class="p">[</span><span class="mi">3</span><span class="p">]):</span>
                            <span class="n">coords</span><span class="p">[</span><span class="n">rk</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">extent</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">j</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">extent</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">k</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">extent</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">l</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">extent</span><span class="p">[</span><span class="mi">3</span><span class="p">]]</span>
                            <span class="n">rk</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="c1"># Save the result</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pre_coordinates</span> <span class="o">=</span> <span class="n">coords</span>

    <span class="k">def</span> <span class="nf">_generate</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overrides the default code generation.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Convolve_code</span>
        <span class="n">convolve_code</span><span class="p">,</span> <span class="n">sum_code</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generate_pooling_code</span><span class="p">()</span>

        <span class="c1"># Generate the code</span>
        <span class="k">if</span> <span class="n">Global</span><span class="o">.</span><span class="n">_check_paradigm</span><span class="p">(</span><span class="s2">&quot;openmp&quot;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_generate_omp</span><span class="p">(</span><span class="n">convolve_code</span><span class="p">,</span> <span class="n">sum_code</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">Global</span><span class="o">.</span><span class="n">_check_paradigm</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">):</span>
            <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s2">&quot;Pooling: not available on GPU devices&quot;</span><span class="p">)</span>
            <span class="c1">#self._generate_cuda(convolve_code, sum_code)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s2">&quot;Pooling: not implemented for the configured paradigm&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_generate_pooling_code</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generate loop statements for the desired pooling operation.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Operation to be performed: sum, max, min, mean</span>
        <span class="n">operation</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">synapse_type</span><span class="o">.</span><span class="n">operation</span>

        <span class="c1"># Main code</span>
        <span class="c1"># default value for sum in code depends on operation</span>
        <span class="n">sum_default</span> <span class="o">=</span> <span class="s2">&quot;0.0&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">synapse_type</span><span class="o">.</span><span class="n">operation</span> <span class="o">==</span> <span class="s2">&quot;min&quot;</span><span class="p">:</span>
            <span class="n">sum_default</span> <span class="o">=</span> <span class="s2">&quot;std::numeric_limits&lt;</span><span class="si">%(float_prec)s</span><span class="s2">&gt;::max()&quot;</span> <span class="o">%</span> <span class="p">{</span><span class="s1">&#39;float_prec&#39;</span><span class="p">:</span> <span class="n">Global</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;precision&#39;</span><span class="p">]}</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">synapse_type</span><span class="o">.</span><span class="n">operation</span> <span class="o">==</span> <span class="s2">&quot;max&quot;</span><span class="p">:</span>
            <span class="n">sum_default</span> <span class="o">=</span> <span class="s2">&quot;std::numeric_limits&lt;</span><span class="si">%(float_prec)s</span><span class="s2">&gt;::min()&quot;</span> <span class="o">%</span> <span class="p">{</span><span class="s1">&#39;float_prec&#39;</span><span class="p">:</span> <span class="n">Global</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;precision&#39;</span><span class="p">]}</span>

        <span class="n">code</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">            sum = </span><span class="si">%(sum_default)s</span><span class="s2">;</span>
<span class="s2">&quot;&quot;&quot;</span> <span class="o">%</span> <span class="p">{</span><span class="s1">&#39;sum_default&#39;</span><span class="p">:</span> <span class="n">sum_default</span><span class="p">}</span>

        <span class="c1"># Generate for loops</span>
        <span class="k">for</span> <span class="n">dim</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dim_pre</span><span class="p">):</span>
            <span class="n">ind_dict</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s1">&#39;index&#39;</span><span class="p">:</span> <span class="n">indices</span><span class="p">[</span><span class="n">dim</span><span class="p">],</span>
                <span class="s1">&#39;size&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">extent</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span>
            <span class="p">}</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">extent</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">code</span> <span class="o">+=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">            for(int </span><span class="si">%(index)s</span><span class="s2">_w = 0; </span><span class="si">%(index)s</span><span class="s2">_w &lt; </span><span class="si">%(size)s</span><span class="s2">; </span><span class="si">%(index)s</span><span class="s2">_w++){</span>
<span class="s2">    &quot;&quot;&quot;</span> <span class="o">%</span> <span class="n">ind_dict</span>

        <span class="c1"># Compute indices</span>
        <span class="k">for</span> <span class="n">dim</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dim_pre</span><span class="p">):</span>
            <span class="n">ind_dict</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s1">&#39;index&#39;</span><span class="p">:</span> <span class="n">indices</span><span class="p">[</span><span class="n">dim</span><span class="p">],</span>
                <span class="s1">&#39;dim&#39;</span><span class="p">:</span> <span class="n">dim</span>
            <span class="p">}</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">extent</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">code</span> <span class="o">+=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">                int </span><span class="si">%(index)s</span><span class="s2">_pre = coord[</span><span class="si">%(dim)s</span><span class="s2">] + </span><span class="si">%(index)s</span><span class="s2">_w;&quot;&quot;&quot;</span> <span class="o">%</span> <span class="n">ind_dict</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">code</span> <span class="o">+=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">                int </span><span class="si">%(index)s</span><span class="s2">_pre = coord[</span><span class="si">%(dim)s</span><span class="s2">];&quot;&quot;&quot;</span> <span class="o">%</span> <span class="n">ind_dict</span>

        <span class="c1"># Check indices</span>
        <span class="k">for</span> <span class="n">dim</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dim_pre</span><span class="p">):</span>
            <span class="n">ind_dict</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s1">&#39;index&#39;</span><span class="p">:</span> <span class="n">indices</span><span class="p">[</span><span class="n">dim</span><span class="p">],</span>
                <span class="s1">&#39;max_size&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">geometry</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span>
            <span class="p">}</span>
            <span class="n">code</span> <span class="o">+=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">                if ((</span><span class="si">%(index)s</span><span class="s2">_pre &lt; 0) ||(</span><span class="si">%(index)s</span><span class="s2">_pre &gt; </span><span class="si">%(max_size)s</span><span class="s2">)){</span>
<span class="s2">                    continue;</span>
<span class="s2">                }&quot;&quot;&quot;</span> <span class="o">%</span> <span class="n">ind_dict</span>

        <span class="c1"># Compute pre-synaptic rank</span>
        <span class="n">code</span> <span class="o">+=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">                rk_pre = </span><span class="si">%(value)s</span><span class="s2">;&quot;&quot;&quot;</span> <span class="o">%</span> <span class="p">{</span><span class="s1">&#39;value&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_coordinates_to_rank</span><span class="p">(</span><span class="s1">&#39;pre&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">geometry</span><span class="p">)}</span>

        <span class="c1"># Compute the value to pool</span>
        <span class="n">psp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">synapse_type</span><span class="o">.</span><span class="n">description</span><span class="p">[</span><span class="s1">&#39;psp&#39;</span><span class="p">][</span><span class="s1">&#39;cpp&#39;</span><span class="p">]</span> <span class="o">%</span> <span class="p">{</span>
            <span class="s1">&#39;id_pre&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">id</span><span class="p">,</span>
            <span class="s1">&#39;id_post&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">id</span><span class="p">,</span>
            <span class="s1">&#39;local_index&#39;</span><span class="p">:</span> <span class="s1">&#39;[i][j]&#39;</span><span class="p">,</span>
            <span class="s1">&#39;global_index&#39;</span><span class="p">:</span> <span class="s1">&#39;[i]&#39;</span><span class="p">,</span>
            <span class="s1">&#39;pre_index&#39;</span><span class="p">:</span> <span class="s1">&#39;[rk_pre]&#39;</span><span class="p">,</span>
            <span class="s1">&#39;post_index&#39;</span><span class="p">:</span> <span class="s1">&#39;[rk_post]&#39;</span><span class="p">,</span>
            <span class="s1">&#39;pre_prefix&#39;</span><span class="p">:</span> <span class="s1">&#39;pop&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">id</span><span class="p">)</span><span class="o">+</span><span class="s1">&#39;.&#39;</span><span class="p">,</span>
            <span class="s1">&#39;post_prefix&#39;</span><span class="p">:</span> <span class="s1">&#39;pop&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">id</span><span class="p">)</span><span class="o">+</span><span class="s1">&#39;.&#39;</span>
        <span class="p">}</span>

        <span class="c1"># Delays</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">delays</span> <span class="o">&gt;</span> <span class="n">Global</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;dt&#39;</span><span class="p">]:</span>
            <span class="n">psp</span> <span class="o">=</span> <span class="n">psp</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span>
                <span class="s1">&#39;pop</span><span class="si">%(id_pre)s</span><span class="s1">.r[rk_pre]&#39;</span> <span class="o">%</span> <span class="p">{</span><span class="s1">&#39;id_pre&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">id</span><span class="p">},</span>
                <span class="s1">&#39;pop</span><span class="si">%(id_pre)s</span><span class="s1">._delayed_r[</span><span class="si">%(delay)s</span><span class="s1">][rk_pre]&#39;</span> <span class="o">%</span> <span class="p">{</span><span class="s1">&#39;id_pre&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">id</span><span class="p">,</span> <span class="s1">&#39;delay&#39;</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">delays</span><span class="o">/</span><span class="n">Global</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;dt&#39;</span><span class="p">])</span><span class="o">-</span><span class="mi">1</span><span class="p">)}</span>
            <span class="p">)</span>

        <span class="c1"># Apply the operation</span>
        <span class="k">if</span> <span class="n">operation</span> <span class="o">==</span> <span class="s2">&quot;max&quot;</span><span class="p">:</span>
            <span class="n">code</span> <span class="o">+=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">                </span><span class="si">%(float_prec)s</span><span class="s2"> _psp = </span><span class="si">%(psp)s</span><span class="s2">;</span>
<span class="s2">                if(_psp &gt; sum) sum = _psp;&quot;&quot;&quot;</span>
        <span class="k">elif</span> <span class="n">operation</span> <span class="o">==</span> <span class="s2">&quot;min&quot;</span><span class="p">:</span>
            <span class="n">code</span> <span class="o">+=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">                </span><span class="si">%(float_prec)s</span><span class="s2"> _psp = </span><span class="si">%(psp)s</span><span class="s2">;</span>
<span class="s2">                if(_psp &lt; sum) sum = _psp;&quot;&quot;&quot;</span>
        <span class="k">elif</span> <span class="n">operation</span> <span class="o">==</span> <span class="s2">&quot;sum&quot;</span><span class="p">:</span>
            <span class="n">code</span> <span class="o">+=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">                sum += </span><span class="si">%(psp)s</span><span class="s2">;&quot;&quot;&quot;</span>
        <span class="k">elif</span> <span class="n">operation</span> <span class="o">==</span> <span class="s2">&quot;mean&quot;</span><span class="p">:</span>
            <span class="n">code</span> <span class="o">+=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">                sum += </span><span class="si">%(psp)s</span><span class="s2">;&quot;&quot;&quot;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s1">&#39;SharedProjection: Operation&#39;</span><span class="p">,</span> <span class="n">operation</span><span class="p">,</span> <span class="s1">&#39;is not implemented yet for shared projections with pooling.&#39;</span><span class="p">)</span>

        <span class="c1"># Close for loops</span>
        <span class="k">for</span> <span class="n">dim</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dim_pre</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">extent</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">code</span> <span class="o">+=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">            }&quot;&quot;&quot;</span>

        <span class="n">impl_code</span> <span class="o">=</span> <span class="n">code</span> <span class="o">%</span> <span class="p">{</span>
            <span class="s1">&#39;id_proj&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">id</span><span class="p">,</span>
            <span class="s1">&#39;target&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="p">,</span>
            <span class="s1">&#39;id_pre&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">id</span><span class="p">,</span> <span class="s1">&#39;name_pre&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="s1">&#39;size_pre&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">size</span><span class="p">,</span>
            <span class="s1">&#39;id_post&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">id</span><span class="p">,</span> <span class="s1">&#39;name_post&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="s1">&#39;size_post&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">size</span><span class="p">,</span>
            <span class="s1">&#39;psp&#39;</span><span class="p">:</span> <span class="n">psp</span><span class="p">,</span>
            <span class="s1">&#39;float_prec&#39;</span><span class="p">:</span> <span class="n">Global</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;precision&#39;</span><span class="p">]</span>
        <span class="p">}</span>

        <span class="k">if</span> <span class="n">operation</span> <span class="o">==</span> <span class="s2">&quot;mean&quot;</span><span class="p">:</span>
            <span class="n">size</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="k">for</span> <span class="n">dim</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">dimension</span><span class="p">):</span>
                <span class="n">size</span> <span class="o">*=</span> <span class="bp">self</span><span class="o">.</span><span class="n">extent</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span>
            <span class="n">sum_code</span> <span class="o">=</span> <span class="s2">&quot;sum/&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">size</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">sum_code</span> <span class="o">=</span> <span class="s2">&quot;sum&quot;</span>

        <span class="k">return</span> <span class="n">impl_code</span><span class="p">,</span> <span class="n">sum_code</span>

    <span class="k">def</span> <span class="nf">_generate_omp</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">convolve_code</span><span class="p">,</span> <span class="n">sum_code</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Update the ProjectionGenerator._specific_template structure and bypass the standard openMP code generation.</span>

<span class="sd">        :param convolve_code:</span>
<span class="sd">        :param sum_code:</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># default value for sum in code depends on operation</span>
        <span class="n">sum_default</span> <span class="o">=</span> <span class="s2">&quot;0.0&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">synapse_type</span><span class="o">.</span><span class="n">operation</span> <span class="o">==</span> <span class="s2">&quot;min&quot;</span><span class="p">:</span>
            <span class="n">sum_default</span> <span class="o">=</span> <span class="s2">&quot;std::numeric_limits&lt;</span><span class="si">%(float_prec)s</span><span class="s2">&gt;::max()&quot;</span> <span class="o">%</span> <span class="p">{</span><span class="s1">&#39;float_prec&#39;</span><span class="p">:</span> <span class="n">Global</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;precision&#39;</span><span class="p">]}</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">synapse_type</span><span class="o">.</span><span class="n">operation</span> <span class="o">==</span> <span class="s2">&quot;max&quot;</span><span class="p">:</span>
            <span class="n">sum_default</span> <span class="o">=</span> <span class="s2">&quot;std::numeric_limits&lt;</span><span class="si">%(float_prec)s</span><span class="s2">&gt;::min()&quot;</span> <span class="o">%</span> <span class="p">{</span><span class="s1">&#39;float_prec&#39;</span><span class="p">:</span> <span class="n">Global</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;precision&#39;</span><span class="p">]}</span>

        <span class="c1"># Specific template for generation</span>
        <span class="n">pool_dict</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">pooling_template_omp</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">pool_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">value</span> <span class="o">=</span> <span class="n">value</span> <span class="o">%</span> <span class="p">{</span>
                <span class="s1">&#39;id_proj&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">id</span><span class="p">,</span>
                <span class="s1">&#39;size_post&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">size</span><span class="p">,</span>
                <span class="s1">&#39;sum_default&#39;</span><span class="p">:</span> <span class="n">sum_default</span><span class="p">,</span>
                <span class="s1">&#39;float_prec&#39;</span><span class="p">:</span> <span class="n">Global</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;precision&#39;</span><span class="p">]</span>
            <span class="p">}</span>
            <span class="n">pool_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_specific_template</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">pool_dict</span><span class="p">)</span>

        <span class="c1"># OMP code</span>
        <span class="n">omp_code</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
        <span class="k">if</span> <span class="n">Global</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;num_threads&#39;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">omp_code</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">        #pragma omp for private(sum, rk_pre, coord) </span><span class="si">%(psp_schedule)s</span><span class="s2">&quot;&quot;&quot;</span> <span class="o">%</span> <span class="p">{</span>
                <span class="s1">&#39;psp_schedule&#39;</span><span class="p">:</span> <span class="s2">&quot;&quot;</span> <span class="k">if</span> <span class="ow">not</span> <span class="s1">&#39;psp_schedule&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_omp_config</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">_omp_config</span><span class="p">[</span>
                    <span class="s1">&#39;psp_schedule&#39;</span><span class="p">]}</span>

        <span class="c1"># HD ( 16.10.2015 ):</span>
        <span class="c1"># pre-load delayed firing rate in a local array, so we</span>
        <span class="c1"># prevent multiple accesses to pop%(id_pre)s._delayed_r[%(delay)s]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">delays</span> <span class="o">&gt;</span> <span class="n">Global</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;dt&#39;</span><span class="p">]:</span>
            <span class="n">pre_load_r</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">        // pre-load delayed firing rate</span>
<span class="s2">        auto delayed_r = pop</span><span class="si">%(id_pre)s</span><span class="s2">._delayed_r[</span><span class="si">%(delay)s</span><span class="s2">];</span>
<span class="s2">        &quot;&quot;&quot;</span> <span class="o">%</span> <span class="p">{</span><span class="s1">&#39;id_pre&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">id</span><span class="p">,</span> <span class="s1">&#39;delay&#39;</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">delays</span> <span class="o">/</span> <span class="n">Global</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;dt&#39;</span><span class="p">])</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)}</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">pre_load_r</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>

        <span class="c1"># Target variable depends on neuron type</span>
        <span class="n">target_code</span> <span class="o">=</span> <span class="s2">&quot;_sum_</span><span class="si">%(target)s</span><span class="s2">&quot;</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">neuron_type</span><span class="o">.</span><span class="n">type</span><span class="o">==</span><span class="s2">&quot;rate&quot;</span> <span class="k">else</span> <span class="s2">&quot;g_</span><span class="si">%(target)s</span><span class="s2">&quot;</span>
        <span class="n">target_code</span> <span class="o">%=</span> <span class="p">{</span><span class="s1">&#39;target&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="p">}</span>

        <span class="c1"># Compute sum</span>
        <span class="n">wsum</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">        if ( _transmission &amp;&amp; pop</span><span class="si">%(id_pre)s</span><span class="s2">._active ) {</span>
<span class="s2">        std::vector&lt;int&gt; coord;</span>
<span class="s2">&quot;&quot;&quot;</span> <span class="o">+</span> <span class="n">pre_load_r</span> <span class="o">+</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">        </span><span class="si">%(omp_code)s</span><span class="s2"></span>
<span class="s2">        for(int i = 0; i &lt; </span><span class="si">%(size_post)s</span><span class="s2">; i++){</span>
<span class="s2">            coord = pre_rank[i];</span>
<span class="s2">&quot;&quot;&quot;</span> <span class="o">+</span> <span class="n">convolve_code</span> <span class="o">+</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">            pop</span><span class="si">%(id_post)s</span><span class="s2">.</span><span class="si">%(target)s</span><span class="s2">[i] += &quot;&quot;&quot;</span> <span class="o">+</span> <span class="n">sum_code</span> <span class="o">+</span> <span class="s2">&quot;&quot;&quot;;</span>
<span class="s2">        } // for</span>
<span class="s2">        } // if</span>
<span class="s2">&quot;&quot;&quot;</span>

        <span class="c1"># Delays</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_specific_template</span><span class="p">[</span><span class="s1">&#39;wrapper_init_delay&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>

        <span class="c1"># Dictionary keys</span>
        <span class="n">psp_dict</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;id_proj&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">id</span><span class="p">,</span>
            <span class="s1">&#39;target&#39;</span><span class="p">:</span> <span class="n">target_code</span><span class="p">,</span>
            <span class="s1">&#39;id_pre&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">id</span><span class="p">,</span> <span class="s1">&#39;name_pre&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
            <span class="s1">&#39;size_pre&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">size</span><span class="p">,</span>
            <span class="s1">&#39;id_post&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">id</span><span class="p">,</span> <span class="s1">&#39;name_post&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
            <span class="s1">&#39;size_post&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">size</span><span class="p">,</span>
            <span class="s1">&#39;omp_code&#39;</span><span class="p">:</span> <span class="n">omp_code</span><span class="p">,</span>
            <span class="s1">&#39;convolve_code&#39;</span><span class="p">:</span> <span class="n">convolve_code</span>
        <span class="p">}</span>

        <span class="c1"># Psp code</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_specific_template</span><span class="p">[</span><span class="s1">&#39;psp_code&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">wsum</span> <span class="o">%</span> <span class="n">psp_dict</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_specific_template</span><span class="p">[</span><span class="s1">&#39;size_in_bytes&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">        // connectivity</span>
<span class="s2">        size_in_bytes += sizeof(std::vector&lt;int&gt;);</span>
<span class="s2">        size_in_bytes += pre_rank.capacity() * sizeof(int);</span>

<span class="s2">        size_in_bytes += sizeof(std::vector&lt;std::vector&lt;int&gt;&gt;);</span>
<span class="s2">        size_in_bytes += pre_rank.capacity() * sizeof(std::vector&lt;int&gt;);</span>
<span class="s2">        for (auto it = pre_rank.begin(); it != pre_rank.end(); it++) {</span>
<span class="s2">            size_in_bytes += it-&gt;capacity() * sizeof(int);</span>
<span class="s2">        }</span>
<span class="s2">&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_specific_template</span><span class="p">[</span><span class="s1">&#39;clear&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">        // post-ranks</span>
<span class="s2">        post_rank.clear();</span>
<span class="s2">        post_rank.shrink_to_fit();</span>

<span class="s2">        // pre-ranks sub-lists</span>
<span class="s2">        for (auto it = pre_rank.begin(); it != pre_rank.end(); it++) {</span>
<span class="s2">            it-&gt;clear();</span>
<span class="s2">            it-&gt;shrink_to_fit();</span>
<span class="s2">        }</span>
<span class="s2">        // pre-ranks top-list</span>
<span class="s2">        pre_rank.clear();</span>
<span class="s2">        pre_rank.shrink_to_fit();</span>
<span class="s2">&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">_generate_cuda</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">convolve_code</span><span class="p">,</span> <span class="n">sum_code</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Update the ProjectionGenerator._specific_template structure and bypass the standard CUDA code generation.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">pool_operation</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">synapse_type</span><span class="o">.</span><span class="n">operation</span>

        <span class="c1"># default value for sum in code depends on operation</span>
        <span class="n">sum_default</span> <span class="o">=</span> <span class="s2">&quot;0.0&quot;</span>
        <span class="k">if</span> <span class="n">pool_operation</span> <span class="o">==</span> <span class="s2">&quot;min&quot;</span><span class="p">:</span>
            <span class="n">sum_default</span> <span class="o">=</span> <span class="s2">&quot;FLT_MAX&quot;</span>
        <span class="k">elif</span> <span class="n">pool_operation</span> <span class="o">==</span> <span class="s2">&quot;max&quot;</span><span class="p">:</span>
            <span class="n">sum_default</span> <span class="o">=</span> <span class="s2">&quot;FLT_MIN&quot;</span>

        <span class="c1"># operation to perform</span>
        <span class="n">pool_op_code</span> <span class="o">=</span> <span class="n">cuda_op_code</span><span class="p">[</span><span class="n">pool_operation</span><span class="p">]</span> <span class="o">%</span> <span class="p">{</span><span class="s1">&#39;float_prec&#39;</span><span class="p">:</span> <span class="n">Global</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;precision&#39;</span><span class="p">]}</span>

        <span class="c1"># result dictionary with code for</span>
        <span class="c1"># body, call and header</span>
        <span class="n">pool_template</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">base_ids</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;id_proj&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">id</span><span class="p">,</span>
            <span class="s1">&#39;id_pre&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">id</span><span class="p">,</span>
            <span class="s1">&#39;id_post&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">id</span><span class="p">,</span>
            <span class="s1">&#39;target&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="p">,</span>
            <span class="s1">&#39;float_prec&#39;</span><span class="p">:</span> <span class="n">Global</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;precision&#39;</span><span class="p">],</span>
            <span class="s1">&#39;size_post&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">size</span> <span class="c1"># TODO: population views?</span>
        <span class="p">}</span>

        <span class="c1"># The correct templates depends on both</span>
        <span class="c1"># kernel-geometry and extent</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">geometry</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="c1"># For small extents, we compute multiple coords within one warp. If one extent can fill alone</span>
            <span class="c1"># a half-warp we switch to the other implementation.</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">extent</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">6</span><span class="p">:</span>

                <span class="n">pool_op_reduce_code</span> <span class="o">=</span> <span class="n">cuda_pooling_code_2d_small_extent</span><span class="p">[</span><span class="s1">&#39;reduce_code&#39;</span><span class="p">][</span><span class="n">pool_operation</span><span class="p">]</span> <span class="o">%</span> <span class="p">{</span>
                    <span class="s1">&#39;float_prec&#39;</span><span class="p">:</span> <span class="n">Global</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;precision&#39;</span><span class="p">],</span>
                    <span class="s1">&#39;row_extent&#39;</span><span class="p">:</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">extent</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span>
                    <span class="s1">&#39;col_extent&#39;</span><span class="p">:</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">extent</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
                <span class="p">}</span>

                <span class="n">pool_dict</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">base_ids</span><span class="p">)</span>
                <span class="n">pool_dict</span><span class="o">.</span><span class="n">update</span><span class="p">({</span>
                    <span class="s1">&#39;sum_default&#39;</span><span class="p">:</span> <span class="n">sum_default</span><span class="p">,</span>
                    <span class="s1">&#39;row_extent&#39;</span><span class="p">:</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">extent</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span>
                    <span class="s1">&#39;col_extent&#39;</span><span class="p">:</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">extent</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span>
                    <span class="s1">&#39;row_size&#39;</span><span class="p">:</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">geometry</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span>
                    <span class="s1">&#39;col_size&#39;</span><span class="p">:</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">geometry</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span>
                    <span class="s1">&#39;operation&#39;</span><span class="p">:</span> <span class="n">tabify</span><span class="p">(</span><span class="n">pool_op_code</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
                    <span class="s1">&#39;operation_reduce&#39;</span><span class="p">:</span> <span class="n">pool_op_reduce_code</span>
                <span class="p">})</span>

                <span class="n">pool_template</span><span class="p">[</span><span class="s1">&#39;psp_body&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">cuda_pooling_code_2d_small_extent</span><span class="p">[</span><span class="s1">&#39;psp_body&#39;</span><span class="p">]</span> <span class="o">%</span> <span class="n">pool_dict</span>
                <span class="n">pool_template</span><span class="p">[</span><span class="s1">&#39;psp_header&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">cuda_pooling_code_2d_small_extent</span><span class="p">[</span><span class="s1">&#39;psp_header&#39;</span><span class="p">]</span> <span class="o">%</span> <span class="n">pool_dict</span>
                <span class="n">pool_template</span><span class="p">[</span><span class="s1">&#39;psp_call&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">cuda_pooling_code_2d_small_extent</span><span class="p">[</span><span class="s1">&#39;psp_call&#39;</span><span class="p">]</span> <span class="o">%</span> <span class="n">pool_dict</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="n">pool_op_reduce_code</span> <span class="o">=</span> <span class="n">cuda_pooling_code_2d</span><span class="p">[</span><span class="s1">&#39;reduce_code&#39;</span><span class="p">][</span><span class="n">pool_operation</span><span class="p">]</span> <span class="o">%</span> <span class="p">{</span>
                    <span class="s1">&#39;float_prec&#39;</span><span class="p">:</span> <span class="n">Global</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;precision&#39;</span><span class="p">],</span>
                    <span class="s1">&#39;row_extent&#39;</span><span class="p">:</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">extent</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span>
                    <span class="s1">&#39;col_extent&#39;</span><span class="p">:</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">extent</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
                <span class="p">}</span>

                <span class="n">pool_dict</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">base_ids</span><span class="p">)</span>
                <span class="n">pool_dict</span><span class="o">.</span><span class="n">update</span><span class="p">({</span>
                    <span class="s1">&#39;sum_default&#39;</span><span class="p">:</span> <span class="n">sum_default</span><span class="p">,</span>
                    <span class="s1">&#39;row_extent&#39;</span><span class="p">:</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">extent</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span>
                    <span class="s1">&#39;col_extent&#39;</span><span class="p">:</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">extent</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span>
                    <span class="s1">&#39;row_size&#39;</span><span class="p">:</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">geometry</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span>
                    <span class="s1">&#39;col_size&#39;</span><span class="p">:</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">geometry</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span>
                    <span class="s1">&#39;operation&#39;</span><span class="p">:</span> <span class="n">tabify</span><span class="p">(</span><span class="n">pool_op_code</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
                    <span class="s1">&#39;operation_reduce&#39;</span><span class="p">:</span> <span class="n">tabify</span><span class="p">(</span><span class="n">pool_op_reduce_code</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
                <span class="p">})</span>

                <span class="n">pool_template</span><span class="p">[</span><span class="s1">&#39;psp_body&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">remove_trailing_spaces</span><span class="p">(</span><span class="n">cuda_pooling_code_2d</span><span class="p">[</span><span class="s1">&#39;psp_body&#39;</span><span class="p">]</span> <span class="o">%</span> <span class="n">pool_dict</span><span class="p">)</span>
                <span class="n">pool_template</span><span class="p">[</span><span class="s1">&#39;psp_header&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">cuda_pooling_code_2d</span><span class="p">[</span><span class="s1">&#39;psp_header&#39;</span><span class="p">]</span> <span class="o">%</span> <span class="n">pool_dict</span>
                <span class="n">pool_template</span><span class="p">[</span><span class="s1">&#39;psp_call&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">cuda_pooling_code_2d</span><span class="p">[</span><span class="s1">&#39;psp_call&#39;</span><span class="p">]</span> <span class="o">%</span> <span class="n">pool_dict</span>

        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">geometry</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>

            <span class="n">pool_dict</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">base_ids</span><span class="p">)</span>
            <span class="n">pool_dict</span><span class="o">.</span><span class="n">update</span><span class="p">({</span>
                <span class="s1">&#39;sum_default&#39;</span><span class="p">:</span> <span class="n">sum_default</span><span class="p">,</span>
                <span class="s1">&#39;row_extent&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">extent</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                <span class="s1">&#39;col_extent&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">extent</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                <span class="s1">&#39;plane_extent&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">extent</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span>
                <span class="s1">&#39;row_size&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">geometry</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                <span class="s1">&#39;col_size&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">geometry</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                <span class="s1">&#39;plane_size&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">geometry</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span>
                <span class="s1">&#39;operation&#39;</span><span class="p">:</span> <span class="n">tabify</span><span class="p">(</span><span class="n">pool_op_code</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
            <span class="p">})</span>

            <span class="n">pool_template</span><span class="p">[</span><span class="s1">&#39;psp_body&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">remove_trailing_spaces</span><span class="p">(</span><span class="n">cuda_pooling_code_3d</span><span class="p">[</span><span class="s1">&#39;psp_body&#39;</span><span class="p">]</span> <span class="o">%</span> <span class="n">pool_dict</span><span class="p">)</span>
            <span class="n">pool_template</span><span class="p">[</span><span class="s1">&#39;psp_header&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">cuda_pooling_code_3d</span><span class="p">[</span><span class="s1">&#39;psp_header&#39;</span><span class="p">]</span> <span class="o">%</span> <span class="n">pool_dict</span>
            <span class="n">pool_template</span><span class="p">[</span><span class="s1">&#39;psp_call&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">cuda_pooling_code_3d</span><span class="p">[</span><span class="s1">&#39;psp_header&#39;</span><span class="p">]</span> <span class="o">%</span> <span class="n">pool_dict</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span>

        <span class="c1"># Update psp fields</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_specific_template</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">pool_template</span><span class="p">)</span>

        <span class="c1"># Specific template for generation (wrapper, etc)</span>
        <span class="n">pool_dict</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">pooling_template_cuda</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">pool_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">value</span> <span class="o">=</span> <span class="n">value</span> <span class="o">%</span> <span class="n">base_ids</span>
            <span class="n">pool_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_specific_template</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">pool_dict</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_specific_template</span><span class="p">[</span><span class="s1">&#39;wrapper_connector_call&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_specific_template</span><span class="p">[</span><span class="s1">&#39;access_parameters_variables&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_specific_template</span><span class="p">[</span><span class="s1">&#39;size_in_bytes&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;//TODO:</span><span class="se">\n</span><span class="s2">&quot;</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_coordinates_to_rank</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">geometry</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generate the code for array access, for instance used</span>
<span class="sd">        for pre-synaptic ranks.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">dim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">geometry</span><span class="p">)</span>

        <span class="n">txt</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>

        <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">dim</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">txt</span> <span class="o">==</span> <span class="s2">&quot;&quot;</span><span class="p">:</span>   <span class="c1"># first coordinate is special</span>
                <span class="n">txt</span> <span class="o">=</span> <span class="n">indices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot;_&quot;</span> <span class="o">+</span> <span class="n">name</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">txt</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">geometry</span><span class="p">[</span><span class="n">d</span><span class="p">])</span> <span class="o">+</span> <span class="s1">&#39;*(&#39;</span> <span class="o">+</span> <span class="n">txt</span> <span class="o">+</span> <span class="s1">&#39;) + &#39;</span> <span class="o">+</span> <span class="n">indices</span><span class="p">[</span><span class="n">d</span><span class="p">]</span> <span class="o">+</span> <span class="s1">&#39;_&#39;</span> <span class="o">+</span> <span class="n">name</span>

        <span class="k">return</span> <span class="n">txt</span>

    <span class="c1">##############################</span>
    <span class="c1">## Override useless methods</span>
    <span class="c1">##############################</span>
    <span class="k">def</span> <span class="nf">_data</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="s2">&quot;Disable saving.&quot;</span>
        <span class="n">desc</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">desc</span><span class="p">[</span><span class="s1">&#39;post_ranks&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">post_ranks</span>
        <span class="n">desc</span><span class="p">[</span><span class="s1">&#39;attributes&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attributes</span>
        <span class="n">desc</span><span class="p">[</span><span class="s1">&#39;parameters&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span>
        <span class="n">desc</span><span class="p">[</span><span class="s1">&#39;variables&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">variables</span>

        <span class="n">desc</span><span class="p">[</span><span class="s1">&#39;dendrites&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">desc</span><span class="p">[</span><span class="s1">&#39;number_of_synapses&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">return</span> <span class="n">desc</span>

    <span class="k">def</span> <span class="nf">save_connectivity</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filename</span><span class="p">):</span>
        <span class="s2">&quot;Not available.&quot;</span>
        <span class="n">Global</span><span class="o">.</span><span class="n">_warning</span><span class="p">(</span><span class="s1">&#39;Pooling projections can not be saved.&#39;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filename</span><span class="p">):</span>
        <span class="s2">&quot;Not available.&quot;</span>
        <span class="n">Global</span><span class="o">.</span><span class="n">_warning</span><span class="p">(</span><span class="s1">&#39;Pooling projections can not be saved.&#39;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filename</span><span class="p">):</span>
        <span class="s2">&quot;Not available.&quot;</span>
        <span class="n">Global</span><span class="o">.</span><span class="n">_warning</span><span class="p">(</span><span class="s1">&#39;Pooling projections can not be loaded.&#39;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">receptive_fields</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">variable</span> <span class="o">=</span> <span class="s1">&#39;w&#39;</span><span class="p">,</span> <span class="n">in_post_geometry</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
        <span class="s2">&quot;Not available.&quot;</span>
        <span class="n">Global</span><span class="o">.</span><span class="n">_warning</span><span class="p">(</span><span class="s1">&#39;Pooling projections can not display receptive fields.&#39;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">connectivity_matrix</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="mf">0.0</span><span class="p">):</span>
        <span class="s2">&quot;Not available.&quot;</span>
        <span class="n">Global</span><span class="o">.</span><span class="n">_warning</span><span class="p">(</span><span class="s1">&#39;Pooling projections can not display connectivity matrices.&#39;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
        </details>

  

  <div class="doc doc-children">









<div class="doc doc-object doc-function">



<h4 id="ANNarchy.extensions.convolution.Pooling.Pooling.__init__" class="doc doc-heading">
<code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">pre</span><span class="p">,</span> <span class="n">post</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">psp</span><span class="o">=</span><span class="s1">&#39;pre.r&#39;</span><span class="p">,</span> <span class="n">operation</span><span class="o">=</span><span class="s1">&#39;max&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">copied</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

<a href="#ANNarchy.extensions.convolution.Pooling.Pooling.__init__" class="headerlink" title="Permanent link">#</a></h4>


  <div class="doc doc-contents ">
  
      

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>pre</code></td>
          <td>
          </td>
          <td><p>pre-synaptic population (either its name or a <code>Population</code> object).</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>post</code></td>
          <td>
          </td>
          <td><p>post-synaptic population (either its name or a <code>Population</code> object).</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>target</code></td>
          <td>
          </td>
          <td><p>type of the connection</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>operation</code></td>
          <td>
          </td>
          <td><p>pooling function to be applied ("max", "min", "mean")</p></td>
          <td>
                <code>&#39;max&#39;</code>
          </td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>ANNarchy/extensions/convolution/Pooling.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span>
<span class="normal">84</span>
<span class="normal">85</span>
<span class="normal">86</span>
<span class="normal">87</span>
<span class="normal">88</span>
<span class="normal">89</span>
<span class="normal">90</span>
<span class="normal">91</span>
<span class="normal">92</span>
<span class="normal">93</span>
<span class="normal">94</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pre</span><span class="p">,</span> <span class="n">post</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">psp</span><span class="o">=</span><span class="s2">&quot;pre.r&quot;</span><span class="p">,</span> <span class="n">operation</span><span class="o">=</span><span class="s2">&quot;max&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">copied</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    :param pre: pre-synaptic population (either its name or a ``Population`` object).</span>
<span class="sd">    :param post: post-synaptic population (either its name or a ``Population`` object).</span>
<span class="sd">    :param target: type of the connection</span>
<span class="sd">    :param operation: pooling function to be applied (&quot;max&quot;, &quot;min&quot;, &quot;mean&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Sanity check</span>
    <span class="c1">#if not pre.neuron_type.type == &#39;rate&#39;:</span>
    <span class="c1">#    Global._error(&#39;Pooling: only implemented for rate-coded populations.&#39;)</span>

    <span class="c1"># Sanity check</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">operation</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;max&quot;</span><span class="p">,</span> <span class="s2">&quot;mean&quot;</span><span class="p">,</span> <span class="s2">&quot;min&quot;</span><span class="p">]:</span>
        <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s2">&quot;Pooling: the operation must be either &#39;max&#39;, &#39;mean&#39; or &#39;min&#39;.&quot;</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">operation</span> <span class="o">=</span> <span class="n">operation</span>

    <span class="c1"># Store for _copy</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">psp</span> <span class="o">=</span> <span class="n">psp</span>

    <span class="n">Projection</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">pre</span><span class="p">,</span>
        <span class="n">post</span><span class="p">,</span>
        <span class="n">target</span><span class="p">,</span>
        <span class="n">synapse</span><span class="o">=</span><span class="n">SharedSynapse</span><span class="p">(</span><span class="n">psp</span><span class="o">=</span><span class="n">psp</span><span class="p">,</span> <span class="n">operation</span><span class="o">=</span><span class="n">operation</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;Pooling operation&quot;</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="n">operation</span><span class="o">+</span><span class="s2">&quot;-pooling operation over the pre-synaptic population.&quot;</span><span class="p">),</span>
        <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
        <span class="n">copied</span><span class="o">=</span><span class="n">copied</span>
    <span class="p">)</span>

    <span class="c1"># check dimensions of populations, should not exceed 4</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dim_pre</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">dimension</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dim_post</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">dimension</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_post</span> <span class="o">&gt;</span> <span class="mi">4</span><span class="p">:</span>
        <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s1">&#39;Pooling: Too many dimensions for the post-synaptic population (maximum 4).&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_pre</span> <span class="o">&gt;</span> <span class="mi">4</span><span class="p">:</span>
        <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s1">&#39;Pooling: Too many dimensions for the pre-synaptic population (maximum 4).&#39;</span><span class="p">)</span>

    <span class="c1"># Disable saving</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_saveable</span> <span class="o">=</span> <span class="kc">False</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h4 id="ANNarchy.extensions.convolution.Pooling.Pooling.connect_pooling" class="doc doc-heading">
<code class="highlight language-python"><span class="n">connect_pooling</span><span class="p">(</span><span class="n">extent</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">delays</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span></code>

<a href="#ANNarchy.extensions.convolution.Pooling.Pooling.connect_pooling" class="headerlink" title="Permanent link">#</a></h4>


  <div class="doc doc-contents ">
  
      

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>extent</code></td>
          <td>
          </td>
          <td><p>extent of the pooling area expressed in the geometry of the pre-synaptic population (e.g <code>(2, 2)</code>). In each dimension, the product of this extent with the number of neurons in the post-synaptic population must be equal to the number of pre-synaptic neurons. Default: None.</p></td>
          <td>
                <code>None</code>
          </td>
        </tr>
        <tr>
          <td><code>delays</code></td>
          <td>
          </td>
          <td><p>synaptic delay in ms</p></td>
          <td>
                <code>0.0</code>
          </td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>ANNarchy/extensions/convolution/Pooling.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">connect_pooling</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">extent</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">delays</span><span class="o">=</span><span class="mf">0.0</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    :param extent: extent of the pooling area expressed in the geometry of the pre-synaptic population (e.g ``(2, 2)``). In each dimension, the product of this extent with the number of neurons in the post-synaptic population must be equal to the number of pre-synaptic neurons. Default: None.</span>
<span class="sd">    :param delays: synaptic delay in ms</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># process extent</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">extent_init</span> <span class="o">=</span> <span class="n">extent</span>
    <span class="k">if</span> <span class="n">extent</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>  <span class="c1"># compute the extent automatically</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">dimension</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">dimension</span><span class="p">:</span>
            <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span>
                <span class="s1">&#39;Pooling: If you do not provide the extent parameter, the two populations must have the same number of dimensions.&#39;</span><span class="p">)</span>

        <span class="n">extent</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">geometry</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">dim</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">dimension</span><span class="p">):</span>
            <span class="n">extent</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="o">/=</span> <span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">geometry</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">geometry</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="o">!=</span> <span class="n">extent</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">geometry</span><span class="p">[</span><span class="n">dim</span><span class="p">]:</span>
                <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span>
                    <span class="s1">&#39;Pooling: Unable to compute the extent of the pooling area: the number of neurons do not match.&#39;</span><span class="p">)</span>

    <span class="k">elif</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">extent</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
        <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s1">&#39;Pooling: You must provide a tuple for the extent of the pooling operation.&#39;</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">extent</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">extent</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">extent</span><span class="p">)</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">dimension</span><span class="p">:</span>
        <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s1">&#39;Pooling: You must provide a tuple for the extent of the pooling operation.&#39;</span><span class="p">)</span>

    <span class="c1"># process delays</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">delays</span> <span class="o">=</span> <span class="n">delays</span>

    <span class="c1"># Generate the pre-synaptic coordinates</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_generate_extent_coordinates</span><span class="p">()</span>

    <span class="c1"># create fake LIL</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_create</span><span class="p">()</span>

    <span class="k">return</span> <span class="bp">self</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h4 id="ANNarchy.extensions.convolution.Pooling.Pooling.connectivity_matrix" class="doc doc-heading">
<code class="highlight language-python"><span class="n">connectivity_matrix</span><span class="p">(</span><span class="n">fill</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span></code>

<a href="#ANNarchy.extensions.convolution.Pooling.Pooling.connectivity_matrix" class="headerlink" title="Permanent link">#</a></h4>


  <div class="doc doc-contents ">
  
      <p>Not available.</p>

      <details class="quote">
        <summary>Source code in <code>ANNarchy/extensions/convolution/Pooling.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">634</span>
<span class="normal">635</span>
<span class="normal">636</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">connectivity_matrix</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="mf">0.0</span><span class="p">):</span>
    <span class="s2">&quot;Not available.&quot;</span>
    <span class="n">Global</span><span class="o">.</span><span class="n">_warning</span><span class="p">(</span><span class="s1">&#39;Pooling projections can not display connectivity matrices.&#39;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h4 id="ANNarchy.extensions.convolution.Pooling.Pooling.load" class="doc doc-heading">
<code class="highlight language-python"><span class="n">load</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span></code>

<a href="#ANNarchy.extensions.convolution.Pooling.Pooling.load" class="headerlink" title="Permanent link">#</a></h4>


  <div class="doc doc-contents ">
  
      <p>Not available.</p>

      <details class="quote">
        <summary>Source code in <code>ANNarchy/extensions/convolution/Pooling.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">628</span>
<span class="normal">629</span>
<span class="normal">630</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filename</span><span class="p">):</span>
    <span class="s2">&quot;Not available.&quot;</span>
    <span class="n">Global</span><span class="o">.</span><span class="n">_warning</span><span class="p">(</span><span class="s1">&#39;Pooling projections can not be loaded.&#39;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h4 id="ANNarchy.extensions.convolution.Pooling.Pooling.receptive_fields" class="doc doc-heading">
<code class="highlight language-python"><span class="n">receptive_fields</span><span class="p">(</span><span class="n">variable</span><span class="o">=</span><span class="s1">&#39;w&#39;</span><span class="p">,</span> <span class="n">in_post_geometry</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></code>

<a href="#ANNarchy.extensions.convolution.Pooling.Pooling.receptive_fields" class="headerlink" title="Permanent link">#</a></h4>


  <div class="doc doc-contents ">
  
      <p>Not available.</p>

      <details class="quote">
        <summary>Source code in <code>ANNarchy/extensions/convolution/Pooling.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">631</span>
<span class="normal">632</span>
<span class="normal">633</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">receptive_fields</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">variable</span> <span class="o">=</span> <span class="s1">&#39;w&#39;</span><span class="p">,</span> <span class="n">in_post_geometry</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
    <span class="s2">&quot;Not available.&quot;</span>
    <span class="n">Global</span><span class="o">.</span><span class="n">_warning</span><span class="p">(</span><span class="s1">&#39;Pooling projections can not display receptive fields.&#39;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h4 id="ANNarchy.extensions.convolution.Pooling.Pooling.save" class="doc doc-heading">
<code class="highlight language-python"><span class="n">save</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span></code>

<a href="#ANNarchy.extensions.convolution.Pooling.Pooling.save" class="headerlink" title="Permanent link">#</a></h4>


  <div class="doc doc-contents ">
  
      <p>Not available.</p>

      <details class="quote">
        <summary>Source code in <code>ANNarchy/extensions/convolution/Pooling.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">625</span>
<span class="normal">626</span>
<span class="normal">627</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filename</span><span class="p">):</span>
    <span class="s2">&quot;Not available.&quot;</span>
    <span class="n">Global</span><span class="o">.</span><span class="n">_warning</span><span class="p">(</span><span class="s1">&#39;Pooling projections can not be saved.&#39;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h4 id="ANNarchy.extensions.convolution.Pooling.Pooling.save_connectivity" class="doc doc-heading">
<code class="highlight language-python"><span class="n">save_connectivity</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span></code>

<a href="#ANNarchy.extensions.convolution.Pooling.Pooling.save_connectivity" class="headerlink" title="Permanent link">#</a></h4>


  <div class="doc doc-contents ">
  
      <p>Not available.</p>

      <details class="quote">
        <summary>Source code in <code>ANNarchy/extensions/convolution/Pooling.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">622</span>
<span class="normal">623</span>
<span class="normal">624</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">save_connectivity</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filename</span><span class="p">):</span>
    <span class="s2">&quot;Not available.&quot;</span>
    <span class="n">Global</span><span class="o">.</span><span class="n">_warning</span><span class="p">(</span><span class="s1">&#39;Pooling projections can not be saved.&#39;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>



  </div>

  </div>

</div>




  </div>

  </div>

</div>

<div class="doc doc-object doc-module">



<h2 id="ANNarchy.extensions.convolution.Copy" class="doc doc-heading">
          <code>ANNarchy.extensions.convolution.Copy</code>


<a href="#ANNarchy.extensions.convolution.Copy" class="headerlink" title="Permanent link">#</a></h2>

  <div class="doc doc-contents first">

  

  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h3 id="ANNarchy.extensions.convolution.Copy.Copy" class="doc doc-heading">
        <code>Copy</code>


<a href="#ANNarchy.extensions.convolution.Copy.Copy" class="headerlink" title="Permanent link">#</a></h3>


  <div class="doc doc-contents ">
      <p class="doc doc-class-bases">
        Bases: <code><a title="ANNarchy.core.Projection.Projection" href="../Projection.html#ANNarchy.Projection">Projection</a></code></p>

  
      <p>Creates a virtual projection reusing the weights and delays of an already-defined projection.</p>
<p>Although the original projection can be learnable, this one can not. Changes in the original weights will be reflected in this projection. The only possible modifications are <code>psp</code> and <code>operation</code>.</p>
<p>The pre- and post-synaptic populations of both projections must have the same geometry.</p>
<p>Example:</p>
<div class="highlight"><pre><span></span><code><span class="n">proj</span> <span class="o">=</span> <span class="n">Projection</span><span class="p">(</span><span class="n">pop1</span><span class="p">,</span> <span class="n">pop2</span><span class="p">,</span> <span class="s2">&quot;exc&quot;</span><span class="p">)</span>
<span class="n">proj</span><span class="o">.</span><span class="n">connect_fixed_probability</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>

<span class="n">copy_proj</span> <span class="o">=</span> <span class="n">Copy</span><span class="p">(</span><span class="n">pop1</span><span class="p">,</span> <span class="n">pop3</span><span class="p">,</span> <span class="s2">&quot;exc&quot;</span><span class="p">)</span>
<span class="n">copy_proj</span><span class="o">.</span><span class="n">connect_copy</span><span class="p">(</span><span class="n">proj</span><span class="p">)</span>
</code></pre></div>


        <details class="quote">
          <summary>Source code in <code>ANNarchy/extensions/convolution/Copy.py</code></summary>
          <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">Copy</span><span class="p">(</span><span class="n">Projection</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Creates a virtual projection reusing the weights and delays of an already-defined projection.</span>

<span class="sd">    Although the original projection can be learnable, this one can not. Changes in the original weights will be reflected in this projection. The only possible modifications are ``psp`` and ``operation``.</span>

<span class="sd">    The pre- and post-synaptic populations of both projections must have the same geometry.</span>

<span class="sd">    Example:</span>

<span class="sd">    ```python</span>
<span class="sd">    proj = Projection(pop1, pop2, &quot;exc&quot;)</span>
<span class="sd">    proj.connect_fixed_probability(0.1, 0.5)</span>

<span class="sd">    copy_proj = Copy(pop1, pop3, &quot;exc&quot;)</span>
<span class="sd">    copy_proj.connect_copy(proj)</span>
<span class="sd">    ```</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pre</span><span class="p">,</span> <span class="n">post</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">psp</span><span class="o">=</span><span class="s2">&quot;pre.r * w&quot;</span><span class="p">,</span> <span class="n">operation</span><span class="o">=</span><span class="s2">&quot;sum&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">copied</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :param pre: pre-synaptic population (either its name or a ``Population`` object).</span>
<span class="sd">        :param post: post-synaptic population (either its name or a ``Population`` object).</span>
<span class="sd">        :param target: type of the connection</span>
<span class="sd">        :param psp: continuous influence of a single synapse on the post-synaptic neuron (default for rate-coded: ``w*pre.r``).</span>
<span class="sd">        :param operation: operation (sum, max, min, mean) performed by the kernel (default: sum).</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Create the description, but it will not be used for generation</span>
        <span class="n">Projection</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="n">pre</span><span class="o">=</span><span class="n">pre</span><span class="p">,</span>
            <span class="n">post</span><span class="o">=</span><span class="n">post</span><span class="p">,</span>
            <span class="n">target</span><span class="o">=</span><span class="n">target</span><span class="p">,</span>
            <span class="n">synapse</span> <span class="o">=</span> <span class="n">SharedSynapse</span><span class="p">(</span><span class="n">psp</span><span class="o">=</span><span class="n">psp</span><span class="p">,</span> <span class="n">operation</span><span class="o">=</span><span class="n">operation</span><span class="p">),</span>
            <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
            <span class="n">copied</span><span class="o">=</span><span class="n">copied</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">connect_copy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">projection</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :param projection: Existing projection to copy.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">projection</span> <span class="o">=</span> <span class="n">projection</span>

        <span class="c1"># Sanity checks</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">projection</span><span class="p">,</span> <span class="n">Projection</span><span class="p">):</span>
            <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s1">&#39;Copy: You must provide an existing projection to copy().&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">projection</span><span class="p">,</span> <span class="p">(</span><span class="n">ConvolutionProjection</span><span class="p">,</span> <span class="n">PoolingProjection</span><span class="p">)):</span>
            <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s1">&#39;Copy: You can only copy regular projections, not shared projections.&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">geometry</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">projection</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">geometry</span> <span class="ow">or</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">geometry</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">projection</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">geometry</span><span class="p">:</span>
            <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s1">&#39;Copy: When copying a projection, the geometries must be the same.&#39;</span><span class="p">)</span>

        <span class="c1"># Dummy weights</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pre_coordinates</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># Finish building the synapses</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_create</span><span class="p">()</span>

        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">_copy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pre</span><span class="p">,</span> <span class="n">post</span><span class="p">):</span>
        <span class="s2">&quot;Returns a copy of the projection when creating networks. Internal use only.&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="k">def</span> <span class="nf">_create</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># create fake LIL object, just for compilation.</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="kn">from</span> <span class="nn">ANNarchy.core.cython_ext.Connector</span> <span class="kn">import</span> <span class="n">LILConnectivity</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">Global</span><span class="o">.</span><span class="n">_print</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
            <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s1">&#39;ANNarchy was not successfully installed.&#39;</span><span class="p">)</span>

        <span class="n">lil</span> <span class="o">=</span> <span class="n">LILConnectivity</span><span class="p">()</span>
        <span class="n">lil</span><span class="o">.</span><span class="n">max_delay</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">delays</span>
        <span class="n">lil</span><span class="o">.</span><span class="n">uniform_delay</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">delays</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">connector_name</span> <span class="o">=</span> <span class="s2">&quot;Copy&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">connector_description</span> <span class="o">=</span> <span class="s2">&quot;Copy projection&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_store_connectivity</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_load_from_lil</span><span class="p">,</span> <span class="p">(</span><span class="n">lil</span><span class="p">,</span> <span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">delays</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_connect</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">module</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Builds up dendrites either from list or dictionary. Called by instantiate().</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_connection_method</span><span class="p">:</span>
            <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s1">&#39;Copy: The projection between &#39;</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39; and &#39;</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39; is declared but not connected.&#39;</span><span class="p">)</span>

        <span class="c1"># Create the Cython instance</span>
        <span class="n">proj</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="s1">&#39;proj&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">id</span><span class="p">)</span><span class="o">+</span><span class="s1">&#39;_wrapper&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cyInstance</span> <span class="o">=</span> <span class="n">proj</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre_coordinates</span><span class="p">)</span>

        <span class="c1"># Define the list of postsynaptic neurons</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">post_ranks</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">size</span><span class="p">))</span>

        <span class="c1"># Set delays after instantiation</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">delays</span> <span class="o">&gt;</span> <span class="mf">0.0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">cyInstance</span><span class="o">.</span><span class="n">set_delay</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">delays</span><span class="o">/</span><span class="n">Global</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;dt&#39;</span><span class="p">])</span>

        <span class="k">return</span> <span class="kc">True</span>

    <span class="k">def</span> <span class="nf">_generate</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overrides default code generation. This function is called during the code generation procedure.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">Global</span><span class="o">.</span><span class="n">_check_paradigm</span><span class="p">(</span><span class="s2">&quot;openmp&quot;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_generate_omp</span><span class="p">()</span>
        <span class="k">elif</span> <span class="n">Global</span><span class="o">.</span><span class="n">_check_paradigm</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_generate_cuda</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="k">def</span> <span class="nf">generate_omp</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Code generation of CopyProjection object for the openMP paradigm.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Set the projection specific parameters</span>
        <span class="n">copy_proj_dict</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">copy_proj_template</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">copy_proj_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">value</span> <span class="o">=</span> <span class="n">value</span> <span class="o">%</span> <span class="p">{</span>
                <span class="s1">&#39;id_proj&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">id</span><span class="p">,</span>
                <span class="s1">&#39;id_copy&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">projection</span><span class="o">.</span><span class="n">id</span><span class="p">,</span>
                <span class="s1">&#39;float_prec&#39;</span><span class="p">:</span> <span class="n">Global</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;precision&#39;</span><span class="p">]</span>
            <span class="p">}</span>
            <span class="n">copy_proj_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>

        <span class="c1"># Update specific template</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_specific_template</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">copy_proj_dict</span><span class="p">)</span>

        <span class="c1"># OMP code if more then one thread</span>
        <span class="k">if</span> <span class="n">Global</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;num_threads&#39;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">omp_code</span> <span class="o">=</span> <span class="s1">&#39;#pragma omp for private(sum)&#39;</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="n">Global</span><span class="o">.</span><span class="n">OMP_MIN_NB_NEURONS</span> <span class="k">else</span> <span class="s1">&#39;&#39;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">omp_code</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>

        <span class="c1"># PSP</span>
        <span class="n">psp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">synapse_type</span><span class="o">.</span><span class="n">description</span><span class="p">[</span><span class="s1">&#39;psp&#39;</span><span class="p">][</span><span class="s1">&#39;cpp&#39;</span><span class="p">]</span>  <span class="o">%</span> <span class="p">{</span>
            <span class="s1">&#39;id_pre&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">id</span><span class="p">,</span>
            <span class="s1">&#39;id_post&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">id</span><span class="p">,</span>
            <span class="s1">&#39;local_index&#39;</span><span class="p">:</span><span class="s1">&#39;[i][j]&#39;</span><span class="p">,</span>
            <span class="s1">&#39;global_index&#39;</span><span class="p">:</span> <span class="s1">&#39;[i]&#39;</span><span class="p">,</span>
            <span class="s1">&#39;pre_index&#39;</span><span class="p">:</span> <span class="s1">&#39;[pre_rank[i][j]]&#39;</span><span class="p">,</span>
            <span class="s1">&#39;post_index&#39;</span><span class="p">:</span> <span class="s1">&#39;[post_rank[i]]&#39;</span><span class="p">,</span>
            <span class="s1">&#39;pre_prefix&#39;</span><span class="p">:</span> <span class="s1">&#39;pop&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">id</span><span class="p">)</span><span class="o">+</span><span class="s1">&#39;.&#39;</span><span class="p">,</span>
            <span class="s1">&#39;post_prefix&#39;</span><span class="p">:</span> <span class="s1">&#39;pop&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">id</span><span class="p">)</span><span class="o">+</span><span class="s1">&#39;.&#39;</span><span class="p">}</span>
        <span class="n">psp</span> <span class="o">=</span> <span class="n">psp</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;rk_pre&#39;</span><span class="p">,</span> <span class="s1">&#39;pre_rank[i][j]&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)</span>

        <span class="c1"># Take delays into account if any</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">delays</span> <span class="o">&gt;</span> <span class="n">Global</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;dt&#39;</span><span class="p">]:</span>
            <span class="n">psp</span> <span class="o">=</span> <span class="n">psp</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span>
                <span class="s1">&#39;pop</span><span class="si">%(id_pre)s</span><span class="s1">.r[rk_pre]&#39;</span> <span class="o">%</span> <span class="p">{</span><span class="s1">&#39;id_pre&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">id</span><span class="p">},</span>
                <span class="s1">&#39;pop</span><span class="si">%(id_pre)s</span><span class="s1">._delayed_r[delay-1][rk_pre]&#39;</span> <span class="o">%</span> <span class="p">{</span><span class="s1">&#39;id_pre&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">id</span><span class="p">}</span>
                <span class="c1"># TODO HD: wouldn&#39;t it be much better to reduce delay globaly, instead of the substraction here???</span>
            <span class="p">)</span>

        <span class="c1"># Select template for operation to be performed: sum, max, min, mean</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">sum_code</span> <span class="o">=</span> <span class="n">copy_sum_template</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">synapse_type</span><span class="o">.</span><span class="n">operation</span><span class="p">]</span>
        <span class="k">except</span> <span class="ne">KeyError</span><span class="p">:</span>
            <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s2">&quot;CopyProjection: the operation &quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">synapse_type</span><span class="o">.</span><span class="n">operation</span><span class="p">,</span> <span class="s1">&#39; is not available.&#39;</span><span class="p">)</span>

        <span class="c1"># Finalize code</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">generator</span><span class="p">[</span><span class="s1">&#39;omp&#39;</span><span class="p">][</span><span class="s1">&#39;body_compute_psp&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">sum_code</span> <span class="o">%</span> <span class="p">{</span>
            <span class="s1">&#39;id_proj&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">id</span><span class="p">,</span> <span class="s1">&#39;target&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="p">,</span>
            <span class="s1">&#39;id_pre&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">id</span><span class="p">,</span> <span class="s1">&#39;name_pre&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
            <span class="s1">&#39;id_post&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">id</span><span class="p">,</span> <span class="s1">&#39;name_post&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
            <span class="s1">&#39;id&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">projection</span><span class="o">.</span><span class="n">id</span><span class="p">,</span>
            <span class="s1">&#39;float_prec&#39;</span><span class="p">:</span> <span class="n">Global</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;precision&#39;</span><span class="p">],</span>
            <span class="s1">&#39;omp_code&#39;</span><span class="p">:</span> <span class="n">omp_code</span><span class="p">,</span>
            <span class="s1">&#39;psp&#39;</span><span class="p">:</span> <span class="n">psp</span>
        <span class="p">}</span>

    <span class="k">def</span> <span class="nf">_generate_cuda</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Code generation of CopyProjection object for the CUDA paradigm.</span>

<span class="sd">        Note: currently not implemented (TODO HD)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="c1">##############################</span>
    <span class="c1">## Override useless methods</span>
    <span class="c1">##############################</span>
    <span class="k">def</span> <span class="nf">_data</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="s2">&quot;Disable saving.&quot;</span>
        <span class="n">desc</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">desc</span><span class="p">[</span><span class="s1">&#39;post_ranks&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">post_ranks</span>
        <span class="n">desc</span><span class="p">[</span><span class="s1">&#39;attributes&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attributes</span>
        <span class="n">desc</span><span class="p">[</span><span class="s1">&#39;parameters&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span>
        <span class="n">desc</span><span class="p">[</span><span class="s1">&#39;variables&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">variables</span>

        <span class="n">desc</span><span class="p">[</span><span class="s1">&#39;dendrites&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">desc</span><span class="p">[</span><span class="s1">&#39;number_of_synapses&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">return</span> <span class="n">desc</span>

    <span class="k">def</span> <span class="nf">save_connectivity</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filename</span><span class="p">):</span>
        <span class="s2">&quot;Not available.&quot;</span>
        <span class="n">Global</span><span class="o">.</span><span class="n">_warning</span><span class="p">(</span><span class="s1">&#39;Copied projections can not be saved.&#39;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filename</span><span class="p">):</span>
        <span class="s2">&quot;Not available.&quot;</span>
        <span class="n">Global</span><span class="o">.</span><span class="n">_warning</span><span class="p">(</span><span class="s1">&#39;Copied projections can not be saved.&#39;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filename</span><span class="p">):</span>
        <span class="s2">&quot;Not available.&quot;</span>
        <span class="n">Global</span><span class="o">.</span><span class="n">_warning</span><span class="p">(</span><span class="s1">&#39;Copied projections can not be loaded.&#39;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">receptive_fields</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">variable</span> <span class="o">=</span> <span class="s1">&#39;w&#39;</span><span class="p">,</span> <span class="n">in_post_geometry</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
        <span class="s2">&quot;Not available.&quot;</span>
        <span class="n">Global</span><span class="o">.</span><span class="n">_warning</span><span class="p">(</span><span class="s1">&#39;Copied projections can not display receptive fields.&#39;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">connectivity_matrix</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="mf">0.0</span><span class="p">):</span>
        <span class="s2">&quot;Not available.&quot;</span>
        <span class="n">Global</span><span class="o">.</span><span class="n">_warning</span><span class="p">(</span><span class="s1">&#39;Copied projections can not display connectivity matrices.&#39;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
        </details>

  

  <div class="doc doc-children">









<div class="doc doc-object doc-function">



<h4 id="ANNarchy.extensions.convolution.Copy.Copy.__init__" class="doc doc-heading">
<code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">pre</span><span class="p">,</span> <span class="n">post</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">psp</span><span class="o">=</span><span class="s1">&#39;pre.r * w&#39;</span><span class="p">,</span> <span class="n">operation</span><span class="o">=</span><span class="s1">&#39;sum&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">copied</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

<a href="#ANNarchy.extensions.convolution.Copy.Copy.__init__" class="headerlink" title="Permanent link">#</a></h4>


  <div class="doc doc-contents ">
  
      

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>pre</code></td>
          <td>
          </td>
          <td><p>pre-synaptic population (either its name or a <code>Population</code> object).</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>post</code></td>
          <td>
          </td>
          <td><p>post-synaptic population (either its name or a <code>Population</code> object).</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>target</code></td>
          <td>
          </td>
          <td><p>type of the connection</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>psp</code></td>
          <td>
          </td>
          <td><p>continuous influence of a single synapse on the post-synaptic neuron (default for rate-coded: <code>w*pre.r</code>).</p></td>
          <td>
                <code>&#39;pre.r * w&#39;</code>
          </td>
        </tr>
        <tr>
          <td><code>operation</code></td>
          <td>
          </td>
          <td><p>operation (sum, max, min, mean) performed by the kernel (default: sum).</p></td>
          <td>
                <code>&#39;sum&#39;</code>
          </td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>ANNarchy/extensions/convolution/Copy.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pre</span><span class="p">,</span> <span class="n">post</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">psp</span><span class="o">=</span><span class="s2">&quot;pre.r * w&quot;</span><span class="p">,</span> <span class="n">operation</span><span class="o">=</span><span class="s2">&quot;sum&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">copied</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    :param pre: pre-synaptic population (either its name or a ``Population`` object).</span>
<span class="sd">    :param post: post-synaptic population (either its name or a ``Population`` object).</span>
<span class="sd">    :param target: type of the connection</span>
<span class="sd">    :param psp: continuous influence of a single synapse on the post-synaptic neuron (default for rate-coded: ``w*pre.r``).</span>
<span class="sd">    :param operation: operation (sum, max, min, mean) performed by the kernel (default: sum).</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># Create the description, but it will not be used for generation</span>
    <span class="n">Projection</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">pre</span><span class="o">=</span><span class="n">pre</span><span class="p">,</span>
        <span class="n">post</span><span class="o">=</span><span class="n">post</span><span class="p">,</span>
        <span class="n">target</span><span class="o">=</span><span class="n">target</span><span class="p">,</span>
        <span class="n">synapse</span> <span class="o">=</span> <span class="n">SharedSynapse</span><span class="p">(</span><span class="n">psp</span><span class="o">=</span><span class="n">psp</span><span class="p">,</span> <span class="n">operation</span><span class="o">=</span><span class="n">operation</span><span class="p">),</span>
        <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
        <span class="n">copied</span><span class="o">=</span><span class="n">copied</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h4 id="ANNarchy.extensions.convolution.Copy.Copy.connect_copy" class="doc doc-heading">
<code class="highlight language-python"><span class="n">connect_copy</span><span class="p">(</span><span class="n">projection</span><span class="p">)</span></code>

<a href="#ANNarchy.extensions.convolution.Copy.Copy.connect_copy" class="headerlink" title="Permanent link">#</a></h4>


  <div class="doc doc-contents ">
  
      

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>projection</code></td>
          <td>
          </td>
          <td><p>Existing projection to copy.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>ANNarchy/extensions/convolution/Copy.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span>
<span class="normal">84</span>
<span class="normal">85</span>
<span class="normal">86</span>
<span class="normal">87</span>
<span class="normal">88</span>
<span class="normal">89</span>
<span class="normal">90</span>
<span class="normal">91</span>
<span class="normal">92</span>
<span class="normal">93</span>
<span class="normal">94</span>
<span class="normal">95</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">connect_copy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">projection</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    :param projection: Existing projection to copy.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">projection</span> <span class="o">=</span> <span class="n">projection</span>

    <span class="c1"># Sanity checks</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">projection</span><span class="p">,</span> <span class="n">Projection</span><span class="p">):</span>
        <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s1">&#39;Copy: You must provide an existing projection to copy().&#39;</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">projection</span><span class="p">,</span> <span class="p">(</span><span class="n">ConvolutionProjection</span><span class="p">,</span> <span class="n">PoolingProjection</span><span class="p">)):</span>
        <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s1">&#39;Copy: You can only copy regular projections, not shared projections.&#39;</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">geometry</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">projection</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">geometry</span> <span class="ow">or</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">geometry</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">projection</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">geometry</span><span class="p">:</span>
        <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s1">&#39;Copy: When copying a projection, the geometries must be the same.&#39;</span><span class="p">)</span>

    <span class="c1"># Dummy weights</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">pre_coordinates</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># Finish building the synapses</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_create</span><span class="p">()</span>

    <span class="k">return</span> <span class="bp">self</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h4 id="ANNarchy.extensions.convolution.Copy.Copy.connectivity_matrix" class="doc doc-heading">
<code class="highlight language-python"><span class="n">connectivity_matrix</span><span class="p">(</span><span class="n">fill</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span></code>

<a href="#ANNarchy.extensions.convolution.Copy.Copy.connectivity_matrix" class="headerlink" title="Permanent link">#</a></h4>


  <div class="doc doc-contents ">
  
      <p>Not available.</p>

      <details class="quote">
        <summary>Source code in <code>ANNarchy/extensions/convolution/Copy.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">connectivity_matrix</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="mf">0.0</span><span class="p">):</span>
    <span class="s2">&quot;Not available.&quot;</span>
    <span class="n">Global</span><span class="o">.</span><span class="n">_warning</span><span class="p">(</span><span class="s1">&#39;Copied projections can not display connectivity matrices.&#39;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h4 id="ANNarchy.extensions.convolution.Copy.Copy.generate_omp" class="doc doc-heading">
<code class="highlight language-python"><span class="n">generate_omp</span><span class="p">()</span></code>

<a href="#ANNarchy.extensions.convolution.Copy.Copy.generate_omp" class="headerlink" title="Permanent link">#</a></h4>


  <div class="doc doc-contents ">
  
      <p>Code generation of CopyProjection object for the openMP paradigm.</p>

      <details class="quote">
        <summary>Source code in <code>ANNarchy/extensions/convolution/Copy.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">generate_omp</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Code generation of CopyProjection object for the openMP paradigm.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Set the projection specific parameters</span>
    <span class="n">copy_proj_dict</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">copy_proj_template</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">copy_proj_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">value</span> <span class="o">=</span> <span class="n">value</span> <span class="o">%</span> <span class="p">{</span>
            <span class="s1">&#39;id_proj&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">id</span><span class="p">,</span>
            <span class="s1">&#39;id_copy&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">projection</span><span class="o">.</span><span class="n">id</span><span class="p">,</span>
            <span class="s1">&#39;float_prec&#39;</span><span class="p">:</span> <span class="n">Global</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;precision&#39;</span><span class="p">]</span>
        <span class="p">}</span>
        <span class="n">copy_proj_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>

    <span class="c1"># Update specific template</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_specific_template</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">copy_proj_dict</span><span class="p">)</span>

    <span class="c1"># OMP code if more then one thread</span>
    <span class="k">if</span> <span class="n">Global</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;num_threads&#39;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">omp_code</span> <span class="o">=</span> <span class="s1">&#39;#pragma omp for private(sum)&#39;</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="n">Global</span><span class="o">.</span><span class="n">OMP_MIN_NB_NEURONS</span> <span class="k">else</span> <span class="s1">&#39;&#39;</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">omp_code</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>

    <span class="c1"># PSP</span>
    <span class="n">psp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">synapse_type</span><span class="o">.</span><span class="n">description</span><span class="p">[</span><span class="s1">&#39;psp&#39;</span><span class="p">][</span><span class="s1">&#39;cpp&#39;</span><span class="p">]</span>  <span class="o">%</span> <span class="p">{</span>
        <span class="s1">&#39;id_pre&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">id</span><span class="p">,</span>
        <span class="s1">&#39;id_post&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">id</span><span class="p">,</span>
        <span class="s1">&#39;local_index&#39;</span><span class="p">:</span><span class="s1">&#39;[i][j]&#39;</span><span class="p">,</span>
        <span class="s1">&#39;global_index&#39;</span><span class="p">:</span> <span class="s1">&#39;[i]&#39;</span><span class="p">,</span>
        <span class="s1">&#39;pre_index&#39;</span><span class="p">:</span> <span class="s1">&#39;[pre_rank[i][j]]&#39;</span><span class="p">,</span>
        <span class="s1">&#39;post_index&#39;</span><span class="p">:</span> <span class="s1">&#39;[post_rank[i]]&#39;</span><span class="p">,</span>
        <span class="s1">&#39;pre_prefix&#39;</span><span class="p">:</span> <span class="s1">&#39;pop&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">id</span><span class="p">)</span><span class="o">+</span><span class="s1">&#39;.&#39;</span><span class="p">,</span>
        <span class="s1">&#39;post_prefix&#39;</span><span class="p">:</span> <span class="s1">&#39;pop&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">id</span><span class="p">)</span><span class="o">+</span><span class="s1">&#39;.&#39;</span><span class="p">}</span>
    <span class="n">psp</span> <span class="o">=</span> <span class="n">psp</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;rk_pre&#39;</span><span class="p">,</span> <span class="s1">&#39;pre_rank[i][j]&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)</span>

    <span class="c1"># Take delays into account if any</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">delays</span> <span class="o">&gt;</span> <span class="n">Global</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;dt&#39;</span><span class="p">]:</span>
        <span class="n">psp</span> <span class="o">=</span> <span class="n">psp</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span>
            <span class="s1">&#39;pop</span><span class="si">%(id_pre)s</span><span class="s1">.r[rk_pre]&#39;</span> <span class="o">%</span> <span class="p">{</span><span class="s1">&#39;id_pre&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">id</span><span class="p">},</span>
            <span class="s1">&#39;pop</span><span class="si">%(id_pre)s</span><span class="s1">._delayed_r[delay-1][rk_pre]&#39;</span> <span class="o">%</span> <span class="p">{</span><span class="s1">&#39;id_pre&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">id</span><span class="p">}</span>
            <span class="c1"># TODO HD: wouldn&#39;t it be much better to reduce delay globaly, instead of the substraction here???</span>
        <span class="p">)</span>

    <span class="c1"># Select template for operation to be performed: sum, max, min, mean</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">sum_code</span> <span class="o">=</span> <span class="n">copy_sum_template</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">synapse_type</span><span class="o">.</span><span class="n">operation</span><span class="p">]</span>
    <span class="k">except</span> <span class="ne">KeyError</span><span class="p">:</span>
        <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s2">&quot;CopyProjection: the operation &quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">synapse_type</span><span class="o">.</span><span class="n">operation</span><span class="p">,</span> <span class="s1">&#39; is not available.&#39;</span><span class="p">)</span>

    <span class="c1"># Finalize code</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">generator</span><span class="p">[</span><span class="s1">&#39;omp&#39;</span><span class="p">][</span><span class="s1">&#39;body_compute_psp&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">sum_code</span> <span class="o">%</span> <span class="p">{</span>
        <span class="s1">&#39;id_proj&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">id</span><span class="p">,</span> <span class="s1">&#39;target&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="p">,</span>
        <span class="s1">&#39;id_pre&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">id</span><span class="p">,</span> <span class="s1">&#39;name_pre&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
        <span class="s1">&#39;id_post&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">id</span><span class="p">,</span> <span class="s1">&#39;name_post&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
        <span class="s1">&#39;id&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">projection</span><span class="o">.</span><span class="n">id</span><span class="p">,</span>
        <span class="s1">&#39;float_prec&#39;</span><span class="p">:</span> <span class="n">Global</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;precision&#39;</span><span class="p">],</span>
        <span class="s1">&#39;omp_code&#39;</span><span class="p">:</span> <span class="n">omp_code</span><span class="p">,</span>
        <span class="s1">&#39;psp&#39;</span><span class="p">:</span> <span class="n">psp</span>
    <span class="p">}</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h4 id="ANNarchy.extensions.convolution.Copy.Copy.load" class="doc doc-heading">
<code class="highlight language-python"><span class="n">load</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span></code>

<a href="#ANNarchy.extensions.convolution.Copy.Copy.load" class="headerlink" title="Permanent link">#</a></h4>


  <div class="doc doc-contents ">
  
      <p>Not available.</p>

      <details class="quote">
        <summary>Source code in <code>ANNarchy/extensions/convolution/Copy.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filename</span><span class="p">):</span>
    <span class="s2">&quot;Not available.&quot;</span>
    <span class="n">Global</span><span class="o">.</span><span class="n">_warning</span><span class="p">(</span><span class="s1">&#39;Copied projections can not be loaded.&#39;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h4 id="ANNarchy.extensions.convolution.Copy.Copy.receptive_fields" class="doc doc-heading">
<code class="highlight language-python"><span class="n">receptive_fields</span><span class="p">(</span><span class="n">variable</span><span class="o">=</span><span class="s1">&#39;w&#39;</span><span class="p">,</span> <span class="n">in_post_geometry</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></code>

<a href="#ANNarchy.extensions.convolution.Copy.Copy.receptive_fields" class="headerlink" title="Permanent link">#</a></h4>


  <div class="doc doc-contents ">
  
      <p>Not available.</p>

      <details class="quote">
        <summary>Source code in <code>ANNarchy/extensions/convolution/Copy.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">receptive_fields</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">variable</span> <span class="o">=</span> <span class="s1">&#39;w&#39;</span><span class="p">,</span> <span class="n">in_post_geometry</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
    <span class="s2">&quot;Not available.&quot;</span>
    <span class="n">Global</span><span class="o">.</span><span class="n">_warning</span><span class="p">(</span><span class="s1">&#39;Copied projections can not display receptive fields.&#39;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h4 id="ANNarchy.extensions.convolution.Copy.Copy.save" class="doc doc-heading">
<code class="highlight language-python"><span class="n">save</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span></code>

<a href="#ANNarchy.extensions.convolution.Copy.Copy.save" class="headerlink" title="Permanent link">#</a></h4>


  <div class="doc doc-contents ">
  
      <p>Not available.</p>

      <details class="quote">
        <summary>Source code in <code>ANNarchy/extensions/convolution/Copy.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filename</span><span class="p">):</span>
    <span class="s2">&quot;Not available.&quot;</span>
    <span class="n">Global</span><span class="o">.</span><span class="n">_warning</span><span class="p">(</span><span class="s1">&#39;Copied projections can not be saved.&#39;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h4 id="ANNarchy.extensions.convolution.Copy.Copy.save_connectivity" class="doc doc-heading">
<code class="highlight language-python"><span class="n">save_connectivity</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span></code>

<a href="#ANNarchy.extensions.convolution.Copy.Copy.save_connectivity" class="headerlink" title="Permanent link">#</a></h4>


  <div class="doc doc-contents ">
  
      <p>Not available.</p>

      <details class="quote">
        <summary>Source code in <code>ANNarchy/extensions/convolution/Copy.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">save_connectivity</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filename</span><span class="p">):</span>
    <span class="s2">&quot;Not available.&quot;</span>
    <span class="n">Global</span><span class="o">.</span><span class="n">_warning</span><span class="p">(</span><span class="s1">&#39;Copied projections can not be saved.&#39;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>



  </div>

  </div>

</div>




  </div>

  </div>

</div>





                
              </article>
            </div>
          
          
        </div>
        
      </main>
      
        <footer class="md-footer">
  
    
    <nav class="md-footer__inner md-grid" aria-label="Footer" >
      
        
        <a href="Hybrid.html" class="md-footer__link md-footer__link--prev" aria-label="Previous: Hybrid networks" rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Previous
              </span>
              Hybrid networks
            </div>
          </div>
        </a>
      
      
        
        <a href="Logging.html" class="md-footer__link md-footer__link--next" aria-label="Next: Logging with tensorboard" rel="next">
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Next
              </span>
              Logging with tensorboard
            </div>
          </div>
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg>
          </div>
        </a>
      
    </nav>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; Julien Vitay, Helge lo Dinkelbach, Fred H. Hamker
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "..", "features": ["header.autohide"], "search": "../assets/javascripts/workers/search.16e2a7d4.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version.title": "Select version"}}</script>
    
    
      <script src="../assets/javascripts/bundle.5a2dcb6a.min.js"></script>
      
        <script src="../javascripts/config.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
    
  </body>
</html>