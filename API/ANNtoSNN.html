
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="BOLD.html">
      
      
        <link rel="next" href="../example/List.html">
      
      
      <link rel="icon" href="../_static/logo.svg">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-9.5.13">
    
    
      
        <title>ANN-to-SNN conversion - ANNarchy 4.7.3</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.7e359304.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="../css/ansi-colours.css">
    
      <link rel="stylesheet" href="../css/jupyter-cells.css">
    
      <link rel="stylesheet" href="../css/pandas-dataframe.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="black" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#ann-to-snn-conversion" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../index.html" title="ANNarchy 4.7.3" class="md-header__button md-logo" aria-label="ANNarchy 4.7.3" data-md-component="logo">
      
  <img src="../_static/logowhite.svg" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            ANNarchy 4.7.3
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              ANN-to-SNN conversion
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/ANNarchy/ANNarchy" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../index.html" title="ANNarchy 4.7.3" class="md-nav__button md-logo" aria-label="ANNarchy 4.7.3" data-md-component="logo">
      
  <img src="../_static/logowhite.svg" alt="logo">

    </a>
    ANNarchy 4.7.3
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/ANNarchy/ANNarchy" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../index.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../Installation.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Installation
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Manual
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Manual
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../manual/Structure.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    General structure
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../manual/Parser.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Parser
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../manual/RateNeuron.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Rate-coded neurons
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../manual/SpikeNeuron.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Spiking neurons
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../manual/RateSynapse.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Rate-coded synapses
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../manual/SpikeSynapse.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Spiking synapses
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../manual/Populations.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Populations
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../manual/Projections.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Projections
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../manual/Connector.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Connectivity
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../manual/Inputs.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Setting inputs
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../manual/Simulation.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Simulation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../manual/Configuration.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Configuration
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../manual/NumericalMethods.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Equations and numerical methods
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../manual/Recording.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Recording with Monitors
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../manual/Saving.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Saving and loading a network
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../manual/Network.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Parallel simulations and networks
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../manual/Hybrid.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hybrid networks
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../manual/StructuralPlasticity.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Structural plasticity
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../manual/ConvolutionalNetworks.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Convolution and pooling
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../manual/Notebooks.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Notebooks
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../manual/Reporting.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Reporting
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../manual/Logging.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Logging with tensorboard
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" checked>
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    API
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            API
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_1" >
        
          
          <label class="md-nav__link" for="__nav_4_1" id="__nav_4_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    core
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_1">
            <span class="md-nav__icon md-icon"></span>
            core
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="ANNarchy.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Top-level methods
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="Neuron.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Neuron
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="SpecificNeuron.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Built-in neuron types
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="Synapse.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Synapse
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="SpecificSynapse.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Built-in synapse types
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="Population.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Population
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="SpecificPopulation.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Specific Populations
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="Projection.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Projection
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="SpecificProjection.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Specific Projections
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="Dendrite.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Dendrite
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="Monitor.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Monitoring
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="RandomDistribution.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Random Distributions
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="Network.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Network
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="IO.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Saving / Loading
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="Utilities.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Reporting
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_2" checked>
        
          
          <label class="md-nav__link" for="__nav_4_2" id="__nav_4_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    extensions
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_4_2">
            <span class="md-nav__icon md-icon"></span>
            extensions
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="Convolution.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Convolution and Pooling
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="Logging.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Logging with tensorboard
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="BOLD.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    BOLD monitoring
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    ANN-to-SNN conversion
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="ANNtoSNN.html" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    ANN-to-SNN conversion
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#background" class="md-nav__link">
    <span class="md-ellipsis">
      Background
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Background">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#processing-queue" class="md-nav__link">
    <span class="md-ellipsis">
      Processing Queue
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#input-encoding" class="md-nav__link">
    <span class="md-ellipsis">
      Input Encoding
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Input Encoding">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#intrinsically-bursting-ib" class="md-nav__link">
    <span class="md-ellipsis">
      Intrinsically Bursting ("IB")
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#poisson-cpn" class="md-nav__link">
    <span class="md-ellipsis">
      Poisson ("CPN")
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#phase-shift-oscillation-pso" class="md-nav__link">
    <span class="md-ellipsis">
      Phase Shift Oscillation ("PSO")
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#user-defined-input-encodings" class="md-nav__link">
    <span class="md-ellipsis">
      User-defined input encodings
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#read-out-methods" class="md-nav__link">
    <span class="md-ellipsis">
      Read-out Methods
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Read-out Methods">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#maximum-spike-count" class="md-nav__link">
    <span class="md-ellipsis">
      Maximum Spike Count
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#time-to-number-of-spikes" class="md-nav__link">
    <span class="md-ellipsis">
      Time to Number of Spikes
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#membrane-potential" class="md-nav__link">
    <span class="md-ellipsis">
      Membrane potential
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#interface" class="md-nav__link">
    <span class="md-ellipsis">
      Interface
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#ANNarchy.extensions.ann_to_snn_conversion.ANNtoSNNConverter" class="md-nav__link">
    <span class="md-ellipsis">
      ANNtoSNNConverter
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ANNtoSNNConverter">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ANNarchy.extensions.ann_to_snn_conversion.ANNtoSNNConverter.ANNtoSNNConverter" class="md-nav__link">
    <span class="md-ellipsis">
      ANNtoSNNConverter
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ANNtoSNNConverter">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ANNarchy.extensions.ann_to_snn_conversion.ANNtoSNNConverter.ANNtoSNNConverter.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ANNarchy.extensions.ann_to_snn_conversion.ANNtoSNNConverter.ANNtoSNNConverter.get_annarchy_network" class="md-nav__link">
    <span class="md-ellipsis">
      get_annarchy_network
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ANNarchy.extensions.ann_to_snn_conversion.ANNtoSNNConverter.ANNtoSNNConverter.init_from_keras_model" class="md-nav__link">
    <span class="md-ellipsis">
      init_from_keras_model
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ANNarchy.extensions.ann_to_snn_conversion.ANNtoSNNConverter.ANNtoSNNConverter.predict" class="md-nav__link">
    <span class="md-ellipsis">
      predict
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#references" class="md-nav__link">
    <span class="md-ellipsis">
      References
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Examples
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            Examples
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../example/List.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    List of notebooks
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../example/NeuralField.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Neural Field
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../example/BarLearning.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Bar Learning
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../example/StructuralPlasticity.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Structural plasticity
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../example/Izhikevich.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Izhikevich
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../example/GapJunctions.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Gap junctions
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../example/HodgkinHuxley.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hodgkin-Huxley
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../example/COBA.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    COBA
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../example/STP.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    STP
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../example/SimpleSTDP.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    STDP
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../example/Ramp.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Ramp
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../example/Hybrid.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hybrid
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../example/Image.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Image
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../example/Webcam.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Webcam
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../example/MultipleNetworks.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Parallel simulations
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../example/BayesianOptimization.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Bayesian optimization
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../example/BasalGanglia.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Logging with tensorboard
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../example/BoldMonitoring.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    BOLD monitoring
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../example/ANN2SNN.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ANN to SNN Conversion
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../License.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    License
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#background" class="md-nav__link">
    <span class="md-ellipsis">
      Background
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Background">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#processing-queue" class="md-nav__link">
    <span class="md-ellipsis">
      Processing Queue
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#input-encoding" class="md-nav__link">
    <span class="md-ellipsis">
      Input Encoding
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Input Encoding">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#intrinsically-bursting-ib" class="md-nav__link">
    <span class="md-ellipsis">
      Intrinsically Bursting ("IB")
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#poisson-cpn" class="md-nav__link">
    <span class="md-ellipsis">
      Poisson ("CPN")
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#phase-shift-oscillation-pso" class="md-nav__link">
    <span class="md-ellipsis">
      Phase Shift Oscillation ("PSO")
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#user-defined-input-encodings" class="md-nav__link">
    <span class="md-ellipsis">
      User-defined input encodings
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#read-out-methods" class="md-nav__link">
    <span class="md-ellipsis">
      Read-out Methods
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Read-out Methods">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#maximum-spike-count" class="md-nav__link">
    <span class="md-ellipsis">
      Maximum Spike Count
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#time-to-number-of-spikes" class="md-nav__link">
    <span class="md-ellipsis">
      Time to Number of Spikes
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#membrane-potential" class="md-nav__link">
    <span class="md-ellipsis">
      Membrane potential
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#interface" class="md-nav__link">
    <span class="md-ellipsis">
      Interface
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#ANNarchy.extensions.ann_to_snn_conversion.ANNtoSNNConverter" class="md-nav__link">
    <span class="md-ellipsis">
      ANNtoSNNConverter
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ANNtoSNNConverter">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ANNarchy.extensions.ann_to_snn_conversion.ANNtoSNNConverter.ANNtoSNNConverter" class="md-nav__link">
    <span class="md-ellipsis">
      ANNtoSNNConverter
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ANNtoSNNConverter">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ANNarchy.extensions.ann_to_snn_conversion.ANNtoSNNConverter.ANNtoSNNConverter.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ANNarchy.extensions.ann_to_snn_conversion.ANNtoSNNConverter.ANNtoSNNConverter.get_annarchy_network" class="md-nav__link">
    <span class="md-ellipsis">
      get_annarchy_network
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ANNarchy.extensions.ann_to_snn_conversion.ANNtoSNNConverter.ANNtoSNNConverter.init_from_keras_model" class="md-nav__link">
    <span class="md-ellipsis">
      init_from_keras_model
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ANNarchy.extensions.ann_to_snn_conversion.ANNtoSNNConverter.ANNtoSNNConverter.predict" class="md-nav__link">
    <span class="md-ellipsis">
      predict
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#references" class="md-nav__link">
    <span class="md-ellipsis">
      References
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


<h1 id="ann-to-snn-conversion">ANN-to-SNN conversion<a class="headerlink" href="#ann-to-snn-conversion" title="Permanent link">#</a></h1>
<p>The ANN-to-SNN conversion module is part of the extensions and must be explicitely imported:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">ANNarchy</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">ANNarchy.extensions.ann_to_snn_conversion</span> <span class="kn">import</span> <span class="n">ANNtoSNNConverter</span>
</code></pre></div>
<h2 id="background">Background<a class="headerlink" href="#background" title="Permanent link">#</a></h2>
<p>The implementation of the present module is inspired by the SNNToolbox (Rueckauer et al. 2017), and is largely based on the work of Diehl et al. (2015). We provide several input encodings, as suggested in the work of Park et al. (2019) and Auge et al. (2021).</p>
<h3 id="processing-queue">Processing Queue<a class="headerlink" href="#processing-queue" title="Permanent link">#</a></h3>
<p>The pre-trained ANN model to be converted should be saved in keras as an h5py file (extension <code>.h5</code>). The saved model is transformed layer by layer into a feed-forward ANNarchy spiking network. The structure of the network remains the same as in the original ANN, while the weights are normalised. Please note that the current implementation focuses primarily on the correctness of the conversion. Computational performance, especially of the converted CNNs, will be improved in future releases.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>While the neurons are conceptually spiking neurons, there is one specialty: next to the spike event (stored automatically in ANNarchy), each event will be stored in an additional <em>mask</em> array. This <em>mask</em> value decays in absence of further spike events exponentially. The decay can be controlled by the <em>mask_tau</em> parameter of the population. The projections (either dense or convolution) will use this mask as pre-synaptic input, not the generated list of spike events.</p>
</div>
<h3 id="input-encoding">Input Encoding<a class="headerlink" href="#input-encoding" title="Permanent link">#</a></h3>
<p>In the following we provide brief descriptions of the available input encodings. The abbreviations in brackets denote the name provided to the conversion tool constructor.</p>
<h4 id="intrinsically-bursting-ib">Intrinsically Bursting ("IB")<a class="headerlink" href="#intrinsically-bursting-ib" title="Permanent link">#</a></h4>
<p>This encoding bases on the Izhikevich (2003) model that comprises two ODEs:</p>
<div class="arithmatex">\[
\begin{cases}
  \frac{dv}{dt} = 0.04 \cdot v^2 + 5.0 \cdot v + 140.0 - u + I \\
  \\
  \frac{du}{dt} = a \cdot (b \cdot v - u) \\
\end{cases}
\]</div>
<p>The parameters for <span class="arithmatex">\(a\)</span> - <span class="arithmatex">\(d\)</span> are selected accordingly to Izhikevich (2003). The provided input images will be set as <span class="arithmatex">\(I\)</span>.</p>
<h4 id="poisson-cpn">Poisson ("CPN")<a class="headerlink" href="#poisson-cpn" title="Permanent link">#</a></h4>
<p>This encoding uses a Poisson distribution where the pixel values of the image will be used as probability for each individual neuron.</p>
<h4 id="phase-shift-oscillation-pso">Phase Shift Oscillation ("PSO")<a class="headerlink" href="#phase-shift-oscillation-pso" title="Permanent link">#</a></h4>
<p>Based on the description by Park et al. (2019), the spiking threshold <span class="arithmatex">\(v_\text{th}\)</span> is modulated by a oscillation function <span class="arithmatex">\(\Pi\)</span>, whereas the membrane potential follows simply the input current. </p>
<div class="arithmatex">\[
\begin{cases}
  \Pi(t) = 2^{-(1+ \text{mod}(t,k))}\\
  \\
  v_\text{th}(t) = \Pi(t) \, v_\text{th}(t)\\
\end{cases}
\]</div>
<h4 id="user-defined-input-encodings">User-defined input encodings<a class="headerlink" href="#user-defined-input-encodings" title="Permanent link">#</a></h4>
<p>In addition to the pre-defined models, one can opt for individual models using the <code>Neuron</code> class of ANNarchy. Please note that a <code>mask</code> variable need to be defined, which is fed into the subsequent projections.</p>
<h3 id="read-out-methods">Read-out Methods<a class="headerlink" href="#read-out-methods" title="Permanent link">#</a></h3>
<p>In a classification task, the neuron with the highest activity corresponds corresponds to the decision to which class the presented input belongs. However, the highest activity can be determined in different ways. We support currently three methods, defined by the <code>read_out</code> parameter of the constructor:</p>
<h4 id="maximum-spike-count">Maximum Spike Count<a class="headerlink" href="#maximum-spike-count" title="Permanent link">#</a></h4>
<p><code>read_out = 'spike_count'</code> : the number of spikes emitted by each neuron is recorded and the index of the neuron(s) with the maximum number is returned.</p>
<h4 id="time-to-number-of-spikes">Time to Number of Spikes<a class="headerlink" href="#time-to-number-of-spikes" title="Permanent link">#</a></h4>
<p><code>read_out = 'time_to_first_spike'</code> or <code>read_out = 'time_to_k_spikes'</code>: when the first or first <span class="arithmatex">\(k\)</span> spikes are emitted by a single neuron, the simulation is stopped and the neuron rank(s) is returned. For the second mode, an additional <span class="arithmatex">\(k\)</span> argument need to be also provided.</p>
<h4 id="membrane-potential">Membrane potential<a class="headerlink" href="#membrane-potential" title="Permanent link">#</a></h4>
<p><code>read_out = 'membrane_potential'</code>:  pre-synaptic events are accumulated in the membrane potential of each output neuron. The index of the neuron(s) with the highest membrane potential is returned.</p>
<h2 id="interface">Interface<a class="headerlink" href="#interface" title="Permanent link">#</a></h2>


<div class="doc doc-object doc-module">



<h2 id="ANNarchy.extensions.ann_to_snn_conversion.ANNtoSNNConverter" class="doc doc-heading">
          <code>ANNtoSNNConverter</code>


<a href="#ANNarchy.extensions.ann_to_snn_conversion.ANNtoSNNConverter" class="headerlink" title="Permanent link">#</a></h2>

  <div class="doc doc-contents first">
  
      <p>:copyright: Copyright 2013 - now, see AUTHORS.
:license: GPLv2, see LICENSE for details.</p>

  

  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h3 id="ANNarchy.extensions.ann_to_snn_conversion.ANNtoSNNConverter.ANNtoSNNConverter" class="doc doc-heading">
          <code>ANNtoSNNConverter</code>


<a href="#ANNarchy.extensions.ann_to_snn_conversion.ANNtoSNNConverter.ANNtoSNNConverter" class="headerlink" title="Permanent link">#</a></h3>


  <div class="doc doc-contents ">

  
      <p>Implements a conversion of a pre-trained fully-connected Keras model into a spiking model. The procedure is based on the implementation of:</p>
<blockquote>
<p>Diehl et al. (2015) "Fast-classifying, high-accuracy spiking deep networks through weight and threshold balancing" Proceedings of IJCNN. doi: 10.1109/IJCNN.2015.7280696</p>
</blockquote>

            <details class="quote">
              <summary>Source code in <code>ANNarchy/extensions/ann_to_snn_conversion/ANNtoSNNConverter.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">ANNtoSNNConverter</span> <span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Implements a conversion of a pre-trained fully-connected Keras model into a spiking model. The procedure is based on the implementation of:</span>

<span class="sd">    &gt; Diehl et al. (2015) &quot;Fast-classifying, high-accuracy spiking deep networks through weight and threshold balancing&quot; Proceedings of IJCNN. doi: 10.1109/IJCNN.2015.7280696</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_encoding</span><span class="o">=</span><span class="s1">&#39;poisson&#39;</span><span class="p">,</span> <span class="n">hidden_neuron</span><span class="o">=</span><span class="s1">&#39;IaF&#39;</span><span class="p">,</span> <span class="n">read_out</span><span class="o">=</span><span class="s1">&#39;spike_count&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :param input_encoding: a string representing which input encoding should be used: custom poisson, PSO, IB or CH (for more details see InputEncoding).</span>
<span class="sd">        :param hidden_neuron:  neuron model used in the hidden layers. Either the default integrate-and-fire (&#39;IaF&#39;) or an ANNarchy Neuron object.</span>
<span class="sd">        :param read_out: a string which of the following read-out method should be used: spike_count, time_to_first_spike, membrane_potential (for more details see the manual).</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Neuron model</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">hidden_neuron</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">hidden_neuron</span> <span class="o">==</span> <span class="s2">&quot;IaF&quot;</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_hidden_neuron_model</span> <span class="o">=</span> <span class="n">IaF</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Invalid model name for hidden neurons.&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_hidden_neuron_model</span> <span class="o">=</span> <span class="n">hidden_neuron</span>

        <span class="c1"># Input encoding</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_input_encoding</span> <span class="o">=</span> <span class="n">input_encoding</span>
        <span class="k">if</span> <span class="n">input_encoding</span> <span class="o">==</span> <span class="s2">&quot;poisson&quot;</span> <span class="ow">or</span> <span class="n">input_encoding</span> <span class="o">==</span> <span class="s2">&quot;CPN&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_input_model</span> <span class="o">=</span> <span class="n">CPN</span>
        <span class="k">elif</span> <span class="n">input_encoding</span> <span class="o">==</span> <span class="s1">&#39;PSO&#39;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_input_model</span> <span class="o">=</span> <span class="n">PSO</span>
        <span class="k">elif</span> <span class="n">input_encoding</span><span class="o">==</span><span class="s1">&#39;IB&#39;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_input_model</span> <span class="o">=</span> <span class="n">IB</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Unknown input encoding:&quot;</span><span class="p">,</span> <span class="n">input_encoding</span><span class="p">)</span>

        <span class="c1"># Readout</span>
        <span class="k">if</span> <span class="n">read_out</span> <span class="ow">in</span> <span class="n">available_read_outs</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_read_out</span> <span class="o">=</span> <span class="n">read_out</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Unknown value for read-out:&quot;</span><span class="p">,</span> <span class="n">read_out</span><span class="p">)</span>

        <span class="c1"># Maximum frequency</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_max_f</span> <span class="o">=</span> <span class="mi">100</span>      <span class="c1"># scale factor used for poisson encoding</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_read_out</span> <span class="o">==</span> <span class="s2">&quot;time_to_k_spikes&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="s1">&#39;k&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s2">&quot;When read_out is set to &#39;time_to_k_spikes&#39;, the k parameter need to be provided.&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_k_param</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;k&#39;</span><span class="p">]</span>

        <span class="c1"># TODO: sanity check on key-value args</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">key</span> <span class="o">==</span> <span class="s2">&quot;max_f&quot;</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_max_f</span> <span class="o">=</span> <span class="n">value</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_snn_network</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">init_from_keras_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
            <span class="n">filename</span><span class="p">,</span> 
            <span class="n">directory</span><span class="o">=</span><span class="s2">&quot;annarchy&quot;</span><span class="p">,</span> 
            <span class="n">scale_factor</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
            <span class="n">show_info</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
        <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Loads the pre-trained model provided as a .h5 file.</span>

<span class="sd">        In tf.keras, the weights can be saved using:</span>

<span class="sd">        ```python</span>
<span class="sd">        model.save(&quot;model.h5&quot;)</span>
<span class="sd">        ```</span>

<span class="sd">        :param filename: stored model as a .h5 file.</span>
<span class="sd">        :param directory: sub-directory where the generated code should be stored (default: &quot;annarchy&quot;)</span>
<span class="sd">        :param scale_factor: allows a fine-grained control of the weight scale factor. By default (None), with each layer-depth the factor increases by one. If a scalar value is provided the same value is used for each layer. Otherwise a list can be provided to assign the scale factors individually.</span>
<span class="sd">        :param show_info: whether the network structure should be printed on console (default: True)</span>

<span class="sd">        :returns net: An `ANNarchy.Network` instance.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Filename</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">filename</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;.h5&quot;</span><span class="p">):</span>
            <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s2">&quot;ANNtoSNNConverter: the keras model must be provided as a .h5 file.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_filename</span> <span class="o">=</span> <span class="n">filename</span>

        <span class="c1"># Extract weight matrices</span>
        <span class="n">weight_matrices</span><span class="p">,</span> <span class="n">layer_order</span><span class="p">,</span> <span class="n">layer_operation</span><span class="p">,</span> <span class="n">input_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_extract_weight_matrices</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>

        <span class="c1"># Create spiking network</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_snn_network</span> <span class="o">=</span> <span class="n">Network</span><span class="p">(</span><span class="n">everything</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
        <span class="n">input_pop</span> <span class="o">=</span> <span class="n">Population</span><span class="p">(</span><span class="n">name</span> <span class="o">=</span> <span class="n">layer_order</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">geometry</span><span class="o">=</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">neuron</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_input_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_snn_network</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">input_pop</span><span class="p">)</span>

        <span class="c1"># Hidden neuron</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_hidden_neuron_model</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">hidden_type</span> <span class="o">=</span> <span class="s2">&quot;user-specified&quot;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">hidden_type</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_hidden_neuron_model</span><span class="o">.</span><span class="n">name</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_hidden_neuron_model</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_hidden_neuron_model</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">layer_order</span><span class="p">)</span><span class="o">-</span><span class="mi">2</span><span class="p">)]</span>

        <span class="n">description</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;&quot;&quot;Parameters</span>
<span class="s2">----------------------</span>
<span class="s2">* input encoding: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_input_encoding</span><span class="si">}</span>
<span class="s2">* hidden neuron: </span><span class="si">{</span><span class="n">hidden_type</span><span class="si">}</span>
<span class="s2">* read-out method: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_read_out</span><span class="si">}</span>

<span class="s2">Layers</span>
<span class="s2">----------------------</span>
<span class="s2">&quot;&quot;&quot;</span>

        <span class="c1"># Create populations</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">layer_order</span><span class="p">)):</span>
            <span class="k">if</span> <span class="s1">&#39;conv&#39;</span> <span class="ow">in</span> <span class="n">layer_order</span><span class="p">[</span><span class="n">layer</span><span class="p">]:</span>

                <span class="n">geometry</span> <span class="o">=</span> <span class="n">input_dim</span> <span class="o">+</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">weight_matrices</span><span class="p">[</span><span class="n">layer</span><span class="p">])[</span><span class="mi">0</span><span class="p">],)</span>
                <span class="n">conv_pop</span> <span class="o">=</span> <span class="n">Population</span><span class="p">(</span><span class="n">geometry</span> <span class="o">=</span> <span class="n">geometry</span><span class="p">,</span> <span class="n">neuron</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_hidden_neuron_model</span><span class="p">[</span><span class="n">layer</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="n">layer_order</span><span class="p">[</span><span class="n">layer</span><span class="p">]</span> <span class="p">)</span> <span class="c1"># create convolution population</span>
                <span class="n">conv_pop</span><span class="o">.</span><span class="n">vt</span> <span class="o">=</span> <span class="n">conv_pop</span><span class="o">.</span><span class="n">vt</span> <span class="o">-</span> <span class="p">(</span><span class="mf">0.05</span><span class="o">*</span><span class="n">layer</span><span class="p">)</span> <span class="c1"># reduce the threshold for deeper layers</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_snn_network</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">conv_pop</span><span class="p">)</span>

                <span class="n">description</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;* name=</span><span class="si">{</span><span class="n">layer_order</span><span class="p">[</span><span class="n">layer</span><span class="p">]</span><span class="si">}</span><span class="s2">, convolutional layer, </span><span class="si">{</span><span class="n">geometry</span><span class="si">=}</span><span class="se">\n</span><span class="s2">&quot;</span>

            <span class="k">elif</span> <span class="s1">&#39;pool&#39;</span> <span class="ow">in</span> <span class="n">layer_order</span><span class="p">[</span><span class="n">layer</span><span class="p">]:</span>

                <span class="n">input_dim</span> <span class="o">=</span> <span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">input_dim</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span> <span class="mi">2</span><span class="p">),</span> <span class="nb">int</span><span class="p">(</span><span class="n">input_dim</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">/</span> <span class="mi">2</span><span class="p">))</span>
                <span class="n">l_weights</span> <span class="o">=</span> <span class="n">weight_matrices</span><span class="p">[</span><span class="n">layer</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># get the weights of the previous layer (should be a conv-layer, or not?)</span>
                <span class="n">dim_0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">l_weights</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

                <span class="n">geometry</span> <span class="o">=</span> <span class="n">input_dim</span> <span class="c1"># add it to the geometry</span>
                <span class="n">geometry</span> <span class="o">=</span> <span class="n">geometry</span> <span class="o">+</span> <span class="p">(</span><span class="n">dim_0</span><span class="p">,)</span>
                <span class="n">pool_pop</span> <span class="o">=</span> <span class="n">Population</span><span class="p">(</span><span class="n">geometry</span> <span class="o">=</span> <span class="n">geometry</span><span class="p">,</span> <span class="n">neuron</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_hidden_neuron_model</span><span class="p">[</span><span class="n">layer</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="n">layer_order</span><span class="p">[</span><span class="n">layer</span><span class="p">])</span>
                <span class="n">pool_pop</span><span class="o">.</span><span class="n">vt</span> <span class="o">=</span> <span class="n">pool_pop</span><span class="o">.</span><span class="n">vt</span> <span class="o">-</span> <span class="p">(</span><span class="mf">0.05</span><span class="o">*</span><span class="n">layer</span><span class="p">)</span> <span class="c1"># reduce the threshold for deeper layers</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_snn_network</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">pool_pop</span><span class="p">)</span>

                <span class="n">description</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;* name=</span><span class="si">{</span><span class="n">layer_order</span><span class="p">[</span><span class="n">layer</span><span class="p">]</span><span class="si">}</span><span class="s2">, pooling layer, </span><span class="si">{</span><span class="n">geometry</span><span class="si">=}</span><span class="se">\n</span><span class="s2">&quot;</span>

            <span class="k">elif</span> <span class="s1">&#39;dense&#39;</span> <span class="ow">in</span> <span class="n">layer_order</span><span class="p">[</span><span class="n">layer</span><span class="p">]:</span>

                <span class="n">geometry</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">weight_matrices</span><span class="p">[</span><span class="n">layer</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span>

                <span class="c1"># read-out layer</span>
                <span class="k">if</span> <span class="n">layer</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer_order</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_read_out</span> <span class="o">==</span> <span class="s2">&quot;membrane_potential&quot;</span><span class="p">:</span>
                        <span class="c1"># HD (24th April 2023): instead of reading out spike events, we use the accumulated inputs</span>
                        <span class="c1">#                       as decision parameter</span>
                        <span class="n">dense_pop</span> <span class="o">=</span> <span class="n">Population</span><span class="p">(</span><span class="n">geometry</span> <span class="o">=</span> <span class="n">geometry</span><span class="p">,</span> <span class="n">neuron</span><span class="o">=</span><span class="n">IaF_Acc</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">layer_order</span><span class="p">[</span><span class="n">layer</span><span class="p">])</span>

                    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_read_out</span> <span class="o">==</span> <span class="s2">&quot;time_to_first_spike&quot;</span> <span class="ow">and</span> <span class="n">layer</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer_order</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span>
                        <span class="c1"># HD (24th April 2023): instead of reading out spike events, we simulate untile the first</span>
                        <span class="c1">#                       neuron in the read-out layer spikes.</span>
                        <span class="n">dense_pop</span> <span class="o">=</span> <span class="n">Population</span><span class="p">(</span><span class="n">geometry</span> <span class="o">=</span> <span class="n">geometry</span><span class="p">,</span> <span class="n">neuron</span><span class="o">=</span><span class="n">IaF</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">layer_order</span><span class="p">[</span><span class="n">layer</span><span class="p">],</span> <span class="n">stop_condition</span><span class="o">=</span><span class="s2">&quot;spiked: any&quot;</span><span class="p">)</span>

                    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_read_out</span> <span class="o">==</span> <span class="s2">&quot;time_to_k_spikes&quot;</span> <span class="ow">and</span> <span class="n">layer</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer_order</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span>
                        <span class="c1"># HD (3rd May 2023): instead of reading out spike events, we simulate untile the first</span>
                        <span class="c1">#                    neuron emitted k spikes in the read-out layer.</span>
                        <span class="n">dense_pop</span> <span class="o">=</span> <span class="n">Population</span><span class="p">(</span><span class="n">geometry</span> <span class="o">=</span> <span class="n">geometry</span><span class="p">,</span> <span class="n">neuron</span><span class="o">=</span><span class="n">IaF_TTKS</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">layer_order</span><span class="p">[</span><span class="n">layer</span><span class="p">],</span> <span class="n">stop_condition</span><span class="o">=</span><span class="s2">&quot;sc &gt;= k: any&quot;</span><span class="p">)</span>
                        <span class="n">dense_pop</span><span class="o">.</span><span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_k_param</span>

                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">dense_pop</span> <span class="o">=</span> <span class="n">Population</span><span class="p">(</span><span class="n">geometry</span> <span class="o">=</span> <span class="n">geometry</span><span class="p">,</span> <span class="n">neuron</span><span class="o">=</span><span class="n">IaF_ReadOut</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">layer_order</span><span class="p">[</span><span class="n">layer</span><span class="p">])</span>
                        <span class="c1"># ARK:  scaling the threshold as number of layers increases divide</span>
                        <span class="c1">#       the value 1/half of the number of the network</span>
                        <span class="n">dense_pop</span><span class="o">.</span><span class="n">vt</span> <span class="o">=</span> <span class="n">dense_pop</span><span class="o">.</span><span class="n">vt</span> <span class="o">-</span> <span class="p">(</span><span class="mf">0.05</span><span class="o">*</span><span class="n">layer</span><span class="p">)</span>
                        <span class="c1"># HD (20th Feb. 2023): we want to generate this firing vector for a</span>
                        <span class="c1">#                      single time step</span>
                        <span class="n">dense_pop</span><span class="o">.</span><span class="n">compute_firing_rate</span><span class="p">(</span><span class="n">Global</span><span class="o">.</span><span class="n">dt</span><span class="p">())</span>

                <span class="c1"># hidden layer neurons</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">dense_pop</span> <span class="o">=</span> <span class="n">Population</span><span class="p">(</span><span class="n">geometry</span> <span class="o">=</span> <span class="n">geometry</span><span class="p">,</span> <span class="n">neuron</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_hidden_neuron_model</span><span class="p">[</span><span class="n">layer</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="n">layer_order</span><span class="p">[</span><span class="n">layer</span><span class="p">])</span>
                    <span class="c1"># ARK:  scaling the threshold as number of layers increases divide</span>
                    <span class="c1">#       the value 1/half of the number of the network</span>
                    <span class="n">dense_pop</span><span class="o">.</span><span class="n">vt</span> <span class="o">=</span> <span class="n">dense_pop</span><span class="o">.</span><span class="n">vt</span> <span class="o">-</span> <span class="p">(</span><span class="mf">0.05</span><span class="o">*</span><span class="n">layer</span><span class="p">)</span>
                    <span class="c1"># HD (20th Feb. 2023): we want to generate this firing vector for a</span>
                    <span class="c1">#                      single time step</span>
                    <span class="n">dense_pop</span><span class="o">.</span><span class="n">compute_firing_rate</span><span class="p">(</span><span class="n">Global</span><span class="o">.</span><span class="n">dt</span><span class="p">())</span>

                <span class="c1"># Add created layer to the network</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_snn_network</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">dense_pop</span><span class="p">)</span>

                <span class="c1"># Description</span>
                <span class="n">description</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;* name=</span><span class="si">{</span><span class="n">layer_order</span><span class="p">[</span><span class="n">layer</span><span class="p">]</span><span class="si">}</span><span class="s2">, dense layer, </span><span class="si">{</span><span class="n">geometry</span><span class="si">=}</span><span class="se">\n</span><span class="s2">&quot;</span>


        <span class="c1"># Create Projections</span>
        <span class="n">description</span> <span class="o">+=</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Projections</span><span class="se">\n</span><span class="s1">----------------------</span><span class="se">\n</span><span class="s1">&#39;</span>

        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">layer_order</span><span class="p">)):</span>
            <span class="k">if</span> <span class="s1">&#39;conv&#39;</span> <span class="ow">in</span> <span class="n">layer_order</span><span class="p">[</span><span class="n">p</span><span class="p">]:</span>

                <span class="n">post_pop</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_snn_network</span><span class="o">.</span><span class="n">get_population</span><span class="p">(</span><span class="n">layer_order</span><span class="p">[</span><span class="n">p</span><span class="p">])</span>
                <span class="n">pre_pop</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_snn_network</span><span class="o">.</span><span class="n">get_population</span><span class="p">(</span><span class="n">layer_order</span><span class="p">[</span><span class="n">p</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

                <span class="n">weight_m</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">weight_matrices</span><span class="p">[</span><span class="n">p</span><span class="p">])</span>

                <span class="n">conv_proj</span> <span class="o">=</span> <span class="n">Convolution</span><span class="p">(</span><span class="n">pre</span> <span class="o">=</span> <span class="n">pre_pop</span><span class="p">,</span> <span class="n">post</span><span class="o">=</span><span class="n">post_pop</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="s1">&#39;exc&#39;</span><span class="p">,</span> <span class="n">psp</span><span class="o">=</span><span class="s2">&quot;pre.mask * w&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;conv_proj_</span><span class="si">%i</span><span class="s1">&#39;</span><span class="o">%</span><span class="n">p</span><span class="p">)</span>
                <span class="n">conv_proj</span><span class="o">.</span><span class="n">connect_filters</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="n">weight_m</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_snn_network</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">conv_proj</span><span class="p">)</span>

                <span class="n">description</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;* </span><span class="si">{</span><span class="n">layer_order</span><span class="p">[</span><span class="n">p</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">pre_pop</span><span class="o">.</span><span class="n">geometry</span><span class="si">}</span><span class="s2"> -&gt; </span><span class="si">{</span><span class="n">layer_order</span><span class="p">[</span><span class="n">p</span><span class="p">]</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">post_pop</span><span class="o">.</span><span class="n">geometry</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="n">description</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;    weight matrix </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">weight_m</span><span class="p">)</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>


            <span class="k">elif</span> <span class="s1">&#39;pool&#39;</span> <span class="ow">in</span> <span class="n">layer_order</span><span class="p">[</span><span class="n">p</span><span class="p">]:</span>

                <span class="n">post_pop</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_snn_network</span><span class="o">.</span><span class="n">get_population</span><span class="p">(</span><span class="n">layer_order</span><span class="p">[</span><span class="n">p</span><span class="p">])</span>
                <span class="n">pre_pop</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_snn_network</span><span class="o">.</span><span class="n">get_population</span><span class="p">(</span><span class="n">layer_order</span><span class="p">[</span><span class="n">p</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

                <span class="n">pool_proj</span> <span class="o">=</span> <span class="n">Pooling</span><span class="p">(</span><span class="n">pre</span> <span class="o">=</span> <span class="n">pre_pop</span><span class="p">,</span> <span class="n">post</span><span class="o">=</span><span class="n">post_pop</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="s1">&#39;exc&#39;</span><span class="p">,</span> <span class="n">operation</span><span class="o">=</span><span class="n">layer_operation</span><span class="p">[</span><span class="n">p</span><span class="p">],</span> <span class="n">psp</span><span class="o">=</span><span class="s2">&quot;pre.mask&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;pool_proj_</span><span class="si">%i</span><span class="s1">&#39;</span><span class="o">%</span><span class="n">p</span><span class="p">)</span>
                <span class="n">pool_proj</span><span class="o">.</span><span class="n">connect_pooling</span><span class="p">(</span><span class="n">extent</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_snn_network</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">pool_proj</span><span class="p">)</span>

                <span class="n">description</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;* </span><span class="si">{</span><span class="n">layer_order</span><span class="p">[</span><span class="n">p</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">pre_pop</span><span class="o">.</span><span class="n">geometry</span><span class="si">}</span><span class="s2"> -&gt; </span><span class="si">{</span><span class="n">layer_order</span><span class="p">[</span><span class="n">p</span><span class="p">]</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">post_pop</span><span class="o">.</span><span class="n">geometry</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="n">description</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;    pooling operation </span><span class="si">{</span><span class="n">layer_operation</span><span class="p">[</span><span class="n">p</span><span class="p">]</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>

            <span class="k">elif</span> <span class="s1">&#39;dense&#39;</span> <span class="ow">in</span> <span class="n">layer_order</span><span class="p">[</span><span class="n">p</span><span class="p">]:</span>

                <span class="n">post_pop</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_snn_network</span><span class="o">.</span><span class="n">get_population</span><span class="p">(</span><span class="n">layer_order</span><span class="p">[</span><span class="n">p</span><span class="p">])</span>
                <span class="n">pre_pop</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_snn_network</span><span class="o">.</span><span class="n">get_population</span><span class="p">(</span><span class="n">layer_order</span><span class="p">[</span><span class="n">p</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

                <span class="n">dense_proj</span> <span class="o">=</span> <span class="n">Projection</span><span class="p">(</span>
                    <span class="n">pre</span> <span class="o">=</span> <span class="n">pre_pop</span><span class="p">,</span> <span class="n">post</span> <span class="o">=</span> <span class="n">post_pop</span><span class="p">,</span> 
                    <span class="n">target</span> <span class="o">=</span> <span class="s2">&quot;exc&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;dense_proj_</span><span class="si">%i</span><span class="s1">&#39;</span><span class="o">%</span><span class="n">p</span>
                <span class="p">)</span>

                <span class="k">if</span> <span class="n">pre_pop</span><span class="o">.</span><span class="n">neuron_type</span><span class="o">.</span><span class="n">type</span><span class="o">==</span><span class="s2">&quot;rate&quot;</span><span class="p">:</span>
                    <span class="n">dense_proj</span><span class="o">.</span><span class="n">connect_all_to_all</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="n">Uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">storage_format</span><span class="o">=</span><span class="s2">&quot;dense&quot;</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">dense_proj</span><span class="o">.</span><span class="n">connect_all_to_all</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="n">Uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">storage_format</span><span class="o">=</span><span class="s2">&quot;dense&quot;</span><span class="p">,</span> <span class="n">storage_order</span><span class="o">=</span><span class="s2">&quot;pre_to_post&quot;</span><span class="p">)</span>
                    <span class="n">dense_proj</span><span class="o">.</span><span class="n">_parallel_pattern</span> <span class="o">=</span> <span class="s2">&quot;outer_loop&quot;</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">_snn_network</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">dense_proj</span><span class="p">)</span>

                <span class="n">description</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;* </span><span class="si">{</span><span class="n">layer_order</span><span class="p">[</span><span class="n">p</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">pre_pop</span><span class="o">.</span><span class="n">geometry</span><span class="si">}</span><span class="s2"> -&gt; </span><span class="si">{</span><span class="n">layer_order</span><span class="p">[</span><span class="n">p</span><span class="p">]</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">post_pop</span><span class="o">.</span><span class="n">geometry</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="n">description</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;    weight matrix size </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">weight_matrices</span><span class="p">[</span><span class="n">p</span><span class="p">])</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="n">description</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;    mean </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">weight_matrices</span><span class="p">[</span><span class="n">p</span><span class="p">])</span><span class="si">}</span><span class="s2">, std </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">weight_matrices</span><span class="p">[</span><span class="n">p</span><span class="p">])</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="n">description</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;    min </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">weight_matrices</span><span class="p">[</span><span class="n">p</span><span class="p">])</span><span class="si">}</span><span class="s2">, max </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">weight_matrices</span><span class="p">[</span><span class="n">p</span><span class="p">])</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>

        <span class="c1"># Compile the configured network</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_snn_network</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">directory</span><span class="o">=</span><span class="n">directory</span><span class="p">)</span>

        <span class="c1"># Weight normalization</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_apply_weight_normalization</span><span class="p">(</span><span class="n">scale_factor</span><span class="p">,</span> <span class="n">show_info</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">show_info</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">description</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_snn_network</span>

    <span class="k">def</span> <span class="nf">_apply_weight_normalization</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scale_factor</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">show_info</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Apply the weight normalization as described in Diehl et. al (2015). Note that the function is automatically called by default.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># 1st step: load original ANN</span>
        <span class="n">weight_matrices</span><span class="p">,</span> <span class="n">layer_order</span><span class="p">,</span> <span class="n">layer_operation</span><span class="p">,</span> <span class="n">input_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_extract_weight_matrices</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_filename</span><span class="p">)</span>

        <span class="c1"># 2nd step: normalize weights</span>
        <span class="n">norm_weight_matrices</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_normalize_weights</span><span class="p">(</span><span class="n">weight_matrices</span><span class="p">,</span> <span class="n">scale_factor</span><span class="o">=</span><span class="n">scale_factor</span><span class="p">)</span>

        <span class="c1">## go again over all dense projections to load the weight matrices ##</span>
        <span class="k">for</span> <span class="n">proj</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_snn_network</span><span class="o">.</span><span class="n">get_projections</span><span class="p">():</span>

            <span class="k">if</span> <span class="s1">&#39;dense&#39;</span> <span class="ow">in</span> <span class="n">proj</span><span class="o">.</span><span class="n">name</span><span class="p">:</span> <span class="c1"># find the dense projection</span>
                <span class="n">proj_name</span> <span class="o">=</span> <span class="n">proj</span><span class="o">.</span><span class="n">name</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;_&#39;</span><span class="p">)</span>
                <span class="n">proj_idx</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">proj_name</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="c1"># get the index of the dense layer in relation to all other layers</span>

                <span class="c1">## use the not normed weights to the classification layer</span>
                <span class="n">proj</span><span class="o">.</span><span class="n">w</span> <span class="o">=</span> <span class="n">norm_weight_matrices</span><span class="p">[</span><span class="n">proj_idx</span><span class="p">]</span>


    <span class="k">def</span> <span class="nf">get_annarchy_network</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the ANNarchy.Network instance.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_snn_network</span>

    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
                <span class="n">samples</span><span class="p">,</span> 
                <span class="n">duration_per_sample</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> 
                <span class="n">measure_time</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Performs the prediction for a given input series.</span>

<span class="sd">        Parameters:</span>

<span class="sd">        :param samples: set of inputs to present to the network. The function expects a 2-dimensional array (num_samples, input_size).</span>
<span class="sd">        :param duration_per_sample: the number of simulation steps for one input sample (default: 1000, 1 second biological time)</span>
<span class="sd">        :param measure_time: print out the computation time spent for one input sample (default: False)</span>

<span class="sd">        :returns predictions: A list of predicted class indices. If multiple neurons fulfill the condition, all candidate indices are returned.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">predictions</span> <span class="o">=</span> <span class="p">[[]</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">))]</span>

        <span class="c1"># get the top-level layer</span>
        <span class="n">first_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_snn_network</span><span class="o">.</span><span class="n">get_populations</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">name</span>
        <span class="n">last_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_snn_network</span><span class="o">.</span><span class="n">get_population</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_snn_network</span><span class="o">.</span><span class="n">get_populations</span><span class="p">()[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>

        <span class="c1"># record the last layer to determine prediction</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_read_out</span> <span class="o">==</span> <span class="s2">&quot;membrane_potential&quot;</span><span class="p">:</span>
            <span class="n">m_read_out_layer</span> <span class="o">=</span> <span class="n">Monitor</span><span class="p">(</span><span class="n">last_layer</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;v&#39;</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">m_read_out_layer</span> <span class="o">=</span> <span class="n">Monitor</span><span class="p">(</span><span class="n">last_layer</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;spike&#39;</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_snn_network</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">m_read_out_layer</span><span class="p">)</span>

        <span class="n">class_pop_size</span> <span class="o">=</span> <span class="n">last_layer</span><span class="o">.</span><span class="n">size</span>

        <span class="c1"># Needed when multiple classes achieve the same ranking</span>
        <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">()</span>

        <span class="c1"># Iterate over all samples</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="c1"># Progress bar</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\r</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="c1"># Reset state variables</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_snn_network</span><span class="o">.</span><span class="n">reset</span><span class="p">(</span><span class="n">populations</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">monitors</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">projections</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

            <span class="c1"># set input</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_snn_network</span><span class="o">.</span><span class="n">get_population</span><span class="p">(</span><span class="n">first_layer</span><span class="p">)</span><span class="o">.</span><span class="n">rates</span> <span class="o">=</span>  <span class="n">samples</span><span class="p">[</span><span class="n">i</span><span class="p">,:]</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">_max_f</span>

            <span class="c1"># The read-out is performed differently based on the mode selected by the user</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_read_out</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;time_to_first_spike&quot;</span><span class="p">,</span> <span class="s2">&quot;time_to_k_spikes&quot;</span><span class="p">]:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_snn_network</span><span class="o">.</span><span class="n">simulate_until</span><span class="p">(</span><span class="n">duration_per_sample</span><span class="p">,</span> <span class="n">population</span><span class="o">=</span><span class="n">last_layer</span><span class="p">,</span> <span class="n">measure_time</span><span class="o">=</span><span class="n">measure_time</span><span class="p">)</span>

                <span class="c1"># read-out accumulated inputs</span>
                <span class="n">spk_class</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_snn_network</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">m_read_out_layer</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;spike&#39;</span><span class="p">)</span>
                <span class="n">act_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">class_pop_size</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">neur_rank</span><span class="p">,</span> <span class="n">spike_times</span> <span class="ow">in</span> <span class="n">spk_class</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                    <span class="n">act_pred</span><span class="p">[</span><span class="n">neur_rank</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">spike_times</span><span class="p">)</span>

                <span class="c1"># gather all neurons which fulfilled the condition</span>
                <span class="n">tmp_list</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argwhere</span><span class="p">(</span><span class="n">act_pred</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">amax</span><span class="p">(</span><span class="n">act_pred</span><span class="p">))</span>
                <span class="k">for</span> <span class="n">tmp</span> <span class="ow">in</span> <span class="n">tmp_list</span><span class="p">:</span>
                    <span class="n">predictions</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tmp</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_read_out</span> <span class="o">==</span> <span class="s2">&quot;membrane_potential&quot;</span><span class="p">:</span>
                <span class="c1"># simulate 1s and record spikes in output layer</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_snn_network</span><span class="o">.</span><span class="n">simulate</span><span class="p">(</span><span class="n">duration_per_sample</span><span class="p">,</span> <span class="n">measure_time</span><span class="o">=</span><span class="n">measure_time</span><span class="p">)</span>

                <span class="c1"># read-out accumulated inputs</span>
                <span class="n">spk_class</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_snn_network</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">m_read_out_layer</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;v&#39;</span><span class="p">)</span>

                <span class="c1"># the neuron with the highest accumulated membrane potential is the selected candidate</span>
                <span class="c1"># (HD: 23th May 2023: I&#39;m not sure if it could happen that two neurons have the same mp)</span>
                <span class="n">tmp_list</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argwhere</span><span class="p">(</span><span class="n">spk_class</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,:]</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">amax</span><span class="p">(</span><span class="n">spk_class</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,:]))</span>
                <span class="k">for</span> <span class="n">tmp</span> <span class="ow">in</span> <span class="n">tmp_list</span><span class="p">:</span>
                    <span class="n">predictions</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tmp</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_read_out</span> <span class="o">==</span> <span class="s2">&quot;spike_count&quot;</span><span class="p">:</span>
                <span class="c1"># simulate 1s and record spikes in output layer</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_snn_network</span><span class="o">.</span><span class="n">simulate</span><span class="p">(</span><span class="n">duration_per_sample</span><span class="p">,</span> <span class="n">measure_time</span><span class="o">=</span><span class="n">measure_time</span><span class="p">)</span>

                <span class="c1"># retrieve the recorded spike events</span>
                <span class="n">spk_class</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_snn_network</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">m_read_out_layer</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;spike&#39;</span><span class="p">)</span>

                <span class="c1"># The predicted label is the neuron index with the highest number of spikes.</span>
                <span class="c1"># Therefore, we count the number of spikes each output neuron emitted.</span>
                <span class="n">act_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">class_pop_size</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">neur_rank</span><span class="p">,</span> <span class="n">spike_times</span> <span class="ow">in</span> <span class="n">spk_class</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                    <span class="n">act_pred</span><span class="p">[</span><span class="n">neur_rank</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">spike_times</span><span class="p">)</span>

                <span class="c1"># gather all neurons which achieved highest number of spikes</span>
                <span class="n">tmp_list</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argwhere</span><span class="p">(</span><span class="n">act_pred</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">amax</span><span class="p">(</span><span class="n">act_pred</span><span class="p">))</span>
                <span class="k">for</span> <span class="n">tmp</span> <span class="ow">in</span> <span class="n">tmp_list</span><span class="p">:</span>
                    <span class="n">predictions</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tmp</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">NotImplementedError</span>

        <span class="k">return</span> <span class="n">predictions</span>

    <span class="k">def</span> <span class="nf">_set_input</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sample</span><span class="p">,</span> <span class="n">encoding</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        We will support different input encodings in the future.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">encoding</span> <span class="o">==</span> <span class="s2">&quot;poisson&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_input_pop</span><span class="o">.</span><span class="n">rates</span> <span class="o">=</span> <span class="n">sample</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">_max_f</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_input_pop</span><span class="o">.</span><span class="n">rates</span> <span class="o">=</span> <span class="n">sample</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">_max_f</span>

    <span class="k">def</span> <span class="nf">_extract_weight_matrices</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filename</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Read the .h5 file and extract layer sizes as well as the</span>
<span class="sd">        pre-trained weights.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">f</span><span class="o">=</span><span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span><span class="s1">&#39;r&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="s1">&#39;model_weights&#39;</span> <span class="ow">in</span> <span class="n">f</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s2">&quot;Could not find weight matrices in the .h5 file.&quot;</span><span class="p">)</span>

        <span class="c1">## get the configuration of the Keras model</span>
        <span class="n">model_config</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">attrs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;model_config&quot;</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># h5py &lt; 3.0 get() returns &#39;bytes&#39; sequence</span>
            <span class="n">model_config</span> <span class="o">=</span> <span class="n">model_config</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s2">&quot;utf-8&quot;</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
            <span class="c1"># In h5py &gt; 3.0 the return of get() is already decoded</span>
            <span class="k">pass</span>

        <span class="n">model_config</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">model_config</span><span class="p">)</span>

        <span class="c1">## get the list with all layer names</span>
        <span class="n">model_layers</span> <span class="o">=</span> <span class="p">(</span><span class="n">model_config</span><span class="p">[</span><span class="s1">&#39;config&#39;</span><span class="p">][</span><span class="s1">&#39;layers&#39;</span><span class="p">])</span>
        <span class="n">model_weights</span> <span class="o">=</span> <span class="p">(</span><span class="n">f</span><span class="p">[</span><span class="s1">&#39;model_weights&#39;</span><span class="p">])</span>

        <span class="n">Global</span><span class="o">.</span><span class="n">_debug</span><span class="p">(</span><span class="s2">&quot;ANNtoSNNConverter: detected&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">model_layers</span><span class="p">),</span> <span class="s2">&quot;layers.&quot;</span><span class="p">)</span>

        <span class="n">weight_matrices</span><span class="o">=</span><span class="p">[]</span>   <span class="c1"># array to save the weight matrices</span>
        <span class="n">layer_order</span> <span class="o">=</span> <span class="p">[]</span>     <span class="c1"># additional array to save the order of the layers to know it later</span>
        <span class="n">layer_operation</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1"># additional information for each layer</span>

        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">model_layers</span><span class="p">:</span>
            <span class="n">layer_name</span> <span class="o">=</span> <span class="n">layer</span><span class="p">[</span><span class="s1">&#39;config&#39;</span><span class="p">][</span><span class="s1">&#39;name&#39;</span><span class="p">]</span>
            <span class="n">layer_class</span> <span class="o">=</span> <span class="n">layer</span><span class="p">[</span><span class="s1">&#39;class_name&#39;</span><span class="p">]</span>

            <span class="k">if</span> <span class="s1">&#39;conv2d&#39;</span> <span class="ow">in</span> <span class="n">layer_name</span><span class="p">:</span>
                <span class="n">layer_w</span> <span class="o">=</span> <span class="n">model_weights</span><span class="p">[</span><span class="n">layer_name</span><span class="p">][</span><span class="n">layer_name</span><span class="p">][</span><span class="s1">&#39;kernel:0&#39;</span><span class="p">]</span>
                <span class="c1">## if it is a convolutional layer, reshape it to fitt to annarchy</span>
                <span class="n">dim_h</span><span class="p">,</span> <span class="n">dim_w</span><span class="p">,</span> <span class="n">dim_pre</span><span class="p">,</span> <span class="n">dim_post</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">layer_w</span><span class="p">)</span>
                <span class="n">new_w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">dim_post</span><span class="p">,</span> <span class="n">dim_h</span><span class="p">,</span> <span class="n">dim_w</span><span class="p">,</span> <span class="n">dim_pre</span><span class="p">))</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">dim_post</span><span class="p">):</span>
                    <span class="n">new_w</span><span class="p">[</span><span class="n">i</span><span class="p">,:,:]</span> <span class="o">=</span> <span class="n">layer_w</span><span class="p">[:,:,:,</span><span class="n">i</span><span class="p">]</span>
                <span class="n">weight_matrices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">new_w</span><span class="p">)</span>
                <span class="n">layer_order</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layer_name</span><span class="p">)</span>
                <span class="n">layer_operation</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span> <span class="c1"># add an empty string to pad the array</span>

            <span class="k">elif</span> <span class="s1">&#39;dense&#39;</span> <span class="ow">in</span> <span class="n">layer_name</span><span class="p">:</span>
                <span class="n">layer_w</span> <span class="o">=</span> <span class="n">model_weights</span><span class="p">[</span><span class="n">layer_name</span><span class="p">][</span><span class="n">layer_name</span><span class="p">][</span><span class="s1">&#39;kernel:0&#39;</span><span class="p">]</span>
                <span class="n">weight_matrices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">layer_w</span><span class="p">))</span>
                <span class="n">layer_order</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layer_name</span><span class="p">)</span>
                <span class="n">layer_operation</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span> <span class="c1"># add an empty string to pad the array</span>

            <span class="k">elif</span> <span class="s1">&#39;pool&#39;</span> <span class="ow">in</span> <span class="n">layer_name</span><span class="p">:</span>
                <span class="n">layer_order</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layer_name</span><span class="p">)</span>
                <span class="n">weight_matrices</span><span class="o">.</span><span class="n">append</span><span class="p">([])</span> <span class="c1"># add an empty weight matrix to pad the array</span>
                <span class="k">if</span> <span class="s2">&quot;AveragePooling&quot;</span> <span class="ow">in</span> <span class="n">layer_class</span><span class="p">:</span>
                    <span class="n">layer_operation</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;mean&quot;</span><span class="p">)</span>
                <span class="k">elif</span> <span class="s2">&quot;MaxPooling&quot;</span> <span class="ow">in</span> <span class="n">layer_class</span><span class="p">:</span>
                    <span class="n">layer_operation</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;max&quot;</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">Global</span><span class="o">.</span><span class="n">_warning</span><span class="p">(</span><span class="s2">&quot;The pooling class:&quot;</span><span class="p">,</span> <span class="n">layer_class</span><span class="p">,</span> <span class="s2">&quot;is not supported yet. Falling back to max-pooling.&quot;</span><span class="p">)</span>
                    <span class="n">layer_operation</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;max&quot;</span><span class="p">)</span>

            <span class="k">elif</span> <span class="s1">&#39;input&#39;</span> <span class="ow">in</span> <span class="n">layer_name</span><span class="p">:</span>
                <span class="n">layer_order</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layer_name</span><span class="p">)</span>
                <span class="n">input_dim</span> <span class="o">=</span> <span class="n">layer</span><span class="p">[</span><span class="s1">&#39;config&#39;</span><span class="p">][</span><span class="s1">&#39;batch_input_shape&#39;</span><span class="p">]</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_dim</span><span class="p">)</span> <span class="o">&gt;</span><span class="mi">2</span> <span class="p">:</span> <span class="c1">#probably a conv. if &gt;2</span>
                    <span class="n">input_dim</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">input_dim</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">3</span><span class="p">])</span>
                <span class="k">else</span><span class="p">:</span>           <span class="c1"># probably a MLP</span>
                    <span class="n">input_dim</span> <span class="o">=</span> <span class="n">input_dim</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
                <span class="n">weight_matrices</span><span class="o">.</span><span class="n">append</span><span class="p">([])</span> <span class="c1"># add an empty weight matrix to pad the array</span>
                <span class="n">layer_operation</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">weight_matrices</span><span class="p">,</span> <span class="n">layer_order</span><span class="p">,</span> <span class="n">layer_operation</span><span class="p">,</span> <span class="n">input_dim</span>

    <span class="k">def</span> <span class="nf">_normalize_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weight_matrices</span><span class="p">,</span> <span class="n">scale_factor</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Weight normalization based on the &quot;model based normalization&quot; from Diehl et al. (2015)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">norm_wlist</span><span class="o">=</span><span class="p">[]</span>

        <span class="c1">## Argument checking</span>
        <span class="k">if</span> <span class="n">scale_factor</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">scale_factor</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">weight_matrices</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">scale_factor</span><span class="p">,</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="nb">int</span><span class="p">)):</span>
            <span class="n">scale_factor</span> <span class="o">=</span> <span class="p">[</span><span class="n">scale_factor</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">weight_matrices</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">scale_factor</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">)):</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">scale_factor</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">weight_matrices</span><span class="p">):</span>
                <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s2">&quot;The length of the scale_factor list must be equal the number of projections.&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">pass</span> <span class="c1"># nothing to do</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Invalid argument for scale_factor&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">scale_factor</span><span class="p">))</span>

        <span class="c1">## iterate over all weight matrices</span>
        <span class="k">for</span> <span class="n">level</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">weight_matrices</span><span class="p">)):</span>
            <span class="n">max_pos_input</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">w_matrix</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="n">weight_matrices</span><span class="p">[</span><span class="n">level</span><span class="p">])</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">w_matrix</span><span class="p">)</span><span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span> <span class="c1"># Empty weight matrix ?</span>
                <span class="c1">## each row correspnds to one post-synaptic neuron</span>
                <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="nb">range</span> <span class="p">(</span><span class="n">w_matrix</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
                    <span class="n">w_matrix_flat</span><span class="o">=</span><span class="n">w_matrix</span><span class="p">[</span><span class="n">row</span><span class="p">]</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
                    <span class="n">idx</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">w_matrix_flat</span><span class="o">&gt;</span><span class="mi">0</span><span class="p">)</span>
                    <span class="n">input_sum</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">w_matrix_flat</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
                    <span class="c1">## save the maximum input current over all post neurons in this connection</span>
                    <span class="n">max_pos_input</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">max_pos_input</span><span class="p">,</span> <span class="n">input_sum</span><span class="p">)</span>

                <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="nb">range</span> <span class="p">(</span><span class="n">w_matrix</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
                    <span class="c1">## normalize the incoming weights for each neuron, based on the maximum input</span>
                    <span class="c1">## for the complete connection</span>
                    <span class="c1">## and multiply it with the deepth of the connection to boost the input current</span>
                    <span class="n">w_matrix</span><span class="p">[</span><span class="n">row</span><span class="p">]</span><span class="o">=</span><span class="n">scale_factor</span><span class="p">[</span><span class="n">level</span><span class="p">]</span><span class="o">*</span> <span class="n">w_matrix</span><span class="p">[</span><span class="n">row</span><span class="p">]</span><span class="o">/</span><span class="n">max_pos_input</span>

            <span class="n">norm_wlist</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">w_matrix</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">norm_wlist</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">










<div class="doc doc-object doc-function">



<h4 id="ANNarchy.extensions.ann_to_snn_conversion.ANNtoSNNConverter.ANNtoSNNConverter.__init__" class="doc doc-heading">
          <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">input_encoding</span><span class="o">=</span><span class="s1">&#39;poisson&#39;</span><span class="p">,</span> <span class="n">hidden_neuron</span><span class="o">=</span><span class="s1">&#39;IaF&#39;</span><span class="p">,</span> <span class="n">read_out</span><span class="o">=</span><span class="s1">&#39;spike_count&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#ANNarchy.extensions.ann_to_snn_conversion.ANNtoSNNConverter.ANNtoSNNConverter.__init__" class="headerlink" title="Permanent link">#</a></h4>


  <div class="doc doc-contents ">
  
      



  <p>Parameters:</p>
  <ul>
      <li class="field-body">
        <b><code>input_encoding</code></b>
        
        <div class="doc-md-description">
          <p>a string representing which input encoding should be used: custom poisson, PSO, IB or CH (for more details see InputEncoding).</p>
        </div>
      </li>
      <li class="field-body">
        <b><code>hidden_neuron</code></b>
        
        <div class="doc-md-description">
          <p>neuron model used in the hidden layers. Either the default integrate-and-fire ('IaF') or an ANNarchy Neuron object.</p>
        </div>
      </li>
      <li class="field-body">
        <b><code>read_out</code></b>
        
        <div class="doc-md-description">
          <p>a string which of the following read-out method should be used: spike_count, time_to_first_spike, membrane_potential (for more details see the manual).</p>
        </div>
      </li>
  </ul>

          <details class="quote">
            <summary>Source code in <code>ANNarchy/extensions/ann_to_snn_conversion/ANNtoSNNConverter.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_encoding</span><span class="o">=</span><span class="s1">&#39;poisson&#39;</span><span class="p">,</span> <span class="n">hidden_neuron</span><span class="o">=</span><span class="s1">&#39;IaF&#39;</span><span class="p">,</span> <span class="n">read_out</span><span class="o">=</span><span class="s1">&#39;spike_count&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    :param input_encoding: a string representing which input encoding should be used: custom poisson, PSO, IB or CH (for more details see InputEncoding).</span>
<span class="sd">    :param hidden_neuron:  neuron model used in the hidden layers. Either the default integrate-and-fire (&#39;IaF&#39;) or an ANNarchy Neuron object.</span>
<span class="sd">    :param read_out: a string which of the following read-out method should be used: spike_count, time_to_first_spike, membrane_potential (for more details see the manual).</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># Neuron model</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">hidden_neuron</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">hidden_neuron</span> <span class="o">==</span> <span class="s2">&quot;IaF&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_hidden_neuron_model</span> <span class="o">=</span> <span class="n">IaF</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Invalid model name for hidden neurons.&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_hidden_neuron_model</span> <span class="o">=</span> <span class="n">hidden_neuron</span>

    <span class="c1"># Input encoding</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_input_encoding</span> <span class="o">=</span> <span class="n">input_encoding</span>
    <span class="k">if</span> <span class="n">input_encoding</span> <span class="o">==</span> <span class="s2">&quot;poisson&quot;</span> <span class="ow">or</span> <span class="n">input_encoding</span> <span class="o">==</span> <span class="s2">&quot;CPN&quot;</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_input_model</span> <span class="o">=</span> <span class="n">CPN</span>
    <span class="k">elif</span> <span class="n">input_encoding</span> <span class="o">==</span> <span class="s1">&#39;PSO&#39;</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_input_model</span> <span class="o">=</span> <span class="n">PSO</span>
    <span class="k">elif</span> <span class="n">input_encoding</span><span class="o">==</span><span class="s1">&#39;IB&#39;</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_input_model</span> <span class="o">=</span> <span class="n">IB</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Unknown input encoding:&quot;</span><span class="p">,</span> <span class="n">input_encoding</span><span class="p">)</span>

    <span class="c1"># Readout</span>
    <span class="k">if</span> <span class="n">read_out</span> <span class="ow">in</span> <span class="n">available_read_outs</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_read_out</span> <span class="o">=</span> <span class="n">read_out</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Unknown value for read-out:&quot;</span><span class="p">,</span> <span class="n">read_out</span><span class="p">)</span>

    <span class="c1"># Maximum frequency</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_max_f</span> <span class="o">=</span> <span class="mi">100</span>      <span class="c1"># scale factor used for poisson encoding</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_read_out</span> <span class="o">==</span> <span class="s2">&quot;time_to_k_spikes&quot;</span><span class="p">:</span>
        <span class="k">if</span> <span class="s1">&#39;k&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s2">&quot;When read_out is set to &#39;time_to_k_spikes&#39;, the k parameter need to be provided.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_k_param</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;k&#39;</span><span class="p">]</span>

    <span class="c1"># TODO: sanity check on key-value args</span>
    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">key</span> <span class="o">==</span> <span class="s2">&quot;max_f&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_max_f</span> <span class="o">=</span> <span class="n">value</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_snn_network</span> <span class="o">=</span> <span class="kc">None</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h4 id="ANNarchy.extensions.ann_to_snn_conversion.ANNtoSNNConverter.ANNtoSNNConverter.get_annarchy_network" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">get_annarchy_network</span><span class="p">()</span></code>

<a href="#ANNarchy.extensions.ann_to_snn_conversion.ANNtoSNNConverter.ANNtoSNNConverter.get_annarchy_network" class="headerlink" title="Permanent link">#</a></h4>


  <div class="doc doc-contents ">
  
      <p>Returns the ANNarchy.Network instance.</p>

          <details class="quote">
            <summary>Source code in <code>ANNarchy/extensions/ann_to_snn_conversion/ANNtoSNNConverter.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">get_annarchy_network</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the ANNarchy.Network instance.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_snn_network</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h4 id="ANNarchy.extensions.ann_to_snn_conversion.ANNtoSNNConverter.ANNtoSNNConverter.init_from_keras_model" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">init_from_keras_model</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">directory</span><span class="o">=</span><span class="s1">&#39;annarchy&#39;</span><span class="p">,</span> <span class="n">scale_factor</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">show_info</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></code>

<a href="#ANNarchy.extensions.ann_to_snn_conversion.ANNtoSNNConverter.ANNtoSNNConverter.init_from_keras_model" class="headerlink" title="Permanent link">#</a></h4>


  <div class="doc doc-contents ">
  
      <p>Loads the pre-trained model provided as a .h5 file.</p>
<p>In tf.keras, the weights can be saved using:</p>
<div class="highlight"><pre><span></span><code><span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;model.h5&quot;</span><span class="p">)</span>
</code></pre></div>



  <p>Parameters:</p>
  <ul>
      <li class="field-body">
        <b><code>filename</code></b>
        
        <div class="doc-md-description">
          <p>stored model as a .h5 file.</p>
        </div>
      </li>
      <li class="field-body">
        <b><code>directory</code></b>
        
        <div class="doc-md-description">
          <p>sub-directory where the generated code should be stored (default: "annarchy")</p>
        </div>
      </li>
      <li class="field-body">
        <b><code>scale_factor</code></b>
        
        <div class="doc-md-description">
          <p>allows a fine-grained control of the weight scale factor. By default (None), with each layer-depth the factor increases by one. If a scalar value is provided the same value is used for each layer. Otherwise a list can be provided to assign the scale factors individually.</p>
        </div>
      </li>
      <li class="field-body">
        <b><code>show_info</code></b>
        
        <div class="doc-md-description">
          <p>whether the network structure should be printed on console (default: True)</p>
        </div>
      </li>
  </ul>



  <p>Returns:</p>
  <ul>
      <li class="field-body">
        
        <div class="doc-md-description">
          <p>An <code>ANNarchy.Network</code> instance.</p>
      </div>
      </li>
  </ul>

          <details class="quote">
            <summary>Source code in <code>ANNarchy/extensions/ann_to_snn_conversion/ANNtoSNNConverter.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span></pre></div></td><td class="code"><div><pre><span></span><code>    <span class="k">def</span> <span class="nf">init_from_keras_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
            <span class="n">filename</span><span class="p">,</span> 
            <span class="n">directory</span><span class="o">=</span><span class="s2">&quot;annarchy&quot;</span><span class="p">,</span> 
            <span class="n">scale_factor</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
            <span class="n">show_info</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
        <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Loads the pre-trained model provided as a .h5 file.</span>

<span class="sd">        In tf.keras, the weights can be saved using:</span>

<span class="sd">        ```python</span>
<span class="sd">        model.save(&quot;model.h5&quot;)</span>
<span class="sd">        ```</span>

<span class="sd">        :param filename: stored model as a .h5 file.</span>
<span class="sd">        :param directory: sub-directory where the generated code should be stored (default: &quot;annarchy&quot;)</span>
<span class="sd">        :param scale_factor: allows a fine-grained control of the weight scale factor. By default (None), with each layer-depth the factor increases by one. If a scalar value is provided the same value is used for each layer. Otherwise a list can be provided to assign the scale factors individually.</span>
<span class="sd">        :param show_info: whether the network structure should be printed on console (default: True)</span>

<span class="sd">        :returns net: An `ANNarchy.Network` instance.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Filename</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">filename</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;.h5&quot;</span><span class="p">):</span>
            <span class="n">Global</span><span class="o">.</span><span class="n">_error</span><span class="p">(</span><span class="s2">&quot;ANNtoSNNConverter: the keras model must be provided as a .h5 file.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_filename</span> <span class="o">=</span> <span class="n">filename</span>

        <span class="c1"># Extract weight matrices</span>
        <span class="n">weight_matrices</span><span class="p">,</span> <span class="n">layer_order</span><span class="p">,</span> <span class="n">layer_operation</span><span class="p">,</span> <span class="n">input_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_extract_weight_matrices</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>

        <span class="c1"># Create spiking network</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_snn_network</span> <span class="o">=</span> <span class="n">Network</span><span class="p">(</span><span class="n">everything</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
        <span class="n">input_pop</span> <span class="o">=</span> <span class="n">Population</span><span class="p">(</span><span class="n">name</span> <span class="o">=</span> <span class="n">layer_order</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">geometry</span><span class="o">=</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">neuron</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_input_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_snn_network</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">input_pop</span><span class="p">)</span>

        <span class="c1"># Hidden neuron</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_hidden_neuron_model</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">hidden_type</span> <span class="o">=</span> <span class="s2">&quot;user-specified&quot;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">hidden_type</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_hidden_neuron_model</span><span class="o">.</span><span class="n">name</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_hidden_neuron_model</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_hidden_neuron_model</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">layer_order</span><span class="p">)</span><span class="o">-</span><span class="mi">2</span><span class="p">)]</span>

        <span class="n">description</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;&quot;&quot;Parameters</span>
<span class="s2">----------------------</span>
<span class="s2">* input encoding: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_input_encoding</span><span class="si">}</span>
<span class="s2">* hidden neuron: </span><span class="si">{</span><span class="n">hidden_type</span><span class="si">}</span>
<span class="s2">* read-out method: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_read_out</span><span class="si">}</span>

<span class="s2">Layers</span>
<span class="s2">----------------------</span>
<span class="s2">&quot;&quot;&quot;</span>

        <span class="c1"># Create populations</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">layer_order</span><span class="p">)):</span>
            <span class="k">if</span> <span class="s1">&#39;conv&#39;</span> <span class="ow">in</span> <span class="n">layer_order</span><span class="p">[</span><span class="n">layer</span><span class="p">]:</span>

                <span class="n">geometry</span> <span class="o">=</span> <span class="n">input_dim</span> <span class="o">+</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">weight_matrices</span><span class="p">[</span><span class="n">layer</span><span class="p">])[</span><span class="mi">0</span><span class="p">],)</span>
                <span class="n">conv_pop</span> <span class="o">=</span> <span class="n">Population</span><span class="p">(</span><span class="n">geometry</span> <span class="o">=</span> <span class="n">geometry</span><span class="p">,</span> <span class="n">neuron</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_hidden_neuron_model</span><span class="p">[</span><span class="n">layer</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="n">layer_order</span><span class="p">[</span><span class="n">layer</span><span class="p">]</span> <span class="p">)</span> <span class="c1"># create convolution population</span>
                <span class="n">conv_pop</span><span class="o">.</span><span class="n">vt</span> <span class="o">=</span> <span class="n">conv_pop</span><span class="o">.</span><span class="n">vt</span> <span class="o">-</span> <span class="p">(</span><span class="mf">0.05</span><span class="o">*</span><span class="n">layer</span><span class="p">)</span> <span class="c1"># reduce the threshold for deeper layers</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_snn_network</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">conv_pop</span><span class="p">)</span>

                <span class="n">description</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;* name=</span><span class="si">{</span><span class="n">layer_order</span><span class="p">[</span><span class="n">layer</span><span class="p">]</span><span class="si">}</span><span class="s2">, convolutional layer, </span><span class="si">{</span><span class="n">geometry</span><span class="si">=}</span><span class="se">\n</span><span class="s2">&quot;</span>

            <span class="k">elif</span> <span class="s1">&#39;pool&#39;</span> <span class="ow">in</span> <span class="n">layer_order</span><span class="p">[</span><span class="n">layer</span><span class="p">]:</span>

                <span class="n">input_dim</span> <span class="o">=</span> <span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">input_dim</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span> <span class="mi">2</span><span class="p">),</span> <span class="nb">int</span><span class="p">(</span><span class="n">input_dim</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">/</span> <span class="mi">2</span><span class="p">))</span>
                <span class="n">l_weights</span> <span class="o">=</span> <span class="n">weight_matrices</span><span class="p">[</span><span class="n">layer</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># get the weights of the previous layer (should be a conv-layer, or not?)</span>
                <span class="n">dim_0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">l_weights</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

                <span class="n">geometry</span> <span class="o">=</span> <span class="n">input_dim</span> <span class="c1"># add it to the geometry</span>
                <span class="n">geometry</span> <span class="o">=</span> <span class="n">geometry</span> <span class="o">+</span> <span class="p">(</span><span class="n">dim_0</span><span class="p">,)</span>
                <span class="n">pool_pop</span> <span class="o">=</span> <span class="n">Population</span><span class="p">(</span><span class="n">geometry</span> <span class="o">=</span> <span class="n">geometry</span><span class="p">,</span> <span class="n">neuron</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_hidden_neuron_model</span><span class="p">[</span><span class="n">layer</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="n">layer_order</span><span class="p">[</span><span class="n">layer</span><span class="p">])</span>
                <span class="n">pool_pop</span><span class="o">.</span><span class="n">vt</span> <span class="o">=</span> <span class="n">pool_pop</span><span class="o">.</span><span class="n">vt</span> <span class="o">-</span> <span class="p">(</span><span class="mf">0.05</span><span class="o">*</span><span class="n">layer</span><span class="p">)</span> <span class="c1"># reduce the threshold for deeper layers</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_snn_network</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">pool_pop</span><span class="p">)</span>

                <span class="n">description</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;* name=</span><span class="si">{</span><span class="n">layer_order</span><span class="p">[</span><span class="n">layer</span><span class="p">]</span><span class="si">}</span><span class="s2">, pooling layer, </span><span class="si">{</span><span class="n">geometry</span><span class="si">=}</span><span class="se">\n</span><span class="s2">&quot;</span>

            <span class="k">elif</span> <span class="s1">&#39;dense&#39;</span> <span class="ow">in</span> <span class="n">layer_order</span><span class="p">[</span><span class="n">layer</span><span class="p">]:</span>

                <span class="n">geometry</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">weight_matrices</span><span class="p">[</span><span class="n">layer</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span>

                <span class="c1"># read-out layer</span>
                <span class="k">if</span> <span class="n">layer</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer_order</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_read_out</span> <span class="o">==</span> <span class="s2">&quot;membrane_potential&quot;</span><span class="p">:</span>
                        <span class="c1"># HD (24th April 2023): instead of reading out spike events, we use the accumulated inputs</span>
                        <span class="c1">#                       as decision parameter</span>
                        <span class="n">dense_pop</span> <span class="o">=</span> <span class="n">Population</span><span class="p">(</span><span class="n">geometry</span> <span class="o">=</span> <span class="n">geometry</span><span class="p">,</span> <span class="n">neuron</span><span class="o">=</span><span class="n">IaF_Acc</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">layer_order</span><span class="p">[</span><span class="n">layer</span><span class="p">])</span>

                    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_read_out</span> <span class="o">==</span> <span class="s2">&quot;time_to_first_spike&quot;</span> <span class="ow">and</span> <span class="n">layer</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer_order</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span>
                        <span class="c1"># HD (24th April 2023): instead of reading out spike events, we simulate untile the first</span>
                        <span class="c1">#                       neuron in the read-out layer spikes.</span>
                        <span class="n">dense_pop</span> <span class="o">=</span> <span class="n">Population</span><span class="p">(</span><span class="n">geometry</span> <span class="o">=</span> <span class="n">geometry</span><span class="p">,</span> <span class="n">neuron</span><span class="o">=</span><span class="n">IaF</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">layer_order</span><span class="p">[</span><span class="n">layer</span><span class="p">],</span> <span class="n">stop_condition</span><span class="o">=</span><span class="s2">&quot;spiked: any&quot;</span><span class="p">)</span>

                    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_read_out</span> <span class="o">==</span> <span class="s2">&quot;time_to_k_spikes&quot;</span> <span class="ow">and</span> <span class="n">layer</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer_order</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span>
                        <span class="c1"># HD (3rd May 2023): instead of reading out spike events, we simulate untile the first</span>
                        <span class="c1">#                    neuron emitted k spikes in the read-out layer.</span>
                        <span class="n">dense_pop</span> <span class="o">=</span> <span class="n">Population</span><span class="p">(</span><span class="n">geometry</span> <span class="o">=</span> <span class="n">geometry</span><span class="p">,</span> <span class="n">neuron</span><span class="o">=</span><span class="n">IaF_TTKS</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">layer_order</span><span class="p">[</span><span class="n">layer</span><span class="p">],</span> <span class="n">stop_condition</span><span class="o">=</span><span class="s2">&quot;sc &gt;= k: any&quot;</span><span class="p">)</span>
                        <span class="n">dense_pop</span><span class="o">.</span><span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_k_param</span>

                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">dense_pop</span> <span class="o">=</span> <span class="n">Population</span><span class="p">(</span><span class="n">geometry</span> <span class="o">=</span> <span class="n">geometry</span><span class="p">,</span> <span class="n">neuron</span><span class="o">=</span><span class="n">IaF_ReadOut</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">layer_order</span><span class="p">[</span><span class="n">layer</span><span class="p">])</span>
                        <span class="c1"># ARK:  scaling the threshold as number of layers increases divide</span>
                        <span class="c1">#       the value 1/half of the number of the network</span>
                        <span class="n">dense_pop</span><span class="o">.</span><span class="n">vt</span> <span class="o">=</span> <span class="n">dense_pop</span><span class="o">.</span><span class="n">vt</span> <span class="o">-</span> <span class="p">(</span><span class="mf">0.05</span><span class="o">*</span><span class="n">layer</span><span class="p">)</span>
                        <span class="c1"># HD (20th Feb. 2023): we want to generate this firing vector for a</span>
                        <span class="c1">#                      single time step</span>
                        <span class="n">dense_pop</span><span class="o">.</span><span class="n">compute_firing_rate</span><span class="p">(</span><span class="n">Global</span><span class="o">.</span><span class="n">dt</span><span class="p">())</span>

                <span class="c1"># hidden layer neurons</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">dense_pop</span> <span class="o">=</span> <span class="n">Population</span><span class="p">(</span><span class="n">geometry</span> <span class="o">=</span> <span class="n">geometry</span><span class="p">,</span> <span class="n">neuron</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_hidden_neuron_model</span><span class="p">[</span><span class="n">layer</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="n">layer_order</span><span class="p">[</span><span class="n">layer</span><span class="p">])</span>
                    <span class="c1"># ARK:  scaling the threshold as number of layers increases divide</span>
                    <span class="c1">#       the value 1/half of the number of the network</span>
                    <span class="n">dense_pop</span><span class="o">.</span><span class="n">vt</span> <span class="o">=</span> <span class="n">dense_pop</span><span class="o">.</span><span class="n">vt</span> <span class="o">-</span> <span class="p">(</span><span class="mf">0.05</span><span class="o">*</span><span class="n">layer</span><span class="p">)</span>
                    <span class="c1"># HD (20th Feb. 2023): we want to generate this firing vector for a</span>
                    <span class="c1">#                      single time step</span>
                    <span class="n">dense_pop</span><span class="o">.</span><span class="n">compute_firing_rate</span><span class="p">(</span><span class="n">Global</span><span class="o">.</span><span class="n">dt</span><span class="p">())</span>

                <span class="c1"># Add created layer to the network</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_snn_network</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">dense_pop</span><span class="p">)</span>

                <span class="c1"># Description</span>
                <span class="n">description</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;* name=</span><span class="si">{</span><span class="n">layer_order</span><span class="p">[</span><span class="n">layer</span><span class="p">]</span><span class="si">}</span><span class="s2">, dense layer, </span><span class="si">{</span><span class="n">geometry</span><span class="si">=}</span><span class="se">\n</span><span class="s2">&quot;</span>


        <span class="c1"># Create Projections</span>
        <span class="n">description</span> <span class="o">+=</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Projections</span><span class="se">\n</span><span class="s1">----------------------</span><span class="se">\n</span><span class="s1">&#39;</span>

        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">layer_order</span><span class="p">)):</span>
            <span class="k">if</span> <span class="s1">&#39;conv&#39;</span> <span class="ow">in</span> <span class="n">layer_order</span><span class="p">[</span><span class="n">p</span><span class="p">]:</span>

                <span class="n">post_pop</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_snn_network</span><span class="o">.</span><span class="n">get_population</span><span class="p">(</span><span class="n">layer_order</span><span class="p">[</span><span class="n">p</span><span class="p">])</span>
                <span class="n">pre_pop</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_snn_network</span><span class="o">.</span><span class="n">get_population</span><span class="p">(</span><span class="n">layer_order</span><span class="p">[</span><span class="n">p</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

                <span class="n">weight_m</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">weight_matrices</span><span class="p">[</span><span class="n">p</span><span class="p">])</span>

                <span class="n">conv_proj</span> <span class="o">=</span> <span class="n">Convolution</span><span class="p">(</span><span class="n">pre</span> <span class="o">=</span> <span class="n">pre_pop</span><span class="p">,</span> <span class="n">post</span><span class="o">=</span><span class="n">post_pop</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="s1">&#39;exc&#39;</span><span class="p">,</span> <span class="n">psp</span><span class="o">=</span><span class="s2">&quot;pre.mask * w&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;conv_proj_</span><span class="si">%i</span><span class="s1">&#39;</span><span class="o">%</span><span class="n">p</span><span class="p">)</span>
                <span class="n">conv_proj</span><span class="o">.</span><span class="n">connect_filters</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="n">weight_m</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_snn_network</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">conv_proj</span><span class="p">)</span>

                <span class="n">description</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;* </span><span class="si">{</span><span class="n">layer_order</span><span class="p">[</span><span class="n">p</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">pre_pop</span><span class="o">.</span><span class="n">geometry</span><span class="si">}</span><span class="s2"> -&gt; </span><span class="si">{</span><span class="n">layer_order</span><span class="p">[</span><span class="n">p</span><span class="p">]</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">post_pop</span><span class="o">.</span><span class="n">geometry</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="n">description</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;    weight matrix </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">weight_m</span><span class="p">)</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>


            <span class="k">elif</span> <span class="s1">&#39;pool&#39;</span> <span class="ow">in</span> <span class="n">layer_order</span><span class="p">[</span><span class="n">p</span><span class="p">]:</span>

                <span class="n">post_pop</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_snn_network</span><span class="o">.</span><span class="n">get_population</span><span class="p">(</span><span class="n">layer_order</span><span class="p">[</span><span class="n">p</span><span class="p">])</span>
                <span class="n">pre_pop</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_snn_network</span><span class="o">.</span><span class="n">get_population</span><span class="p">(</span><span class="n">layer_order</span><span class="p">[</span><span class="n">p</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

                <span class="n">pool_proj</span> <span class="o">=</span> <span class="n">Pooling</span><span class="p">(</span><span class="n">pre</span> <span class="o">=</span> <span class="n">pre_pop</span><span class="p">,</span> <span class="n">post</span><span class="o">=</span><span class="n">post_pop</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="s1">&#39;exc&#39;</span><span class="p">,</span> <span class="n">operation</span><span class="o">=</span><span class="n">layer_operation</span><span class="p">[</span><span class="n">p</span><span class="p">],</span> <span class="n">psp</span><span class="o">=</span><span class="s2">&quot;pre.mask&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;pool_proj_</span><span class="si">%i</span><span class="s1">&#39;</span><span class="o">%</span><span class="n">p</span><span class="p">)</span>
                <span class="n">pool_proj</span><span class="o">.</span><span class="n">connect_pooling</span><span class="p">(</span><span class="n">extent</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_snn_network</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">pool_proj</span><span class="p">)</span>

                <span class="n">description</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;* </span><span class="si">{</span><span class="n">layer_order</span><span class="p">[</span><span class="n">p</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">pre_pop</span><span class="o">.</span><span class="n">geometry</span><span class="si">}</span><span class="s2"> -&gt; </span><span class="si">{</span><span class="n">layer_order</span><span class="p">[</span><span class="n">p</span><span class="p">]</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">post_pop</span><span class="o">.</span><span class="n">geometry</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="n">description</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;    pooling operation </span><span class="si">{</span><span class="n">layer_operation</span><span class="p">[</span><span class="n">p</span><span class="p">]</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>

            <span class="k">elif</span> <span class="s1">&#39;dense&#39;</span> <span class="ow">in</span> <span class="n">layer_order</span><span class="p">[</span><span class="n">p</span><span class="p">]:</span>

                <span class="n">post_pop</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_snn_network</span><span class="o">.</span><span class="n">get_population</span><span class="p">(</span><span class="n">layer_order</span><span class="p">[</span><span class="n">p</span><span class="p">])</span>
                <span class="n">pre_pop</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_snn_network</span><span class="o">.</span><span class="n">get_population</span><span class="p">(</span><span class="n">layer_order</span><span class="p">[</span><span class="n">p</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

                <span class="n">dense_proj</span> <span class="o">=</span> <span class="n">Projection</span><span class="p">(</span>
                    <span class="n">pre</span> <span class="o">=</span> <span class="n">pre_pop</span><span class="p">,</span> <span class="n">post</span> <span class="o">=</span> <span class="n">post_pop</span><span class="p">,</span> 
                    <span class="n">target</span> <span class="o">=</span> <span class="s2">&quot;exc&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;dense_proj_</span><span class="si">%i</span><span class="s1">&#39;</span><span class="o">%</span><span class="n">p</span>
                <span class="p">)</span>

                <span class="k">if</span> <span class="n">pre_pop</span><span class="o">.</span><span class="n">neuron_type</span><span class="o">.</span><span class="n">type</span><span class="o">==</span><span class="s2">&quot;rate&quot;</span><span class="p">:</span>
                    <span class="n">dense_proj</span><span class="o">.</span><span class="n">connect_all_to_all</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="n">Uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">storage_format</span><span class="o">=</span><span class="s2">&quot;dense&quot;</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">dense_proj</span><span class="o">.</span><span class="n">connect_all_to_all</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="n">Uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">storage_format</span><span class="o">=</span><span class="s2">&quot;dense&quot;</span><span class="p">,</span> <span class="n">storage_order</span><span class="o">=</span><span class="s2">&quot;pre_to_post&quot;</span><span class="p">)</span>
                    <span class="n">dense_proj</span><span class="o">.</span><span class="n">_parallel_pattern</span> <span class="o">=</span> <span class="s2">&quot;outer_loop&quot;</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">_snn_network</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">dense_proj</span><span class="p">)</span>

                <span class="n">description</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;* </span><span class="si">{</span><span class="n">layer_order</span><span class="p">[</span><span class="n">p</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">pre_pop</span><span class="o">.</span><span class="n">geometry</span><span class="si">}</span><span class="s2"> -&gt; </span><span class="si">{</span><span class="n">layer_order</span><span class="p">[</span><span class="n">p</span><span class="p">]</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">post_pop</span><span class="o">.</span><span class="n">geometry</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="n">description</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;    weight matrix size </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">weight_matrices</span><span class="p">[</span><span class="n">p</span><span class="p">])</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="n">description</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;    mean </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">weight_matrices</span><span class="p">[</span><span class="n">p</span><span class="p">])</span><span class="si">}</span><span class="s2">, std </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">weight_matrices</span><span class="p">[</span><span class="n">p</span><span class="p">])</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="n">description</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;    min </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">weight_matrices</span><span class="p">[</span><span class="n">p</span><span class="p">])</span><span class="si">}</span><span class="s2">, max </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">weight_matrices</span><span class="p">[</span><span class="n">p</span><span class="p">])</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>

        <span class="c1"># Compile the configured network</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_snn_network</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">directory</span><span class="o">=</span><span class="n">directory</span><span class="p">)</span>

        <span class="c1"># Weight normalization</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_apply_weight_normalization</span><span class="p">(</span><span class="n">scale_factor</span><span class="p">,</span> <span class="n">show_info</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">show_info</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">description</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_snn_network</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h4 id="ANNarchy.extensions.ann_to_snn_conversion.ANNtoSNNConverter.ANNtoSNNConverter.predict" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">predict</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">duration_per_sample</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">measure_time</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

<a href="#ANNarchy.extensions.ann_to_snn_conversion.ANNtoSNNConverter.ANNtoSNNConverter.predict" class="headerlink" title="Permanent link">#</a></h4>


  <div class="doc doc-contents ">
  
      <p>Performs the prediction for a given input series.</p>
<p>Parameters:</p>



  <p>Parameters:</p>
  <ul>
      <li class="field-body">
        <b><code>samples</code></b>
        
        <div class="doc-md-description">
          <p>set of inputs to present to the network. The function expects a 2-dimensional array (num_samples, input_size).</p>
        </div>
      </li>
      <li class="field-body">
        <b><code>duration_per_sample</code></b>
        
        <div class="doc-md-description">
          <p>the number of simulation steps for one input sample (default: 1000, 1 second biological time)</p>
        </div>
      </li>
      <li class="field-body">
        <b><code>measure_time</code></b>
        
        <div class="doc-md-description">
          <p>print out the computation time spent for one input sample (default: False)</p>
        </div>
      </li>
  </ul>



  <p>Returns:</p>
  <ul>
      <li class="field-body">
        
        <div class="doc-md-description">
          <p>A list of predicted class indices. If multiple neurons fulfill the condition, all candidate indices are returned.</p>
      </div>
      </li>
  </ul>

          <details class="quote">
            <summary>Source code in <code>ANNarchy/extensions/ann_to_snn_conversion/ANNtoSNNConverter.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
            <span class="n">samples</span><span class="p">,</span> 
            <span class="n">duration_per_sample</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> 
            <span class="n">measure_time</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Performs the prediction for a given input series.</span>

<span class="sd">    Parameters:</span>

<span class="sd">    :param samples: set of inputs to present to the network. The function expects a 2-dimensional array (num_samples, input_size).</span>
<span class="sd">    :param duration_per_sample: the number of simulation steps for one input sample (default: 1000, 1 second biological time)</span>
<span class="sd">    :param measure_time: print out the computation time spent for one input sample (default: False)</span>

<span class="sd">    :returns predictions: A list of predicted class indices. If multiple neurons fulfill the condition, all candidate indices are returned.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">predictions</span> <span class="o">=</span> <span class="p">[[]</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">))]</span>

    <span class="c1"># get the top-level layer</span>
    <span class="n">first_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_snn_network</span><span class="o">.</span><span class="n">get_populations</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">name</span>
    <span class="n">last_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_snn_network</span><span class="o">.</span><span class="n">get_population</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_snn_network</span><span class="o">.</span><span class="n">get_populations</span><span class="p">()[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>

    <span class="c1"># record the last layer to determine prediction</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_read_out</span> <span class="o">==</span> <span class="s2">&quot;membrane_potential&quot;</span><span class="p">:</span>
        <span class="n">m_read_out_layer</span> <span class="o">=</span> <span class="n">Monitor</span><span class="p">(</span><span class="n">last_layer</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;v&#39;</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">m_read_out_layer</span> <span class="o">=</span> <span class="n">Monitor</span><span class="p">(</span><span class="n">last_layer</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;spike&#39;</span><span class="p">])</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_snn_network</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">m_read_out_layer</span><span class="p">)</span>

    <span class="n">class_pop_size</span> <span class="o">=</span> <span class="n">last_layer</span><span class="o">.</span><span class="n">size</span>

    <span class="c1"># Needed when multiple classes achieve the same ranking</span>
    <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">()</span>

    <span class="c1"># Iterate over all samples</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="c1"># Progress bar</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\r</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Reset state variables</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_snn_network</span><span class="o">.</span><span class="n">reset</span><span class="p">(</span><span class="n">populations</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">monitors</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">projections</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="c1"># set input</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_snn_network</span><span class="o">.</span><span class="n">get_population</span><span class="p">(</span><span class="n">first_layer</span><span class="p">)</span><span class="o">.</span><span class="n">rates</span> <span class="o">=</span>  <span class="n">samples</span><span class="p">[</span><span class="n">i</span><span class="p">,:]</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">_max_f</span>

        <span class="c1"># The read-out is performed differently based on the mode selected by the user</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_read_out</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;time_to_first_spike&quot;</span><span class="p">,</span> <span class="s2">&quot;time_to_k_spikes&quot;</span><span class="p">]:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_snn_network</span><span class="o">.</span><span class="n">simulate_until</span><span class="p">(</span><span class="n">duration_per_sample</span><span class="p">,</span> <span class="n">population</span><span class="o">=</span><span class="n">last_layer</span><span class="p">,</span> <span class="n">measure_time</span><span class="o">=</span><span class="n">measure_time</span><span class="p">)</span>

            <span class="c1"># read-out accumulated inputs</span>
            <span class="n">spk_class</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_snn_network</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">m_read_out_layer</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;spike&#39;</span><span class="p">)</span>
            <span class="n">act_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">class_pop_size</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">neur_rank</span><span class="p">,</span> <span class="n">spike_times</span> <span class="ow">in</span> <span class="n">spk_class</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="n">act_pred</span><span class="p">[</span><span class="n">neur_rank</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">spike_times</span><span class="p">)</span>

            <span class="c1"># gather all neurons which fulfilled the condition</span>
            <span class="n">tmp_list</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argwhere</span><span class="p">(</span><span class="n">act_pred</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">amax</span><span class="p">(</span><span class="n">act_pred</span><span class="p">))</span>
            <span class="k">for</span> <span class="n">tmp</span> <span class="ow">in</span> <span class="n">tmp_list</span><span class="p">:</span>
                <span class="n">predictions</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tmp</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_read_out</span> <span class="o">==</span> <span class="s2">&quot;membrane_potential&quot;</span><span class="p">:</span>
            <span class="c1"># simulate 1s and record spikes in output layer</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_snn_network</span><span class="o">.</span><span class="n">simulate</span><span class="p">(</span><span class="n">duration_per_sample</span><span class="p">,</span> <span class="n">measure_time</span><span class="o">=</span><span class="n">measure_time</span><span class="p">)</span>

            <span class="c1"># read-out accumulated inputs</span>
            <span class="n">spk_class</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_snn_network</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">m_read_out_layer</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;v&#39;</span><span class="p">)</span>

            <span class="c1"># the neuron with the highest accumulated membrane potential is the selected candidate</span>
            <span class="c1"># (HD: 23th May 2023: I&#39;m not sure if it could happen that two neurons have the same mp)</span>
            <span class="n">tmp_list</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argwhere</span><span class="p">(</span><span class="n">spk_class</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,:]</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">amax</span><span class="p">(</span><span class="n">spk_class</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,:]))</span>
            <span class="k">for</span> <span class="n">tmp</span> <span class="ow">in</span> <span class="n">tmp_list</span><span class="p">:</span>
                <span class="n">predictions</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tmp</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_read_out</span> <span class="o">==</span> <span class="s2">&quot;spike_count&quot;</span><span class="p">:</span>
            <span class="c1"># simulate 1s and record spikes in output layer</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_snn_network</span><span class="o">.</span><span class="n">simulate</span><span class="p">(</span><span class="n">duration_per_sample</span><span class="p">,</span> <span class="n">measure_time</span><span class="o">=</span><span class="n">measure_time</span><span class="p">)</span>

            <span class="c1"># retrieve the recorded spike events</span>
            <span class="n">spk_class</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_snn_network</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">m_read_out_layer</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;spike&#39;</span><span class="p">)</span>

            <span class="c1"># The predicted label is the neuron index with the highest number of spikes.</span>
            <span class="c1"># Therefore, we count the number of spikes each output neuron emitted.</span>
            <span class="n">act_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">class_pop_size</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">neur_rank</span><span class="p">,</span> <span class="n">spike_times</span> <span class="ow">in</span> <span class="n">spk_class</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="n">act_pred</span><span class="p">[</span><span class="n">neur_rank</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">spike_times</span><span class="p">)</span>

            <span class="c1"># gather all neurons which achieved highest number of spikes</span>
            <span class="n">tmp_list</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argwhere</span><span class="p">(</span><span class="n">act_pred</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">amax</span><span class="p">(</span><span class="n">act_pred</span><span class="p">))</span>
            <span class="k">for</span> <span class="n">tmp</span> <span class="ow">in</span> <span class="n">tmp_list</span><span class="p">:</span>
                <span class="n">predictions</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tmp</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="k">return</span> <span class="n">predictions</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>


</div>




  </div>

  </div>

</div><h2 id="references">References<a class="headerlink" href="#references" title="Permanent link">#</a></h2>
<p>Izhikevich (2003) Simple Model of Spiking Neurons. IEEE transactions on neural networks 14(6). doi: 10.1109/TNN.2003.820440</p>
<p>Diehl PU, Neil D, Binas J,et al. (2015) Fast-classifying, high-accuracy spiking deep networks through weight and threshold balancing,2015 International Joint Conference on Neural Networks (IJCNN), 1-8, doi: 10.1109/IJCNN.2015.7280696.</p>
<p>Rueckauer B, Lungu I, Hu Y, et al. (2017) Conversion of Continuous-Valued Deep Networks to Efficient Event-Driven Networks for Image Classification., Front. Neurosci., 2017, 11. doi: 10.3389/fnins.2017.00682</p>
<p>Park S, Kim S, Choe H, et al. (2019) Fast and Efficient Information Transmission with Burst Spikes in Deep Spiking Neural Networks. </p>
<p>Auge D, Hille J, Mueller E et al. (2021) A Survey of Encoding Techniques for Signal Processing in Spiking Neural Networks. Neural Processing Letters. 2021; 53:4963-4710. doi:10.1007/s11063-021-10562-2</p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; Julien Vitay, Helge lo Dinkelbach, Fred H. Hamker
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "..", "features": ["header.autohide"], "search": "../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../assets/javascripts/bundle.c8d2eff1.min.js"></script>
      
        <script src="../javascripts/config.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>